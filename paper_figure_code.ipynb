{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart transplant recipient clinical and protein markers predict post-surgical primary graft dysfunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "seed=0\n",
    "np.random.seed(seed)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib.pylab import plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "\n",
    "from scipy.stats import ttest_rel,ks_2samp, pearsonr, ttest_ind, mannwhitneyu, levene, sem, t, variation\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_score, recall_score, roc_auc_score,precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_auc_score,precision_recall_curve, average_precision_score, f1_score\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "dpi = 400\n",
    "matplotlib.rcParams['figure.dpi'] = dpi\n",
    "matplotlib.rcParams['axes.titleweight'] = 'bold'\n",
    "matplotlib.rcParams['axes.labelweight'] = 'bold'\n",
    "matplotlib.rcParams['font.weight'] = 'bold'\n",
    "matplotlib.rcParams['font.serif'] = 'Times New Roman'\n",
    "matplotlib.rcParams['figure.titleweight'] = 'bold'\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "prospective_color = 'blue'\n",
    "retrospective_color = 'red'\n",
    "integrated_color = 'green'\n",
    "\n",
    "dropbox_figures = '/Users/nickgiangreco/gmail_dropbox/Dropbox/PGD Paper/figures/'\n",
    "dropbox_data = '/Users/nickgiangreco/gmail_dropbox/Dropbox/PGD Paper/data/'\n",
    "\n",
    "def mean_and_std(data):\n",
    "\n",
    "    return np.mean(data), np.std(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Clinical characteristics\n",
    "\n",
    "see src/r/tableone.R for table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "uni_agg = pd.read_csv('../../data/bootstrap_clinical_logit/integrated_logit_bootstrap_pgd_~_clinical_features_lwr_mean_median_upr.csv')\n",
    "print(uni_agg.variable.unique())\n",
    "fs = uni_agg.variable.str.replace('_Y','')\n",
    "fs = fs.str.replace('_',' ')\n",
    "uni_agg.variable = fs\n",
    "tmp = uni_agg.set_index('variable').round(4)[['lwr','mean','upr']]\n",
    "tmp.to_csv(dropbox_data+'clinical_population_associations.csv')\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "uni_agg = pd.read_csv('../../data/bootstrap_clinical_logit/integrated_logit_bootstrap_pgd_~_all_clinical_features_lwr_mean_median_upr.csv')\n",
    "print(uni_agg.variable.unique())\n",
    "fs = uni_agg.variable.str.replace('_Y','')\n",
    "fs = fs.str.replace('_',' ')\n",
    "uni_agg.variable = fs\n",
    "tmp = uni_agg.set_index('variable').round(4)[['lwr','mean','upr']]\n",
    "tmp.to_csv(dropbox_data+'all_clinical_population_associations.csv')\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Exosome Protein characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Identified proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cumc = pd.read_csv('../../data/df_samples_cumc_allsets.csv',index_col=0)\n",
    "cedar = pd.read_csv('../../data/df_samples_cedar_allsets.csv',index_col=0)\n",
    "paris = pd.read_csv('../../data/df_samples_paris_allsets.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "co_p100 = cumc.index.values\n",
    "ce_p010 = cedar.index.values\n",
    "co_ce_p110 = np.intersect1d(co_p100,ce_p010)\n",
    "pa_p001 = paris.index.values\n",
    "co_pa_p101 = np.intersect1d(co_p100,pa_p001)\n",
    "ce_pa_p011 = np.intersect1d(ce_p010,pa_p001)\n",
    "co_ce_pa_p111 = np.intersect1d(co_ce_p110,pa_p001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(dpi=dpi)\n",
    "vd = venn3((len(co_p100),len(ce_p010),len(co_ce_p110),\n",
    "            len(pa_p001),len(co_pa_p101),\n",
    "            len(ce_pa_p011),len(co_ce_pa_p111)),\n",
    "           set_labels=['Columbia','Cedars-Sinai','Pitíe Salpetriere'])\n",
    "ax.set_title('Identified protein markers',pad=8,size=18)\n",
    "\n",
    "s=15\n",
    "for text in vd.subset_labels:\n",
    "    text.set_fontsize(s)\n",
    "s=16\n",
    "for text in vd.set_labels:\n",
    "    text.set_fontsize(s)\n",
    "\n",
    "fig.savefig(dropbox_figures+'ProteinDescription_venn_diagram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "index = pd.Index(np.union1d(np.union1d(co_p100,ce_p010),pa_p001))\n",
    "integrated = pd.DataFrame(index=index)\n",
    "integrated = integrated.join(cumc).join(cedar).join(paris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cohort = pd.read_csv('../../data/integrated_sample_groups_imputed_data_raw.csv',index_col=0).set_index('Sample')[['Cohort','PGD']]\n",
    "tmp = integrated.T\n",
    "integrated_melted_full = tmp.join(cohort['Cohort']).rename_axis('Sample').reset_index().melt(id_vars=['Cohort','Sample'],var_name='Protein')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "integrated_melted_full.Protein.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#integrated_melted_full.groupby(['Cohort','Sample']).agg(sum).sort_values('value').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = integrated_melted_full[~integrated_melted_full.value.notna()].groupby('Cohort')['Protein'].unique()\n",
    "nonidentified_proteins = np.union1d(np.union1d(tmp.iloc[0],tmp.iloc[1]),tmp.iloc[2])\n",
    "len(nonidentified_proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(co_ce_pa_p111))\n",
    "print(len(np.intersect1d(nonidentified_proteins,co_ce_pa_p111)))\n",
    "print(len(co_ce_pa_p111) - len(np.intersect1d(nonidentified_proteins,co_ce_pa_p111)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "common_proteins = integrated_melted_full[~integrated_melted_full.Protein.isin(nonidentified_proteins)].Protein.drop_duplicates().values\n",
    "\n",
    "idmap_sub = pd.read_csv('../../data/protein_gene_map_full.csv')[['Protein','Gene_name']].dropna()\n",
    "\n",
    "common_proteins_to_genes = idmap_sub[idmap_sub.Protein.isin(common_proteins)]\n",
    "\n",
    "display(np.setdiff1d(common_proteins,common_proteins_to_genes.Protein.values))\n",
    "\n",
    "display(common_proteins_to_genes.shape)\n",
    "\n",
    "common_proteins_to_genes_immunos = common_proteins_to_genes[common_proteins_to_genes.Gene_name.str.startswith('IG')]\n",
    "\n",
    "display(common_proteins_to_genes_immunos.shape)\n",
    "\n",
    "common_proteins_to_genes_no_immunos = common_proteins_to_genes[~common_proteins_to_genes.Gene_name.str.startswith('IG')]\n",
    "\n",
    "display(common_proteins_to_genes_no_immunos.shape)\n",
    "\n",
    "pickle.dump(common_proteins_to_genes_no_immunos.Protein.values,open('../../data/proteins_no_immunoglobulins.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_proteins_to_genes_immunos.to_csv('../../data/IGS_to_genes.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_proteins_to_genes_immunos.to_csv('../../data/identified_IG_uniprot_to_genes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = pd.concat([common_proteins_to_genes_no_immunos,\n",
    "           common_proteins_to_genes_immunos]).Protein.unique()\n",
    "pickle.dump(tmp,open('../../data/proteins_immunoglobulins.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "integrated_melted_full[~integrated_melted_full.Protein.isin(nonidentified_proteins)].Protein.drop_duplicates().to_csv('../../data/integrated_cohort_identified_proteins.csv',index=False) \n",
    "\n",
    "integrated_melted_full[~integrated_melted_full.Protein.isin(nonidentified_proteins)].Protein.drop_duplicates().str.split('-').apply(lambda x : x[0]).to_csv('../../data/integrated_cohort_identified_proteins_chopped_isoforms.csv',index=False)\n",
    "\n",
    "integrated_melted_full[~integrated_melted_full.Protein.isin(nonidentified_proteins)].Protein.nunique() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Protein value distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cumc_df = (cumc.\n",
    "          rename_axis('Protein').\n",
    "          loc[common_proteins].\n",
    "          apply(lambda x : (x - np.mean(x)) / np.std(x),axis=1).\n",
    "          reset_index().\n",
    "          melt(id_vars='Protein'))\n",
    "cumc_df['Cohort'] = 'Columbia'\n",
    "\n",
    "cedar_df = (cedar.\n",
    "          rename_axis('Protein').\n",
    "          loc[common_proteins].\n",
    "          apply(lambda x : (x - np.mean(x)) / np.std(x),axis=1).\n",
    "          reset_index().\n",
    "          melt(id_vars='Protein'))\n",
    "cedar_df['Cohort'] = 'Cedar-Sinai'\n",
    "\n",
    "paris_df = (paris.\n",
    "          rename_axis('Protein').\n",
    "          loc[common_proteins].\n",
    "          apply(lambda x : (x - np.mean(x)) / np.std(x),axis=1).\n",
    "          reset_index().\n",
    "          melt(id_vars='Protein'))\n",
    "paris_df['Cohort'] = 'Pitíe Salpetriere'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['axes.titlepad'] = 8\n",
    "matplotlib.rcParams['axes.titlesize'] = 16\n",
    "matplotlib.rcParams['axes.labelsize'] = 16\n",
    "matplotlib.rcParams['xtick.labelsize'] = 16\n",
    "matplotlib.rcParams['ytick.labelsize'] = 16\n",
    "\n",
    "fig,ax = plt.subplots(nrows=3,ncols=1,sharex=True,sharey=True,dpi=dpi,figsize=(6,4))\n",
    "\n",
    "cohorts=['Columbia','Cedar-Sinai','Pitíe Salpetriere']\n",
    "\n",
    "for i,grp in cumc_df.groupby('variable'):\n",
    "    sns.distplot(grp['value'],\n",
    "                 color='Blue',\n",
    "                 label=cohorts[0],\n",
    "                 kde=False,\n",
    "                 ax=ax[0])\n",
    "    ax[0].set_alpha(0.8)\n",
    "\n",
    "for i,grp in cedar_df.groupby('variable'):\n",
    "    sns.distplot(grp['value'],\n",
    "                 color='Green',\n",
    "                 label=cohorts[1],\n",
    "                 kde=False,\n",
    "                 ax=ax[1])\n",
    "    ax[1].set_alpha(0.8)\n",
    "\n",
    "for i,grp in paris_df.groupby('variable'):\n",
    "    sns.distplot(grp['value'],\n",
    "                 color='red',\n",
    "                 label=cohorts[2],\n",
    "                 kde=False,\n",
    "                 ax=ax[2])\n",
    "    ax[2].set_alpha(0.8)\n",
    "sns.despine()\n",
    "ax[0].set_xlabel('')\n",
    "ax[1].set_xlabel('')\n",
    "\n",
    "for i,a in enumerate(ax):\n",
    "    a.text(2.5,50,cohorts[i])\n",
    "    a.set_xlim(-5,5)\n",
    "ax[1].set_ylabel('Density')\n",
    "ax[1].yaxis.set_label_coords(-0.1,0)\n",
    "ax[0].set_title('Exosome protein expression distribution')\n",
    "ax[2].set_xlabel('Standardized protein expression')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'ProteinDescription_distributions.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Distribution deviation from normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import normaltest\n",
    "normaltest(cumc_df['value'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "normaltest(cedar_df['value'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "normaltest(paris_df['value'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Distribution significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as sc\n",
    "print(sc.ks_2samp(cumc_df['value'].values,cedar_df['value'].values))\n",
    "print(sc.ks_2samp(cedar_df['value'].values,paris_df['value'].values))\n",
    "print(sc.ks_2samp(cumc_df['value'].values,paris_df['value'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display(cumc_df['value'].describe())\n",
    "display(cedar_df['value'].describe())\n",
    "display(paris_df['value'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Protein correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=200)\n",
    "integrated.dropna().T.corr('spearman').rename_axis('P1').reset_index().melt(id_vars='P1',var_name='P2')['value'].hist()\n",
    "plt.ylabel('Number of correlated proteins')\n",
    "plt.xlabel('Correlation')\n",
    "plt.tight_layout()\n",
    "plt.savefig(dropbox_figures+'protein_correlations.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Enrichment of identified proteins in GO categories (via StringDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv('../../data/integrated_cohort_identified_proteins_enrichment.Component.tsv',sep='\\t').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample x Protein Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_melted_full[['Cohort','Sample']].drop_duplicates().set_index('Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = pickle.load(open('../../data/proteins_immunoglobulins.pkl','rb'))\n",
    "idmap_sub = pd.read_csv('../../data/protein_gene_map_full.csv')[['Protein','Gene_name']].dropna()\n",
    "dat = (integrated.\n",
    " loc[proteins].\n",
    " join(idmap_sub.set_index('Protein')).\n",
    " set_index('Gene_name').\n",
    " T.\n",
    " join(integrated_melted_full.\n",
    "      loc[:,['Cohort','Sample']].\n",
    "      drop_duplicates().\n",
    "      set_index('Sample')\n",
    "     )\n",
    ")\n",
    "lut = dict(zip(dat.loc[:,'Cohort'].unique(),'rbg'))\n",
    "col_colors = dat.loc[:,'Cohort'].map(lut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_proteins = (pd.read_csv('../../data/individual_clinical_and_protein_01_'+\n",
    "                            'within_notwithcohorts_marker_performance_statistics.csv').\n",
    "                feature.\n",
    "                unique()\n",
    "               )\n",
    "dict(zip(dat.columns.isin(sig_proteins),['black','gray']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.clustermap(dat.drop('Cohort',1).T,\n",
    "               row_cluster=True,col_cluster=True,\n",
    "               standard_scale=1,col_colors=col_colors,\n",
    "               cmap='viridis',figsize=(20,80))\n",
    "g.fig.tight_layout()\n",
    "g.fig.savefig('../../docs/imgs/samplexgeneheeatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Individual clinical and protein prediction processing/analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "data_dir='../../data/integrated_pgd_predictions/'\n",
    "scores = ['roc_auc']\n",
    "scorers = { 'roc_auc' : roc_auc_score}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### clinical predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "type_='clinical_01_within_notwithcohorts_features_pgd_prediction_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "files = [x for x in os.listdir(data_dir) if ( ('pkl' not in x) & \n",
    "                                             (type_ in x) & \n",
    "                                             ('patient' in x) & \n",
    "                                             ('importance' not in x) & \n",
    "                                             ('bootstrap' in x) &\n",
    "                                             ('protein_prediction_metric' in x)\n",
    "                                            )\n",
    "        ]\n",
    "\n",
    "n=50\n",
    "lsts=[]\n",
    "scorers = { 'roc_auc' : m.roc_auc_score, 'precision' : m.precision_score, 'recall' : m.recall_score }\n",
    "feature_mccv_score_means_dfs = []\n",
    "for score,scorer in scorers.items():\n",
    "    feature_scores_bootstraps = []\n",
    "    for file in files:\n",
    "        feature = (file.\n",
    "                   replace(type_,'').\n",
    "                   replace('_protein_prediction_metric_bootstrap_train_test_val_patient_level_data.csv',''))\n",
    "        dat = pd.read_csv(data_dir+file,index_col=0)\n",
    "        vals = []\n",
    "        for b in range(n):\n",
    "            x = (dat.\n",
    "                 sample(n=dat.shape[0],replace=True)\n",
    "                )\n",
    "            vals.append([feature,b,scorer(x.y_true,x.y_pred)])\n",
    "        feature_scores_bootstrap = pd.DataFrame(vals,columns=['Feature','Bootstrap',score])\n",
    "        feature_scores_bootstraps.append(feature_scores_bootstrap)\n",
    "    \n",
    "    feature_mccv_score_means_df = (pd.concat(feature_scores_bootstraps).\n",
    "                                   groupby(['Feature'])[score].\n",
    "                                   mean().\n",
    "                                   reset_index().\n",
    "                                   rename(columns={score : 'mean_validation_'+score}).\n",
    "                                   set_index('Feature'))\n",
    "\n",
    "    display(feature_mccv_score_means_df.sort_values('mean_validation_'+score).tail())\n",
    "\n",
    "    feature_mccv_score_means_dfs.append(feature_mccv_score_means_df)\n",
    "feature_mccv_score_means_df = pd.concat(feature_mccv_score_means_dfs,\n",
    "                                        axis=1,sort=True).reset_index()\n",
    "feature_mccv_score_means_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = [x for x in os.listdir(data_dir) if ( ('pkl' not in x) & \n",
    "                                             (type_ in x) & \n",
    "                                             ('patient' in x) & \n",
    "                                             ('importance' not in x) & \n",
    "                                             ('bootstrap' in x) &\n",
    "                                             ('protein_prediction_metric' not in x) & \n",
    "                                             ('clinical_prediction_metric' not in x) &\n",
    "                                             ('prediction_metric' in x)\n",
    "                                            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(files))\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "feature_mccv_score_means_dfs = []\n",
    "for score in scores:\n",
    "    lsts=[]\n",
    "    for file in files:\n",
    "        feature = (file.\n",
    "                   replace(type_,'').\n",
    "                   replace('_protein_prediction_metric_bootstrap_train_test_val.csv',''))\n",
    "        feature_means_series = (pd.\n",
    "                                read_csv(data_dir+file,index_col=0).\n",
    "                                rename(columns={'bootstrap' : 'Bootstrap',\n",
    "                                                'model' : 'Model'})\n",
    "                               )\n",
    "        feature_means_series['Feature'] = feature        \n",
    "        lsts.append(feature_means_series)\n",
    "        \n",
    "    feature_mccv_scores_df = pd.concat(lsts)\n",
    "    feature_mccv_scores_dfs[score] = feature_mccv_scores_df\n",
    "    \n",
    "    feature_mccv_score_means_df = (feature_mccv_scores_df.\n",
    "                                   groupby(['Model','Feature'])[score].\n",
    "                                   mean().\n",
    "                                   reset_index().\n",
    "                                   rename(columns={score : 'mean_'+score}))\n",
    "\n",
    "    display(feature_mccv_score_means_df.sort_values('mean_'+score).tail())\n",
    "\n",
    "    feature_mccv_score_means_dfs.append(feature_mccv_score_means_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "feature_mccv_score_means_df = pd.concat([\n",
    "    feature_mccv_score_means_dfs[i][['mean_'+score]] for \n",
    "    i,score in enumerate(scores)],axis=1)\n",
    "\n",
    "feature_mccv_score_means_df['Feature'] = feature_mccv_score_means_dfs[0]['Feature']\n",
    "feature_mccv_score_means_df['Model'] = feature_mccv_score_means_dfs[0]['Model']\n",
    "\n",
    "feature_mccv_score_means_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n=50\n",
    "lsts=[]\n",
    "feature_mccv_scores_df = {}\n",
    "feature_mccv_score_means_dfs = []\n",
    "for score,scorer in scorers.items():\n",
    "    feature_scores_bootstraps = []\n",
    "    for file in files:\n",
    "        feature = (file.\n",
    "                   replace(type_,'').\n",
    "                   replace('_prediction_metric_bootstrap_train_test_val'+\n",
    "                           '_patient_level_data.csv','').\n",
    "                   replace('CVP_','CVP/')\n",
    "                  )\n",
    "        dat = pd.read_csv(data_dir+file,index_col=0)\n",
    "        vals = []\n",
    "        for b in range(n):\n",
    "            x = (dat.\n",
    "                 sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "                )\n",
    "            vals.append([feature,b,x.model.unique()[0],scorer(x.y_true,x.y_proba)])\n",
    "        feature_scores_bootstrap = pd.DataFrame(vals,columns=['Feature','Bootstrap',\n",
    "                                                              'Model',score])\n",
    "        feature_scores_bootstraps.append(feature_scores_bootstrap)\n",
    "    \n",
    "    feature_mccv_scores_df[score] = \\\n",
    "    (pd.concat(feature_scores_bootstraps)\n",
    "    )\n",
    "    (pd.concat(feature_scores_bootstraps).\n",
    "     groupby(['Feature','Model'])[score].\n",
    "     describe(percentiles=[0.025,0.975]).\n",
    "     loc[:,['2.5%','mean','97.5%']].\n",
    "     sort_values('mean',ascending=False)\n",
    "    ).to_csv('../../data/'+type_+score+'_CIs.csv')\n",
    "\n",
    "    feature_mccv_score_means_df = (pd.concat(feature_scores_bootstraps).\n",
    "                                   groupby(['Feature','Model'])[score].\n",
    "                                   mean().\n",
    "                                   reset_index().\n",
    "                                   rename(columns={score : 'mean_validation_'+score}))\n",
    "\n",
    "    display(feature_mccv_score_means_df.sort_values('mean_validation_'+score).tail())\n",
    "\n",
    "    feature_mccv_score_means_dfs.append(feature_mccv_score_means_df)\n",
    "feature_mccv_score_means_df = (reduce(lambda  left,right: pd.merge(left,right,\n",
    "                                                                  on=['Feature','Model'],\n",
    "                                            how='outer'), feature_mccv_score_means_dfs))\n",
    "feature_mccv_score_means_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = [x for x in os.listdir(data_dir) if ( ('pkl' not in x) & \n",
    "                                             (type_ in x) & \n",
    "                                             ('patient' not in x) & \n",
    "                                             ('importance' in x) & \n",
    "                                             ('bootstrap' in x) &\n",
    "                                             ('protein_prediction_metric' not in x) & \n",
    "                                             ('clinical_prediction_metric' not in x) &\n",
    "                                             ('prediction_metric' in x)\n",
    "                                            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lsts=[]\n",
    "for file in files:\n",
    "    feature = (file.\n",
    "               replace(type_,'').\n",
    "               replace('_prediction_metric_bootstrap_train_test_val'+\n",
    "                       '_feature_importances.csv','').\n",
    "               replace('CVP_','CVP/')\n",
    "              )\n",
    "    feature_logit_df = (pd.read_csv(data_dir+file,index_col=0).\n",
    "                        rename(columns={'bootstrap' : 'Bootstrap',\n",
    "                                        'model' : 'Model'}))\n",
    "    lsts.append(feature_logit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_importance_odds_df = pd.concat(lsts)\n",
    "feature_mccv_importance_odds_df['odds'] = np.exp(feature_mccv_importance_odds_df['Importance'])\n",
    "feature_mccv_odds_df = (feature_mccv_importance_odds_df.\n",
    "                        groupby(['Feature','Model'])['odds'].\n",
    "                        describe(percentiles=[0.025,0.975]).\n",
    "                        loc[:,['2.5%','mean','97.5%']].\n",
    "                        rename(columns={'2.5%' : 'odds_lwr',\n",
    "                                        'mean' : 'odds_mean',\n",
    "                                        '97.5%' : 'odds_upr'}).\n",
    "                        reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_odds_df.query('odds_lwr>1 | odds_upr<1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_odds_df.query('Feature==\"CVP/PCWP\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### permuted performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = [x for x in os.listdir(data_dir) if ( ('pkl' not in x) & \n",
    "                                             (type_ in x) & \n",
    "                                             ('patient' in x) & \n",
    "                                             ('importance' not in x) & \n",
    "                                             ('bootstrap' not in x) &\n",
    "                                             ('protein_prediction_metric' not in x) & \n",
    "                                             ('clinical_prediction_metric' not in x) &\n",
    "                                             ('prediction_metric' in x)\n",
    "                                            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "feature_mccv_permuted_scores_dfs = {}\n",
    "for score in scores:\n",
    "    lsts=[]\n",
    "    for file in files:\n",
    "        feature = (file.\n",
    "                   replace(type_,'').\n",
    "                   replace('_protein_prediction_metric_permute_train_test_val.csv',''))\n",
    "        feature_means_series = (pd.read_csv(data_dir+file,index_col=0).\n",
    "                                rename(columns={'bootstrap' : 'Bootstrap','model' : 'Model'}\n",
    "                                      )\n",
    "                               )\n",
    "        feature_means_series['Feature'] = feature\n",
    "        lsts.append(feature_means_series)\n",
    "        \n",
    "    feature_mccv_permuted_scores_df = pd.concat(lsts)\n",
    "    feature_mccv_permuted_scores_dfs[score] = feature_mccv_permuted_scores_df\n",
    "    \n",
    "    feature_mccv_permuted_score_means_df = (feature_mccv_permuted_scores_df.\n",
    "                                            groupby(['Model','Feature'])[score].\n",
    "                                            mean().\n",
    "                                            reset_index().\n",
    "                                            rename(columns={score : 'mean_permuted_'+score}))\n",
    "\n",
    "    display(feature_mccv_permuted_score_means_df.sort_values('mean_permuted_'+score).tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n=50\n",
    "lsts=[]\n",
    "feature_mccv_permuted_scores_df = {}\n",
    "feature_mccv_permuted_score_means_dfs = []\n",
    "for score,scorer in scorers.items():\n",
    "    feature_scores_bootstraps = []\n",
    "    for file in files:\n",
    "        feature = (file.\n",
    "                   replace(type_,'').\n",
    "                   replace('_prediction_metric_permute_train_test_val_patient_level_data.csv',''))\n",
    "        dat = pd.read_csv(data_dir+file,index_col=0)\n",
    "        vals = []\n",
    "        for b in range(n):\n",
    "            x = (dat.\n",
    "                 sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "                )\n",
    "            vals.append([feature,b,x.model.unique()[0],scorer(x.y_true,x.y_proba)])\n",
    "        feature_scores_bootstrap = pd.DataFrame(vals,columns=['Feature','Bootstrap',\n",
    "                                                              'Model',score])\n",
    "        feature_scores_bootstraps.append(feature_scores_bootstrap)\n",
    "    \n",
    "    feature_mccv_permuted_scores_df[score] = \\\n",
    "    (pd.concat(feature_scores_bootstraps)\n",
    "    )\n",
    "    feature_mccv_permuted_score_means_df = (pd.concat(feature_scores_bootstraps).\n",
    "                                   groupby(['Feature','Model'])[score].\n",
    "                                   mean().\n",
    "                                   reset_index().\n",
    "                                   rename(columns={score : 'mean_validation_'+score}))\n",
    "\n",
    "    display(feature_mccv_permuted_score_means_df.sort_values('mean_validation_'+score).tail())\n",
    "\n",
    "    feature_mccv_permuted_score_means_dfs.append(feature_mccv_permuted_score_means_df)\n",
    "feature_mccv_permuted_score_means_df = (reduce(lambda  left,right: pd.merge(left,right,\n",
    "                                                                  on=['Feature','Model'],\n",
    "                                            how='outer'), feature_mccv_permuted_score_means_dfs))\n",
    "feature_mccv_permuted_score_means_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### permuted importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = [x for x in os.listdir(data_dir) if ( ('pkl' not in x) & \n",
    "                                             (type_ in x) & \n",
    "                                             ('patient' not in x) & \n",
    "                                             ('importance' in x) & \n",
    "                                             ('bootstrap' not in x) &\n",
    "                                             ('protein_prediction_metric' not in x) & \n",
    "                                             ('clinical_prediction_metric' not in x) &\n",
    "                                             ('prediction_metric' in x)\n",
    "                                            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lsts=[]\n",
    "for file in files:\n",
    "    feature = (file.\n",
    "               replace(type_,'').\n",
    "               replace('_prediction_metric_bootstrap_train_test_val'+\n",
    "                       '_feature_importances.csv',''))\n",
    "    feature_logit_df = (pd.read_csv(data_dir+file,index_col=0).\n",
    "                        rename(columns={'bootstrap' : 'Bootstrap','model' : 'Model'})\n",
    "                       )\n",
    "    lsts.append(feature_logit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_permuted_importance_odds_df = pd.concat(lsts)\n",
    "\n",
    "feature_mccv_permuted_importance_odds_df['odds'] = \\\n",
    "np.exp(feature_mccv_permuted_importance_odds_df['Importance'])\n",
    "\n",
    "feature_mccv_permuted_odds_df = (feature_mccv_permuted_importance_odds_df.\n",
    "                                 groupby(['Feature','Model'])['odds'].\n",
    "                                 describe(percentiles=[0.025,0.975]).\n",
    "                                 loc[:,['2.5%','mean','97.5%']].\n",
    "                                 rename(columns={'2.5%' : 'permuted_odds_lwr',\n",
    "                                                 'mean' : 'permuted_odds_mean',\n",
    "                                                  '97.5%' : 'permuted_odds_upr'}).\n",
    "                                 reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_permuted_odds_df.query('permuted_odds_lwr>1 | permuted_odds_upr<1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### significant performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "score = 'roc_auc'\n",
    "features = feature_mccv_permuted_scores_df[score].Feature.unique()\n",
    "ms = feature_mccv_permuted_scores_df[score].Model.unique()\n",
    "\n",
    "\n",
    "pvals = []\n",
    "for f in features:\n",
    "    for m in ms:\n",
    "        bdist = feature_mccv_scores_df[score].query('Model==@m & Feature==@f')[score].values\n",
    "        pdist = feature_mccv_permuted_scores_df[score].query('Model==@m & Feature==@f')[score].values\n",
    "        t,pval = ks_2samp(pdist,bdist)\n",
    "        pvals.append([f,m,t,pval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_performance_significance = pd.DataFrame(pvals,\n",
    "                                                     columns=\n",
    "                                                     ['Feature',\n",
    "                                                      'Model',\n",
    "                                                      'Performance_Statistic',\n",
    "                                                      'Performance_P_value']\n",
    "                                                    )\n",
    "\n",
    "feature_mccv_performance_significance['Performance_bonferroni'] = \\\n",
    "multipletests(feature_mccv_performance_significance.Performance_P_value.values,\n",
    "              method='bonferroni')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_performance_significance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### significant importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "score = 'roc_auc'\n",
    "features = feature_mccv_permuted_scores_df[score].Feature.unique()\n",
    "ms = feature_mccv_permuted_scores_df[score].Model.unique()\n",
    "\n",
    "pvals = []\n",
    "for f in features:\n",
    "    for m in ms:\n",
    "        f = f.replace('CVP_','CVP/')\n",
    "        bdist = feature_mccv_importance_odds_df.query('Model==@m & Feature==@f')['Importance'].values\n",
    "        pdist = feature_mccv_permuted_importance_odds_df.query('Model==@m & Feature==@f')['Importance'].values\n",
    "        t,pval = ks_2samp(pdist,bdist)\n",
    "        pvals.append([f,m,t,pval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_importance_significance = pd.DataFrame(pvals,columns=['Feature','Model','Importance_Statistic','Importance_P_value'])\n",
    "\n",
    "feature_mccv_importance_significance['Importance_bonferroni'] = multipletests(feature_mccv_importance_significance.Importance_P_value.values,method='bonferroni')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_importance_significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### performance and importance correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "score = 'roc_auc'\n",
    "display(feature_mccv_scores_df[score].\n",
    "        set_index(['Feature','Bootstrap','Model'])[[score]].\n",
    "        head())\n",
    "\n",
    "display(feature_mccv_importance_odds_df.\n",
    "        set_index(['Feature','Bootstrap','Model'])[['odds']].\n",
    "        head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "score = 'roc_auc'\n",
    "performances_and_importances_df = (feature_mccv_scores_df[score].\n",
    "                                   set_index(['Feature','Bootstrap','Model'])[[score]].\n",
    "                                   join(\n",
    "                                       feature_mccv_importance_odds_df.\n",
    "                                       set_index(['Feature','Bootstrap','Model'])[['odds']])).reset_index()\n",
    "performances_and_importances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corr_df = (performances_and_importances_df.\n",
    "           dropna().\n",
    " groupby(['Feature','Model']).\n",
    " apply(lambda x : pearsonr(x.roc_auc,x.odds)[0])\n",
    ").reset_index().rename(columns={0 : 'Performance_Importance_Correlation'}).set_index(['Feature','Model'])\n",
    "\n",
    "corr_pvalue_df = (performances_and_importances_df.\n",
    "                  dropna().\n",
    "                  groupby(['Feature','Model']).\n",
    "                  apply(lambda x : pearsonr(x.roc_auc,x.odds)[1]).\n",
    "                  reset_index().rename(\n",
    "                      columns={0 : 'Performance_Importance_Correlation_P_value'}).\n",
    "                  set_index(['Feature','Model'])\n",
    "                 )\n",
    "\n",
    "corr_pvalue_df['Performance_Importance_Correlation_bonferroni'] = multipletests(corr_pvalue_df.Performance_Importance_Correlation_P_value,method='bonferroni')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "performances_and_importances_corr_df = corr_df.join(corr_pvalue_df).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "performances_and_importances_corr_df.sort_values('Performance_Importance_Correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### join mean performance, performance significance, importance significance, feature odds, and odds/performance correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mccv_performance_importance_correlation_significance_df = (\n",
    "    feature_mccv_score_means_df.set_index(['Feature','Model']).\n",
    "    join(\n",
    "        feature_mccv_odds_df.set_index(['Feature','Model'])\n",
    "    ).\n",
    "    join(\n",
    "        feature_mccv_permuted_odds_df.set_index(['Feature','Model'])\n",
    "    ).\n",
    "    join(\n",
    "        feature_mccv_performance_significance.set_index(['Feature','Model'])\n",
    "    ).\n",
    "    join( feature_mccv_importance_significance.set_index(['Feature','Model'])\n",
    "        ).\n",
    "    join(\n",
    "        performances_and_importances_corr_df.set_index(['Feature','Model'])\n",
    "    ).\n",
    "    reset_index()\n",
    ")\n",
    "mccv_performance_importance_correlation_significance_df.columns = [x.lower() for x in mccv_performance_importance_correlation_significance_df.columns]\n",
    "mccv_performance_importance_correlation_significance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clinical_mccv_performance_significance_and_feature_odds_df = \\\n",
    "mccv_performance_importance_correlation_significance_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clinical_mccv_performance_significance_and_feature_odds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### outputting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(clinical_mccv_performance_significance_and_feature_odds_df.\n",
    " to_csv('../../data/clinical_01_within_notwithcohorts_mccv_performance_significance_and_feature_odds_df.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### protein predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "type_='protein_raw_01_within_notwithcohorts_features_pgd_prediction_'\n",
    "proteins_no_immunoglobulins = pickle.load(open('../../data/proteins_no_immunoglobulins.pkl','rb'))\n",
    "scorers = { 'roc_auc' : roc_auc_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = [x for x in os.listdir(data_dir) if ( ('pkl' not in x) & \n",
    "                                             (type_ in x) & \n",
    "                                             ('patient' in x) & \n",
    "                                             ('importance' not in x) & \n",
    "                                             ('bootstrap' in x) &\n",
    "                                             ('protein_prediction_metric' not in x) & \n",
    "                                             ('clinical_prediction_metric' not in x) &\n",
    "                                             ('prediction_metric' in x)\n",
    "                                            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(files))\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "feature_mccv_scores_dfs = {}\n",
    "feature_mccv_score_means_dfs = []\n",
    "for score in scores:\n",
    "    lsts=[]\n",
    "    for file in files:\n",
    "        feature = (file.\n",
    "                   replace(type_,'').\n",
    "                   replace('_protein_prediction_metric_bootstrap_train_test_val.csv',''))\n",
    "        feature_means_series = (pd.\n",
    "                                read_csv(data_dir+file,index_col=0).\n",
    "                                rename(columns={'bootstrap' : 'Bootstrap',\n",
    "                                                'model' : 'Model'})\n",
    "                               )\n",
    "        feature_means_series['Feature'] = feature\n",
    "        \n",
    "        lsts.append(feature_means_series)\n",
    "        \n",
    "    feature_mccv_scores_df = pd.concat(lsts)\n",
    "    feature_mccv_scores_dfs[score] = feature_mccv_scores_df\n",
    "\n",
    "    feature_mccv_score_means_df = (feature_mccv_scores_df.\n",
    "                                   groupby(['Model','Feature'])[score].\n",
    "                                   mean().\n",
    "                                   reset_index().\n",
    "                                   rename(columns={score : 'mean_'+score}))\n",
    "\n",
    "    display(feature_mccv_score_means_df.sort_values('mean_'+score).tail())\n",
    "\n",
    "    feature_mccv_score_means_dfs.append(feature_mccv_score_means_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "feature_mccv_score_means_df = pd.concat([feature_mccv_score_means_dfs[i][['mean_'+score]] \n",
    "                                         for i,score in enumerate(scores)],axis=1)\n",
    "\n",
    "feature_mccv_score_means_df['Feature'] = feature_mccv_score_means_dfs[0]['Feature']\n",
    "feature_mccv_score_means_df['Model'] = feature_mccv_score_means_dfs[0]['Model']\n",
    "\n",
    "feature_mccv_score_means_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n=50\n",
    "lsts=[]\n",
    "feature_mccv_scores_df = {}\n",
    "feature_mccv_score_means_dfs = []\n",
    "for score,scorer in scorers.items():\n",
    "    feature_scores_bootstraps = []\n",
    "    for file in files:\n",
    "        feature = (file.\n",
    "                   replace(type_,'').\n",
    "                   replace('_prediction_metric_bootstrap_train_test_val_patient_level_data.csv',''))\n",
    "        if feature not in proteins_no_immunoglobulins:\n",
    "            continue\n",
    "        else:\n",
    "            dat = pd.read_csv(data_dir+file,index_col=0)\n",
    "            vals = []\n",
    "            for b in range(n):\n",
    "                x = (dat.\n",
    "                     sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "                    )\n",
    "                vals.append([feature,b,x.model.unique()[0],scorer(x.y_true,x.y_proba)])\n",
    "        feature_scores_bootstrap = pd.DataFrame(vals,columns=['Feature','Bootstrap',\n",
    "                                                              'Model',score])\n",
    "        feature_scores_bootstraps.append(feature_scores_bootstrap)\n",
    "    \n",
    "    feature_mccv_scores_df[score] = \\\n",
    "    (pd.concat(feature_scores_bootstraps)\n",
    "    )\n",
    "\n",
    "    feature_mccv_score_means_df = (pd.concat(feature_scores_bootstraps).\n",
    "                                   groupby(['Feature','Model'])[score].\n",
    "                                   mean().\n",
    "                                   reset_index().\n",
    "                                   rename(columns={score : 'mean_validation_'+score}))\n",
    "    (pd.concat(feature_scores_bootstraps).\n",
    "     groupby(['Feature','Model'])[score].\n",
    "     describe(percentiles=[0.025,0.975]).\n",
    "     loc[:,['2.5%','mean','97.5%']].\n",
    "     sort_values('mean',ascending=False)\n",
    "    ).to_csv('../../data/'+type_+score+'_CIs.csv')\n",
    "\n",
    "    display(feature_mccv_score_means_df.sort_values('mean_validation_'+score).tail())\n",
    "\n",
    "    feature_mccv_score_means_dfs.append(feature_mccv_score_means_df)\n",
    "feature_mccv_score_means_df = (reduce(lambda  left,right: pd.merge(left,right,\n",
    "                                                                  on=['Feature','Model'],\n",
    "                                            how='outer'), feature_mccv_score_means_dfs))\n",
    "print(feature_mccv_score_means_df.shape)\n",
    "feature_mccv_score_means_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = [x for x in os.listdir(data_dir) if ( ('pkl' not in x) & \n",
    "                                             (type_ in x) & \n",
    "                                             ('patient' not in x) & \n",
    "                                             ('importance' in x) & \n",
    "                                             ('bootstrap' in x) &\n",
    "                                             ('protein_prediction_metric' not in x) & \n",
    "                                             ('clinical_prediction_metric' not in x) &\n",
    "                                             ('prediction_metric' in x)\n",
    "                                            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lsts=[]\n",
    "for file in files:\n",
    "    feature = (file.\n",
    "               replace(type_,'').\n",
    "               replace('_prediction_metric_bootstrap_train_test_val'+\n",
    "                       '_feature_importances.csv',''))\n",
    "    if feature not in proteins_no_immunoglobulins:\n",
    "        continue\n",
    "    else:\n",
    "        feature_logit_df = (pd.\n",
    "                        read_csv(data_dir+file,index_col=0).\n",
    "                        rename(columns={'bootstrap' : 'Bootstrap','model' : 'Model'}).\n",
    "                        dropna())\n",
    "        lsts.append(feature_logit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_importance_odds_df = pd.concat(lsts)\n",
    "feature_mccv_importance_odds_df['odds'] = np.exp(feature_mccv_importance_odds_df['Importance'])\n",
    "feature_mccv_odds_df = feature_mccv_importance_odds_df.groupby(['Feature','Model'])['odds'].describe(percentiles=[0.025,0.975]).loc[:,['2.5%','mean','97.5%']].rename(columns={'2.5%' : 'odds_lwr','mean' : 'odds_mean','97.5%' : 'odds_upr'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(feature_mccv_odds_df.query('odds_lwr>1 | odds_upr<1').shape)\n",
    "feature_mccv_odds_df.query('odds_lwr>1 | odds_upr<1').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### permuted performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = [x for x in os.listdir(data_dir) if ( ('pkl' not in x) & \n",
    "                                             (type_ in x) & \n",
    "                                             ('patient' in x) & \n",
    "                                             ('importance' not in x) & \n",
    "                                             ('bootstrap' not in x) &\n",
    "                                             ('protein_prediction_metric' not in x) & \n",
    "                                             ('clinical_prediction_metric' not in x) &\n",
    "                                             ('prediction_metric' in x)\n",
    "                                            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "feature_mccv_permuted_scores_dfs = {}\n",
    "feature_mccv_permuted_score_means_dfs = []\n",
    "for score in scores:\n",
    "    lsts=[]\n",
    "    for file in files:\n",
    "        feature = (file.\n",
    "                   replace(type_,'').\n",
    "                   replace('_protein_prediction_metric_permute_train_test_val.csv',''))\n",
    "        feature_means_series = (pd.read_csv(data_dir+file,index_col=0).\n",
    "                                rename(columns={'bootstrap' : 'Bootstrap',\n",
    "                                                'model' : 'Model'}))\n",
    "        feature_means_series['Feature'] = feature\n",
    "        \n",
    "        lsts.append(feature_means_series)\n",
    "        \n",
    "    feature_mccv_permuted_scores_df = pd.concat(lsts)\n",
    "    feature_mccv_permuted_scores_dfs[score] = feature_mccv_permuted_scores_df\n",
    "\n",
    "    feature_mccv_permuted_score_means_df = (feature_mccv_permuted_scores_df.\n",
    "                                   groupby(['Model','Feature'])[score].\n",
    "                                   mean().\n",
    "                                   reset_index().\n",
    "                                   rename(columns={score : 'mean_'+score}))\n",
    "\n",
    "    display(feature_mccv_permuted_score_means_df.sort_values('mean_'+score).tail())\n",
    "\n",
    "    feature_mccv_permuted_score_means_dfs.append(feature_mccv_permuted_score_means_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "feature_mccv_permuted_score_means_df = pd.concat([\n",
    "    feature_mccv_permuted_score_means_dfs[i][['mean_'+score]] for \n",
    "    i,score in enumerate(scores)],axis=1)\n",
    "\n",
    "feature_mccv_permuted_score_means_df['Feature'] = feature_mccv_permuted_score_means_dfs[0]['Feature']\n",
    "feature_mccv_permuted_score_means_df['Model'] = feature_mccv_permuted_score_means_dfs[0]['Model']\n",
    "\n",
    "feature_mccv_permuted_score_means_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n=50\n",
    "lsts=[]\n",
    "feature_mccv_permuted_scores_df = {}\n",
    "feature_mccv_permuted_score_means_dfs = []\n",
    "for score,scorer in scorers.items():\n",
    "    feature_scores_bootstraps = []\n",
    "    for file in files:\n",
    "        feature = (file.\n",
    "                   replace(type_,'').\n",
    "                   replace('_prediction_metric_permute_train_test_val_patient_level_data.csv',''))\n",
    "        if feature not in proteins_no_immunoglobulins:\n",
    "            continue\n",
    "        else:\n",
    "            dat = pd.read_csv(data_dir+file,index_col=0)\n",
    "            vals = []\n",
    "            for b in range(n):\n",
    "                x = (dat.\n",
    "                     sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "                    )\n",
    "                vals.append([feature,b,x.model.unique()[0],scorer(x.y_true,x.y_proba)])\n",
    "        feature_scores_bootstrap = pd.DataFrame(vals,columns=['Feature','Bootstrap',\n",
    "                                                              'Model',score])\n",
    "        feature_scores_bootstraps.append(feature_scores_bootstrap)\n",
    "    \n",
    "    feature_mccv_permuted_scores_df[score] = \\\n",
    "    (pd.concat(feature_scores_bootstraps)\n",
    "    )\n",
    "    feature_mccv_permuted_score_means_df = (pd.concat(feature_scores_bootstraps).\n",
    "                                   groupby(['Feature','Model'])[score].\n",
    "                                   mean().\n",
    "                                   reset_index().\n",
    "                                   rename(columns={score : 'mean_validation_'+score}))\n",
    "\n",
    "    display(feature_mccv_permuted_score_means_df.sort_values('mean_validation_'+score).tail())\n",
    "\n",
    "    feature_mccv_permuted_score_means_dfs.append(feature_mccv_permuted_score_means_df)\n",
    "feature_mccv_permuted_score_means_df = (reduce(lambda  left,right: pd.merge(left,right,\n",
    "                                                                  on=['Feature','Model'],\n",
    "                                            how='outer'), feature_mccv_permuted_score_means_dfs))\n",
    "feature_mccv_permuted_score_means_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### permuted importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = [x for x in os.listdir(data_dir) if ( ('pkl' not in x) & \n",
    "                                             (type_ in x) & \n",
    "                                             ('patient' not in x) & \n",
    "                                             ('importance' in x) & \n",
    "                                             ('bootstrap' not in x) &\n",
    "                                             ('protein_prediction_metric' not in x) & \n",
    "                                             ('clinical_prediction_metric' not in x) &\n",
    "                                             ('prediction_metric' in x)\n",
    "                                            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(files)\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lsts=[]\n",
    "for file in files:\n",
    "    feature = (file.\n",
    "               replace(type_,'').\n",
    "               replace('_prediction_metric_permute_train_test_val'+\n",
    "                       '_feature_importances.csv',''))\n",
    "    if feature not in proteins_no_immunoglobulins:\n",
    "        continue\n",
    "    else:\n",
    "        feature_logit_df = (pd.\n",
    "                    read_csv(data_dir+file,index_col=0).\n",
    "                    rename(columns={'bootstrap' : 'Bootstrap','model' : 'Model'}).\n",
    "                    dropna())\n",
    "    lsts.append(feature_logit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_permuted_importance_odds_df = pd.concat(lsts)\n",
    "\n",
    "feature_mccv_permuted_importance_odds_df['odds'] = np.exp(feature_mccv_permuted_importance_odds_df['Importance'])\n",
    "\n",
    "feature_mccv_permuted_odds_df = (feature_mccv_permuted_importance_odds_df.\n",
    "                                 groupby(['Feature','Model'])['odds'].\n",
    "                                 describe(percentiles=[0.025,0.975]).\n",
    "                                 loc[:,['2.5%','mean','97.5%']].\n",
    "                                 rename(columns={'2.5%' : 'permuted_odds_lwr','mean' : 'permuted_odds_mean','97.5%' : 'permuted_odds_upr'}).\n",
    "                                 reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_permuted_odds_df.query('permuted_odds_lwr>1 | permuted_odds_upr<1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### significant performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "score = 'roc_auc'\n",
    "features = feature_mccv_permuted_scores_df[score].Feature.unique()\n",
    "ms = feature_mccv_permuted_scores_df[score].Model.unique()\n",
    "\n",
    "\n",
    "pvals = []\n",
    "for f in features:\n",
    "    for m in ms:\n",
    "        bdist = feature_mccv_scores_df[score].query('Model==@m & Feature==@f')[score].values\n",
    "        pdist = feature_mccv_permuted_scores_df[score].query('Model==@m & Feature==@f')[score].values\n",
    "        t,pval = ks_2samp(pdist,bdist)\n",
    "        pvals.append([f,m,t,pval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_performance_significance = pd.DataFrame(pvals,\n",
    "                                                     columns=\n",
    "                                                     ['Feature',\n",
    "                                                      'Model',\n",
    "                                                      'Performance_Statistic',\n",
    "                                                      'Performance_P_value']\n",
    "                                                    )\n",
    "\n",
    "feature_mccv_performance_significance['Performance_bonferroni'] = \\\n",
    "multipletests(feature_mccv_performance_significance.Performance_P_value.values,\n",
    "              method='bonferroni')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_performance_significance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### significant importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "score = 'roc_auc'\n",
    "features = feature_mccv_importance_odds_df.Feature.unique()\n",
    "ms = feature_mccv_permuted_importance_odds_df.Model.unique()\n",
    "\n",
    "pvals = []\n",
    "for f in features:\n",
    "    for m in ms:\n",
    "        f = f.replace('CVP_','CVP/')\n",
    "        bdist = feature_mccv_importance_odds_df.query('Model==@m & Feature==@f')['Importance'].values\n",
    "        pdist = feature_mccv_permuted_importance_odds_df.query('Model==@m & Feature==@f')['Importance'].values\n",
    "        t,pval = ks_2samp(pdist,bdist)\n",
    "        pvals.append([f,m,t,pval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_importance_significance = pd.DataFrame(pvals,columns=['Feature','Model','Importance_Statistic','Importance_P_value'])\n",
    "\n",
    "feature_mccv_importance_significance['Importance_bonferroni'] = multipletests(feature_mccv_importance_significance.Importance_P_value.values,method='bonferroni')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_importance_significance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### performance and importance correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "score = 'roc_auc'\n",
    "display(feature_mccv_scores_df[score].\n",
    "        set_index(['Feature','Bootstrap','Model'])[[score]].\n",
    "        head())\n",
    "\n",
    "display(feature_mccv_importance_odds_df.\n",
    "        set_index(['Feature','Bootstrap','Model'])[['odds']].\n",
    "        head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "score = 'roc_auc'\n",
    "performances_and_importances_df = (feature_mccv_scores_df[score].\n",
    "                                   set_index(['Feature','Bootstrap','Model'])[[score]].\n",
    "                                   join(\n",
    "                                       feature_mccv_importance_odds_df.\n",
    "                                       set_index(['Feature','Bootstrap','Model'])[['odds']])).reset_index()\n",
    "performances_and_importances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corr_df = (performances_and_importances_df.\n",
    "           dropna().\n",
    " groupby(['Feature','Model']).\n",
    " apply(lambda x : pearsonr(x.roc_auc,x.odds)[0])\n",
    ").reset_index().rename(columns={0 : 'Performance_Importance_Correlation'}).set_index(['Feature','Model'])\n",
    "\n",
    "corr_pvalue_df = (performances_and_importances_df.\n",
    "                  dropna().\n",
    "                  groupby(['Feature','Model']).\n",
    "                  apply(lambda x : pearsonr(x.roc_auc,x.odds)[1]).\n",
    "                  reset_index().rename(\n",
    "                      columns={0 : 'Performance_Importance_Correlation_P_value'}).\n",
    "                  set_index(['Feature','Model'])\n",
    "                 )\n",
    "\n",
    "corr_pvalue_df['Performance_Importance_Correlation_bonferroni'] = multipletests(corr_pvalue_df.Performance_Importance_Correlation_P_value,method='bonferroni')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "performances_and_importances_corr_df = corr_df.join(corr_pvalue_df).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "performances_and_importances_corr_df.sort_values('Performance_Importance_Correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### join mean performance, performance significance, importance significance, feature odds, and odds/performance correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mccv_performance_importance_correlation_significance_df = (\n",
    "    feature_mccv_score_means_df.set_index(['Feature','Model']).\n",
    "    join(\n",
    "        feature_mccv_odds_df.set_index(['Feature','Model'])\n",
    "    ).\n",
    "    join(\n",
    "        feature_mccv_permuted_odds_df.set_index(['Feature','Model'])\n",
    "    ).\n",
    "    join(\n",
    "        feature_mccv_performance_significance.set_index(['Feature','Model'])\n",
    "    ).\n",
    "    join( feature_mccv_importance_significance.set_index(['Feature','Model'])\n",
    "        ).\n",
    "    join(\n",
    "        performances_and_importances_corr_df.set_index(['Feature','Model'])\n",
    "    ).\n",
    "    reset_index()\n",
    ")\n",
    "mccv_performance_importance_correlation_significance_df.columns = [x.lower() for x in mccv_performance_importance_correlation_significance_df.columns]\n",
    "mccv_performance_importance_correlation_significance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### outputting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mccv_performance_importance_correlation_significance_df.sort_values('mean_validation_roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "protein_mccv_performance_importance_correlation_significance_df = \\\n",
    "(mccv_performance_importance_correlation_significance_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idmap_sub = pd.read_csv('../../data/protein_gene_map_full.csv')[['Protein','Gene_name']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "protein_mccv_performance_significance_and_feature_odds_df = \\\n",
    "(protein_mccv_performance_importance_correlation_significance_df.\n",
    " set_index('feature').\n",
    " join(\n",
    "     idmap_sub.set_index('Protein')\n",
    " ).reset_index()\n",
    ")\n",
    "protein_mccv_performance_significance_and_feature_odds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(protein_mccv_performance_significance_and_feature_odds_df.\n",
    " to_csv('../../data/protein_raw_01_within_notwithcohorts_mccv_performance_significance_and_feature_odds_df.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### plot protein and clinical markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clinical_mccv_performance_significance_and_feature_odds_df = \\\n",
    "pd.read_csv('../../data/clinical_01_within_notwithcohorts_mccv_performance_significance_and_feature_odds_df.csv',index_col=0)\n",
    "protein_mccv_performance_significance_and_feature_odds_df = \\\n",
    "pd.read_csv('../../data/protein_raw_01_within_notwithcohorts_mccv_performance_significance_and_feature_odds_df.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(clinical_mccv_performance_significance_and_feature_odds_df.shape)\n",
    "display(clinical_mccv_performance_significance_and_feature_odds_df.head())\n",
    "print(protein_mccv_performance_significance_and_feature_odds_df.shape)\n",
    "display(protein_mccv_performance_significance_and_feature_odds_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pcis = pd.read_csv('../../data/protein_raw_01_within_notwithcohorts_features_pgd_prediction_roc_auc_CIs.csv',index_col=0)\n",
    "ccis = pd.read_csv('../../data/clinical_01_within_notwithcohorts_features_pgd_prediction_roc_auc_CIs.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "protein_mccv_performance_significance_and_feature_odds_df = \\\n",
    "protein_mccv_performance_significance_and_feature_odds_df.set_index('feature').join(pcis).reset_index()\n",
    "clinical_mccv_performance_significance_and_feature_odds_df = \\\n",
    "clinical_mccv_performance_significance_and_feature_odds_df.set_index('feature').join(ccis).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fs = clinical_mccv_performance_significance_and_feature_odds_df.feature.str.replace('_Y','')\n",
    "fs = fs.str.replace('_',' ')\n",
    "clinical_mccv_performance_significance_and_feature_odds_df['original_feature'] = \\\n",
    "clinical_mccv_performance_significance_and_feature_odds_df.feature.values\n",
    "clinical_mccv_performance_significance_and_feature_odds_df.feature = fs\n",
    "clinical_mccv_performance_significance_and_feature_odds_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display(protein_mccv_performance_significance_and_feature_odds_df.head())\n",
    "protein_mccv_performance_significance_and_feature_odds_df['original_feature'] = \\\n",
    "protein_mccv_performance_significance_and_feature_odds_df.feature.values\n",
    "protein_mccv_performance_significance_and_feature_odds_df = \\\n",
    "(protein_mccv_performance_significance_and_feature_odds_df.\n",
    " drop('feature',axis=1).\n",
    " rename(columns={'Gene_name' : 'feature'}))\n",
    "print(protein_mccv_performance_significance_and_feature_odds_df.shape)\n",
    "print(protein_mccv_performance_significance_and_feature_odds_df.columns)\n",
    "display(protein_mccv_performance_significance_and_feature_odds_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clinical_mccv_performance_significance_and_feature_odds_df['Marker'] = 'Clinical'\n",
    "protein_mccv_performance_significance_and_feature_odds_df['Marker'] = 'Protein'\n",
    "data = pd.concat([\n",
    "    clinical_mccv_performance_significance_and_feature_odds_df.sort_values('odds_mean'),\n",
    "    protein_mccv_performance_significance_and_feature_odds_df.sort_values('odds_mean')],\n",
    "    sort=False).set_index('feature')\n",
    "display(data.shape)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.shape[0]-181"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query='mean_validation_roc_auc>0.5 &'+ \\\n",
    "           ' (odds_lwr>1 | odds_upr<1) & '+ \\\n",
    "           '(permuted_odds_lwr<1 & permuted_odds_upr>1) &'+ \\\n",
    "           'importance_bonferroni<0.001 & (importance_bonferroni>=importance_p_value)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(data.\n",
    " query(query).\n",
    " loc[:,['mean_validation_roc_auc',\n",
    "        'odds_lwr','odds_mean','odds_upr']].round(4).\n",
    " rename(columns={'mean_validation_roc_auc' : 'AUROC',\n",
    "                 'odds_lwr' : 'Odds lower bound',\n",
    "                 'odds_mean' : 'Odds average',\n",
    "                 'odds_upr' : 'Odds upper bound'}).\n",
    " sort_values('AUROC',ascending=False).\n",
    " to_csv('../../data/individual_clinical_and_protein_01_within_notwithcohorts_marker_performance_statistics.csv')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(data.query(query))\n",
    "data.query(query).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.index = [x.split(';')[0][:len(x.split(';')[0])-1]+' family' if len(x.split(';'))>2 else x for x in data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stat = 'odds_mean'\n",
    "score='-log10(importance_bonferroni)'\n",
    "plot_data = data.copy()\n",
    "plot_data.to_csv(dropbox_data+'all_individual_marker_01_within_notwithcohorts_prediction_results.csv')\n",
    "\n",
    "sig_markers = plot_data.query(query).index.values\n",
    "plot_data.loc[:,'Significance'] = 'Not-Significant'\n",
    "plot_data.loc[plot_data.index.isin(sig_markers),'Significance'] = 'Significant'\n",
    "plot_data['Marker_Color'] = plot_data['Marker'].map({'Clinical' : 'red','Protein' : 'blue'})\n",
    "plot_data['-log10(importance_bonferroni)'] = -np.log10(plot_data['importance_bonferroni'])\n",
    "plot_data.to_csv(dropbox_data+'individual_marker_01_within_notwithcohorts_prediction_results.csv')\n",
    "\n",
    "plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(plot_data.index.nunique())\n",
    "plot_data.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display((plot_data.\n",
    " query(query).\n",
    " sort_values('mean_validation_roc_auc',ascending=False).\n",
    " loc[:,['mean_validation_roc_auc','importance_bonferroni',\n",
    "       'odds_lwr','odds_mean','odds_upr']]\n",
    ").round(4))\n",
    "(plot_data.\n",
    " query(query).\n",
    " sort_values('mean_validation_roc_auc',ascending=False).\n",
    " loc[:,['mean_validation_roc_auc','importance_bonferroni',\n",
    "       'odds_lwr','odds_mean','odds_upr']]\n",
    ").round(4).to_csv(dropbox_data+'raw_01_within_notwithcohorts_significant_individual_markers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_data['odds_mean'] = np.log(plot_data['odds_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(dpi=dpi,figsize=(5,5))\n",
    "\n",
    "palette = 'RdBu_r'\n",
    "\n",
    "plot = plt.scatter(plot_data['odds_mean'].values,\n",
    "          plot_data['mean_validation_roc_auc'].values,\n",
    "          c=plot_data['-log10(importance_bonferroni)'].values,\n",
    "          cmap=palette)\n",
    "\n",
    "plt.clf()\n",
    "plt.colorbar(plot)\n",
    "\n",
    "ax = sns.scatterplot('odds_mean',\n",
    "                     'mean_validation_roc_auc',\n",
    "                     data=plot_data,\n",
    "                     hue='-log10(importance_bonferroni)',\n",
    "                     style='Marker',\n",
    "                     palette=palette,\n",
    "                     edgecolor='k'\n",
    "                    )\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_xlabel(r'$\\beta$ coefficient',size=20)\n",
    "ax.set_ylabel('AUROC',size=20)\n",
    "ax.legend_.remove()\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(dropbox_figures+'individual_clinical_and_protein_predictive_feature_odds_v_auroc_colored_by_significance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(plot_data.query(query).query('Marker==\"Protein\"').shape)\n",
    "print(plot_data.query(query).query('Marker==\"Clinical\"').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_data['odds_mean'] = np.exp(plot_data['odds_mean'])\n",
    "\n",
    "display((plot_data.\n",
    " query(query).\n",
    " sort_values('mean_validation_roc_auc',ascending=False).\n",
    " loc[:,['2.5%','mean_validation_roc_auc','97.5%','importance_bonferroni',\n",
    "       'odds_lwr','odds_mean','odds_upr']]\n",
    ").round(4))\n",
    "tmp = (plot_data.\n",
    " query(query))\n",
    "tmp['importance_bonferroni'] = \\\n",
    "[np.format_float_scientific(x,\n",
    "                            unique=False,\n",
    "                            precision=4)\n",
    "      for x in tmp['importance_bonferroni']]\n",
    "(tmp.\n",
    " sort_values('mean_validation_roc_auc',ascending=False).\n",
    " loc[:,['2.5%','mean_validation_roc_auc','97.5%','importance_bonferroni',\n",
    "       'odds_lwr','odds_mean','odds_upr']]\n",
    ").round(4).to_csv(dropbox_data+'raw_01_within_notwithcohorts_significant_individual_markers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "significant auroc/importance difference between protein and clinical markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = plot_data[plot_data.Marker=='Protein']['mean_validation_roc_auc'].values\n",
    "b = plot_data[plot_data.Marker=='Clinical']['mean_validation_roc_auc'].values\n",
    "print(ttest_ind(a,b))\n",
    "print((np.mean(a), np.std(a)))\n",
    "print((np.mean(b), np.std(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = plot_data[plot_data.Marker=='Protein']['odds_mean'].values\n",
    "b = plot_data[plot_data.Marker=='Clinical']['odds_mean'].values\n",
    "print(ttest_ind(a,b))\n",
    "print(mean_and_std(a))\n",
    "print(mean_and_std(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUROC<0.5 checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "data_dir='../../data/integrated_pgd_predictions/'\n",
    "scores = ['roc_auc']\n",
    "scorers = { 'roc_auc' : roc_auc_score}\n",
    "type_='clinical_01_within_notwithcohorts_features_pgd_prediction_'\n",
    "files = [x for x in os.listdir(data_dir) if ( ('pkl' not in x) & \n",
    "                                             (type_ in x) & \n",
    "                                             ('patient' in x) & \n",
    "                                             ('importance' not in x) & \n",
    "                                             ('bootstrap' in x) &\n",
    "                                             ('protein_prediction_metric' not in x) & \n",
    "                                             ('clinical_prediction_metric' not in x) &\n",
    "                                             ('prediction_metric' in x)\n",
    "                                            )\n",
    "        ]\n",
    "clinical_features = []\n",
    "for score,scorer in scorers.items():\n",
    "    feature_scores_bootstraps = []\n",
    "    for file in files:\n",
    "        feature = (file.\n",
    "                   replace(type_,'').\n",
    "                   replace('_prediction_metric_bootstrap_train_test_val'+\n",
    "                           '_patient_level_data.csv','').\n",
    "                   replace('CVP_','CVP/')\n",
    "                  )\n",
    "        dat = pd.read_csv(data_dir+file,index_col=0)\n",
    "        dat['Feature'] = feature\n",
    "        clinical_features.append(dat)\n",
    "cpreds = pd.concat(clinical_features)\n",
    "type_='protein_raw_01_within_notwithcohorts_features_pgd_prediction_'\n",
    "files = [x for x in os.listdir(data_dir) if ( ('pkl' not in x) & \n",
    "                                             (type_ in x) & \n",
    "                                             ('patient' in x) & \n",
    "                                             ('importance' not in x) & \n",
    "                                             ('bootstrap' in x) &\n",
    "                                             ('protein_prediction_metric' not in x) & \n",
    "                                             ('clinical_prediction_metric' not in x) &\n",
    "                                             ('prediction_metric' in x)\n",
    "                                            )\n",
    "        ]\n",
    "protein_features = []\n",
    "for score,scorer in scorers.items():\n",
    "    feature_scores_bootstraps = []\n",
    "    for file in files:\n",
    "        feature = (file.\n",
    "                   replace(type_,'').\n",
    "                   replace('_prediction_metric_bootstrap_train_test_val'+\n",
    "                           '_patient_level_data.csv','').\n",
    "                   replace('CVP_','CVP/')\n",
    "                  )\n",
    "        dat = pd.read_csv(data_dir+file,index_col=0)\n",
    "        dat['Feature'] = feature\n",
    "        protein_features.append(dat)\n",
    "ppreds = pd.concat(protein_features)\n",
    "cppreds = pd.concat([ppreds,cpreds]).sort_values(['bootstrap','Feature']).set_index('Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_mccv_performance_significance_and_feature_odds_df = \\\n",
    "pd.read_csv('../../data/clinical_01_within_notwithcohorts_mccv_performance_significance_and_feature_odds_df.csv',index_col=0)\n",
    "protein_mccv_performance_significance_and_feature_odds_df = \\\n",
    "pd.read_csv('../../data/protein_raw_01_within_notwithcohorts_mccv_performance_significance_and_feature_odds_df.csv',index_col=0)\n",
    "data = pd.concat([\n",
    "    clinical_mccv_performance_significance_and_feature_odds_df.sort_values('odds_mean'),\n",
    "    protein_mccv_performance_significance_and_feature_odds_df.sort_values('odds_mean')],\n",
    "    sort=False).set_index('feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values('mean_validation_roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp = (cppreds.\n",
    " groupby(['Feature','y_true'])['y_proba'].\n",
    " mean().\n",
    " reset_index().\n",
    " pivot_table(index=['Feature'],columns='y_true',values='y_proba').\n",
    " rename(columns={0 : 'control',1 : 'case'}).\n",
    "       join(data[['mean_validation_roc_auc','odds_mean']])\n",
    "      )\n",
    "tmp['AUROC>0.5'] = (tmp['mean_validation_roc_auc']>.5)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.regplot('control','mean_validation_roc_auc',data=tmp,label='non-PGD',ax=ax)\n",
    "sns.regplot('case','mean_validation_roc_auc',data=tmp,label='PGD',ax=ax)\n",
    "ax.legend()\n",
    "ax.set_xlabel('Average validation probabilities')\n",
    "ax.set_ylabel('Panel AUROC')\n",
    "fig.tight_layout()\n",
    "fig.savefig('../../docs/imgs/AUROC>0.5_figure_1.png')\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "plot = plt.scatter(tmp['control'],tmp['case'],c=tmp['mean_validation_roc_auc'], \n",
    "                   cmap = 'viridis',linewidth=.2,edgecolor='black')\n",
    "plt.colorbar(plot)\n",
    "ax.set_xlabel('Average non-PGD patient validation probabilities')\n",
    "ax.set_ylabel('Average PGD patient probabilities')\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'r--', alpha=0.75, zorder=0)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "fig.tight_layout()\n",
    "fig.savefig('../../docs/imgs/AUROC>0.5_figure_2.png')\n",
    "\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.stripplot('variable','value',hue='AUROC>0.5',\n",
    "             data=tmp.reset_index().melt(id_vars=['Feature','mean_validation_roc_auc','odds_mean','AUROC>0.5']),\n",
    "             linewidth=.2,edgecolor='black',size=5)\n",
    "ax.set_ylabel('Average validation probability')\n",
    "ax.set_xlabel('Patient type')\n",
    "co = tmp[tmp.mean_validation_roc_auc>.5].control.values\n",
    "ca = tmp[tmp.mean_validation_roc_auc>.5].case.values\n",
    "print(np.mean(co))\n",
    "print(np.mean(ca))\n",
    "mannwhitneyu(co,ca)\n",
    "fig.tight_layout()\n",
    "fig.savefig('../../docs/imgs/AUROC>0.5_figure_3.png')\n",
    "\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "from pylab import *\n",
    "plot = plt.scatter(tmp['control'],tmp['case'],c=tmp['AUROC>0.5'], \n",
    "                   cmap = cm.get_cmap('PiYG', 2),linewidth=.2,edgecolor='black')\n",
    "plt.colorbar(plot)\n",
    "ax.set_xlabel('Average non-PGD patient validation probabilities')\n",
    "ax.set_ylabel('Average PGD patient probabilities')\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'r--', alpha=0.75, zorder=0)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "fig.tight_layout()\n",
    "fig.savefig('../../docs/imgs/AUROC>0.5_figure_4.png')\n",
    "\n",
    "a = cppreds.groupby(['Feature','bootstrap'])['y_true'].sum().values\n",
    "b = cppreds.query('y_true==1').groupby(['Feature','bootstrap'])['y_proba'].mean().values\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.regplot(a,b,ax=ax)\n",
    "ax.set_xlabel('Number of PGD patients in validation')\n",
    "ax.set_ylabel('Average PGD patient validation probabilities')\n",
    "fig.tight_layout()\n",
    "fig.savefig('../../docs/imgs/AUROC>0.5_figure_5.png')\n",
    "tmp['diff'] = tmp['case'] - tmp['control']\n",
    "a = tmp['diff'].values\n",
    "b = tmp['mean_validation_roc_auc'].values\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.regplot(a,b,ax=ax)\n",
    "ax.set_xlabel('Difference in the means of case and control validation probabilities')\n",
    "ax.set_ylabel('AUROC')\n",
    "fig.tight_layout()\n",
    "fig.savefig('../../docs/imgs/AUROC>0.5_figure_6.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Individual marker comparison with and without cohort covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = pd.read_csv(\n",
    "    dropbox_data+'all_individual_marker_01_within_prediction_results.csv'\n",
    ")\n",
    "m_wcohortcovs = pd.read_csv(\n",
    "    dropbox_data+'all_individual_marker_01_within_notwithcohorts_prediction_results.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=dpi)\n",
    "sns.scatterplot(m['mean_validation_roc_auc'],\n",
    "                m_wcohortcovs['mean_validation_roc_auc'],\n",
    "                edgecolor='black',color='lightgray',lw=.3)\n",
    "ax.set_ylabel('With covariate adjustment',size=16)\n",
    "ax.set_xlabel('Without covariate adjustment',size=16)\n",
    "\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'r--', alpha=0.75, zorder=0)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "fig.savefig(dropbox_figures+'effect_of_covariate_adjustment_on_individual_markers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(m['mean_validation_roc_auc'], m_wcohortcovs['mean_validation_roc_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Two marker panel prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dir_ = '../../data/'\n",
    "cohort = 'integrated'\n",
    "\n",
    "X_all_proteins = pd.read_csv(dir_+cohort+'_X_raw_all_proteins.csv',index_col=0)\n",
    "proteins_no_immunoglobulins = pickle.load(open('../../data/proteins_no_immunoglobulins.pkl','rb'))\n",
    "X_all_proteins = X_all_proteins.loc[:,proteins_no_immunoglobulins]\n",
    "\n",
    "X_all_clinical = pd.read_csv(dir_+cohort+'_X_clinical_and_cohort_covariates.csv',index_col=0)\n",
    "Y = pd.read_csv(dir_+cohort+'_pgd_y.csv',index_col=0,header=None)\n",
    "\n",
    "query='mean_validation_roc_auc>0.5 &'+ \\\n",
    "           ' (odds_lwr>1 | odds_upr<1) & '+ \\\n",
    "           '(permuted_odds_lwr<1 & permuted_odds_upr>1) &'+ \\\n",
    "           'importance_bonferroni<0.001 & (importance_bonferroni>=importance_p_value)'\n",
    "predictive_proteins =  \\\n",
    "(pd.\n",
    " read_csv('../../data/protein_raw_01_within_notwithcohorts_mccv_performance_significance_and_feature_odds_df.csv',\n",
    "          index_col=0).\n",
    " query(query).\n",
    " feature.\n",
    " unique()\n",
    ")\n",
    "predictive_clinicals =  \\\n",
    "(pd.\n",
    " read_csv('../../data/clinical_01_within_notwithcohorts_mccv_performance_significance_and_feature_odds_df.csv',\n",
    "          index_col=0).\n",
    " query(query).\n",
    " feature.\n",
    " unique()\n",
    ")\n",
    "\n",
    "umarkers = np.union1d(predictive_proteins,predictive_clinicals)\n",
    "len(umarkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def pperf_dat_processing(dat='',set_=0,n=50,scorer=roc_auc_score):\n",
    "        lsts = []\n",
    "        for b in range(n):\n",
    "            lsts.append(\n",
    "                (dat.\n",
    "                 sample(n=dat.shape[0],replace=True,random_state=b).\n",
    "                 groupby('cohort').\n",
    "                 apply(\n",
    "                     lambda x : scorer(x.y_true,x.y_proba)\n",
    "                 )\n",
    "                )\n",
    "            )\n",
    "\n",
    "        vals = []\n",
    "        for b in range(n):\n",
    "            x = (dat.\n",
    "                 sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "                )\n",
    "            vals.append(scorer(x.y_true,x.y_proba))\n",
    "\n",
    "        tmp = \\\n",
    "        pd.concat([\n",
    "            (pd.concat(lsts,1).\n",
    "             T.\n",
    "             describe(percentiles=[0.025,0.975]).\n",
    "             loc[['2.5%','mean','97.5%']].\n",
    "             T.\n",
    "             reset_index()\n",
    "            ),\n",
    "            (pd.\n",
    "             DataFrame(vals,\n",
    "                       columns=['Integrated']).\n",
    "             describe(percentiles=[0.025,0.975]).\n",
    "             loc[['2.5%','mean','97.5%']].\n",
    "             T.\n",
    "             reset_index().\n",
    "             rename(columns={ 'index' : 'cohort'})\n",
    "            )\n",
    "        ])\n",
    "        tmp['set'] = set_\n",
    "        return tmp\n",
    "\n",
    "def pperf_processing(pperf_df='',n_jobs=4,params={}):\n",
    "    tmps = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(pperf_dat_processing)(\n",
    "            dat,set_,**params) for \n",
    "        set_,dat in pperf_df.groupby('set'))\n",
    "    return pd.concat(tmps,sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "basename = '../../data/integrated_pgd_predictions/'+\\\n",
    "'raw_01_within_notwithcohorts_clinicalclinical_proteinclinical_proteinprotein_and_clinical_and_protein_features_small_combos_pgd_prediction_'\n",
    "feature_set = pickle.load(open(basename+'feature_set_dictionary.pkl','rb'))\n",
    "print(len(feature_set.items()))\n",
    "sets_to_use = [k for \n",
    " k,v in feature_set.items() if len(np.setdiff1d(v,umarkers))==0]\n",
    "print(len(sets_to_use))\n",
    "features_not_to_see = [x for x in X_all_clinical.columns if 'Cohort_' in x]\n",
    "features_not_to_see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(umarkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_pperf_df = pd.read_csv(basename+'agg_patient_level_data.csv',index_col=0).query('set in @sets_to_use')\n",
    "all_pperf_processed_df = pperf_processing(all_pperf_df,\n",
    "                                          params={'scorer' : roc_auc_score})\n",
    "all_pperf_processed_df.to_csv(basename+'agg_processed_roc_auc_patient_level_data.csv')\n",
    "pperf_df = all_pperf_processed_df.query('cohort==\"Integrated\"').drop('cohort',1)\n",
    "display(pperf_df.shape)\n",
    "display(pperf_df.head())\n",
    "\n",
    "all_perm_pperf_df = pd.read_csv(basename+'agg_permuted_patient_level_data.csv',index_col=0).query('set in @sets_to_use')\n",
    "all_perm_pperf_processed_df = pperf_processing(all_perm_pperf_df,\n",
    "                                               params={'scorer' : roc_auc_score})\n",
    "all_perm_pperf_processed_df.to_csv(basename+'agg_permuted_processed_roc_auc_patient_level_data.csv')\n",
    "perm_pperf_df = all_perm_pperf_processed_df.query('cohort==\"Integrated\"').drop('cohort',1)\n",
    "display(perm_pperf_df.shape)\n",
    "display(perm_pperf_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_pperf_df = pd.read_csv(basename+'agg_patient_level_data.csv',index_col=0).query('set in @sets_to_use')\n",
    "perf_df = pd.read_csv(basename+'agg_performance.csv',index_col=0).query('set in @sets_to_use')\n",
    "display(perf_df.head())\n",
    "all_perm_pperf_df = pd.read_csv(basename+'agg_permuted_patient_level_data.csv',index_col=0).query('set in @sets_to_use')\n",
    "perm_perf_df = pd.read_csv(basename+'agg_permuted_performance.csv',index_col=0).query('set in @sets_to_use')\n",
    "display(perm_perf_df.head())\n",
    "all_pperf_processed_df = pd.read_csv(basename+'agg_processed_roc_auc_patient_level_data.csv',index_col=0).query('set in @sets_to_use')\n",
    "pperf_df = all_pperf_processed_df.query('cohort==\"Integrated\"').drop('cohort',1)\n",
    "display(pperf_df.head())\n",
    "fimps_df = (pd.\n",
    "            read_csv(basename+'agg_feature_importances.csv',\n",
    "                     index_col=0).\n",
    "            query('Feature!=\"Intercept\"').\n",
    "            query('Feature not in @features_not_to_see').\n",
    "            query('set in @sets_to_use')\n",
    "           )\n",
    "\n",
    "fimps_df['Marker'] = 'N/A'\n",
    "fimps_df['Marker'][fimps_df.Feature.isin(X_all_proteins.columns)] = 'Protein'\n",
    "fimps_df['Marker'][fimps_df.Feature.isin(X_all_clinical.columns)] = 'Clinical'\n",
    "\n",
    "display(fimps_df.head())\n",
    "perm_fimps_df = (pd.\n",
    "                 read_csv(basename+'agg_permuted_feature_importances.csv',\n",
    "                          index_col=0).\n",
    "                 query('Feature!=\"Intercept\"').\n",
    "            query('Feature not in @features_not_to_see').\n",
    "                 query('set in @sets_to_use')\n",
    "                )\n",
    "display(perm_fimps_df.head())\n",
    "all_perm_pperf_processed_df = pd.read_csv(basename+'agg_permuted_processed_roc_auc_patient_level_data.csv',index_col=0).query('set in @sets_to_use')\n",
    "perm_pperf_df = all_perm_pperf_processed_df.query('cohort==\"Integrated\"').drop('cohort',1)\n",
    "display(perm_pperf_df.head())\n",
    "\n",
    "p_c_color_dict = {'Clinical-Clinical' : '#CC3311', #brown \n",
    "            'Clinical-Protein' : '#0077BB', #blue\n",
    "                  'Protein-Clinical' : '#0077BB', #blue\n",
    "            'Protein-Protein' : '#CCBB44' #yellow\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = (all_pperf_df.\n",
    " groupby(['set','y_true'])['y_proba'].\n",
    " mean().\n",
    " reset_index().\n",
    " pivot_table(index=['set'],columns='y_true',values='y_proba').\n",
    " rename(columns={0 : 'control',1 : 'case'})\n",
    ").join(pperf_df.set_index('set')\n",
    "      )\n",
    "fig,ax=plt.subplots(dpi=100)\n",
    "sns.regplot('control','mean',data=tmp,label='non-PGD',ax=ax)\n",
    "sns.regplot('case','mean',data=tmp,label='PGD',ax=ax)\n",
    "ax.legend()\n",
    "ax.set_xlabel('Average validation probabilities')\n",
    "ax.set_ylabel('Panel AUROC')\n",
    "fig,ax=plt.subplots(dpi=100)\n",
    "plot = plt.scatter(tmp['control'],tmp['case'],c=tmp['mean'], cmap = 'viridis')\n",
    "plt.colorbar(plot)\n",
    "ax.set_xlabel('Average non-PGD patient validation probabilities')\n",
    "ax.set_ylabel('Average PGD patient probabilities')\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'r--', alpha=0.75, zorder=0)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Attribute significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as sm\n",
    "allpvalues=[]\n",
    "sets  = [x for x in feature_set.keys() if x in sets_to_use]\n",
    "print(len(sets))\n",
    "for set_ in sets:\n",
    "    fs = feature_set[str(set_)]\n",
    "\n",
    "    best_params = (all_pperf_df.\n",
    "                   query('set==@set_')['y_proba'].\n",
    "                   values)\n",
    "    perm_params = (all_perm_pperf_df.\n",
    "                   query('set==@set_')['y_proba'].\n",
    "                   values)\n",
    "\n",
    "    try:\n",
    "        stat,pval = sm.ks_2samp(best_params,perm_params)\n",
    "        allpvalues.append(pval)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "source": [
    "import scipy.stats as sm\n",
    "allpvalues=[]\n",
    "sets  = [x for x in feature_set.keys()]\n",
    "for set_ in sets:\n",
    "    fs = feature_set[set_]\n",
    "\n",
    "    best_params = (fimps_df.\n",
    "                   query('Feature!=\"Intercept\"').\n",
    "                   query('set==@set_')['mean'].\n",
    "                   values)\n",
    "    perm_params = (perm_fimps_df.\n",
    "                   query('Feature!=\"Intercept\"').\n",
    "                   query('set==@set_')['mean'].\n",
    "                   values)\n",
    "\n",
    "    X_cohort = X_all_proteins.join(X_all_clinical)[fs]\n",
    "    Y_cohort = Y.copy()\n",
    "    best_ps = predict_probability(X_cohort.values,best_params)\n",
    "    perm_ps = predict_probability(X_cohort.values,perm_params)\n",
    "\n",
    "    stat,pval = sm.ks_2samp(best_ps,perm_ps)\n",
    "    allpvalues.append(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "bonfs = multipletests(allpvalues,method='bonferroni')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "set_sig_df = pd.DataFrame([\n",
    "    sets,\n",
    "    allpvalues,\n",
    "    bonfs],\n",
    "    index=['set','pvalue','bonferroni']).T\n",
    "print(set_sig_df.shape)\n",
    "set_sig_df['set'] = set_sig_df['set'].astype(int)\n",
    "set_sig_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perf_sig_df = pperf_df.set_index('set').join(set_sig_df.set_index('set')).reset_index()\n",
    "perf_sig_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "alpha=0.05\n",
    "bonf_thresh = (alpha / len(perf_sig_df['set'].values))\n",
    "print(bonf_thresh)\n",
    "print(perf_sig_df.shape)\n",
    "print(perf_sig_df.query('bonferroni>=pvalue & bonferroni<@bonf_thresh').shape)\n",
    "not_sig_set = perf_sig_df.query('bonferroni<=@bonf_thresh').set.values\n",
    "sig_sets = perf_sig_df.query('bonferroni>=pvalue & bonferroni<@bonf_thresh').set.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perf_sig_df.to_csv(basename+'_01_within_notwithcohorts_set_significant_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fimps_sigs_df = fimps_df[fimps_df['set'].isin(sig_sets)]\n",
    "fimps_sigs_df = fimps_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Marker pairwise prediction heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fimps_spread_1 = \\\n",
    "(fimps_sigs_df.\n",
    " query('Feature!=\"Intercept\"').\n",
    " loc[:,['set','Feature']].\n",
    " rename(columns={'Feature' : 'Feature1'}).\n",
    " drop_duplicates().\n",
    " groupby('set').\n",
    " nth(0).\n",
    " join(\n",
    "     fimps_sigs_df.\n",
    "     query('Feature!=\"Intercept\"').\n",
    "     loc[:,['set','Feature']].\n",
    "     drop_duplicates().\n",
    "     rename(columns={'Feature' : 'Feature2'}).\n",
    "     groupby('set').\n",
    "     nth(1)\n",
    " )\n",
    ")\n",
    "print(fimps_spread_1.shape)\n",
    "display(fimps_spread_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fimps_spread_2 = \\\n",
    "(fimps_spread_1.\n",
    " loc[:,['Feature2','Feature1']].\n",
    " rename(columns={'Feature1' :'Feature2','Feature2' : 'Feature1'}\n",
    "       )\n",
    ")\n",
    "fimps_spread = pd.concat([fimps_spread_1,fimps_spread_2])\n",
    "print(fimps_spread.shape)\n",
    "display(fimps_spread.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f1=\"H0YAC1\"\n",
    "f2=\"Prior_Inotrope_Y\"\n",
    "display(fimps_spread.query('Feature1==@f1 & Feature2==@f2'))\n",
    "fimps_spread.query('Feature1==@f2 & Feature2==@f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perf_fimps_join = \\\n",
    "(pperf_df.\n",
    " reset_index().\n",
    " loc[:,['set','mean']].\n",
    " rename(columns={'mean' : 'mean_auroc'}).\n",
    " drop_duplicates().\n",
    " set_index('set').\n",
    " join(\n",
    "     fimps_spread\n",
    " ).\n",
    " reset_index().\n",
    " pivot_table(index='Feature1',columns='Feature2',values='mean_auroc')\n",
    ")\n",
    "print(perf_fimps_join.shape)\n",
    "display(perf_fimps_join.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "col_sorted_features = perf_fimps_join.mean(0).sort_values(ascending=True).index.values\n",
    "row_sorted_features = perf_fimps_join.mean(1).sort_values(ascending=True).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_data = perf_fimps_join.loc[col_sorted_features,row_sorted_features]\n",
    "display(plot_data.head())\n",
    "plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "minpt = perf_df['mean'].min()\n",
    "maxpt = perf_df['mean'].max()\n",
    "midpt = perf_df['mean'].max() - ((perf_df['mean'].max() - perf_df['mean'].min())/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mask = np.zeros_like(plot_data, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=200,figsize=(30,30))\n",
    "sns.heatmap(\n",
    "    plot_data,\n",
    "    mask=mask,\n",
    "    square=True,\n",
    "    vmin=minpt,\n",
    "    vmax=maxpt,\n",
    "    center=midpt, \n",
    "    cmap='RdBu_r',\n",
    "    cbar_kws={\"orientation\": \"horizontal\"},\n",
    "    ax=ax)\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlabel('')\n",
    "ax.set_xticklabels('')\n",
    "ax.set_yticklabels('')\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=70)\n",
    "fig.savefig(dropbox_figures+'two_marker_panel_predictions_marker_combo_performance_hearmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Marker marker type and performance of clinical-clinical, protein-clinical, and protein-protein markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pairwise_sets = (fimps_sigs_df.groupby('set')['Feature'].count()>2).index.values\n",
    "len(pairwise_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = fimps_sigs_df[fimps_sigs_df['set'].isin(pairwise_sets)]\n",
    "cs = tmp.query('Marker==\"Clinical\"').Feature.unique()\n",
    "ps = tmp.query('Marker==\"Protein\"').Feature.unique()\n",
    "c_c_scores=[]\n",
    "for c1 in cs:\n",
    "    for c2 in cs:\n",
    "        if c1!=c2:\n",
    "            setsc1 = tmp.query('Feature==@c1').set.unique()\n",
    "            setsc2 = tmp.query('Feature==@c2').set.unique()\n",
    "            set_ = np.intersect1d(setsc1,setsc2)\n",
    "            if len(set_)>0:\n",
    "                c_c_scores.append(pperf_df.query('set in @set_')['mean'].tolist()[0])\n",
    "p_c_scores=[]\n",
    "for p in ps:\n",
    "    for c in cs:\n",
    "        if p!=c:\n",
    "            setsp = tmp.query('Feature==@p').set.unique()\n",
    "            setsc = tmp.query('Feature==@c').set.unique()\n",
    "            set_ = np.intersect1d(setsp,setsc)\n",
    "            if len(set_)>0:\n",
    "                p_c_scores.append(pperf_df.query('set in @set_')['mean'].tolist()[0])\n",
    "p_p_scores=[]\n",
    "for p1 in ps:\n",
    "    for p2 in ps:\n",
    "        if p1!=p2:\n",
    "            setsp1 = tmp.query('Feature==@p1').set.unique()\n",
    "            setsp2 = tmp.query('Feature==@p2').set.unique()\n",
    "            set_ = np.intersect1d(setsp1,setsp2)\n",
    "            if len(set_)>0:\n",
    "                p_p_scores.append(pperf_df.query('set in @set_')['mean'].tolist()[0])\n",
    "\n",
    "p_c_dict = {\n",
    "    #'Clinical-Clinical' : c_c_scores, \n",
    "            'Clinical-Protein' : p_c_scores, \n",
    "            'Protein-Protein' : p_p_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=dpi)\n",
    "tmp = \\\n",
    "(pd.\n",
    " DataFrame(\n",
    "     dict([ (k,pd.Series(v)) for k,v in p_c_dict.items() ])\n",
    " )\n",
    ")\n",
    "sns.boxplot('variable','value',data=tmp.melt(),\n",
    "              ax=ax,palette=p_c_color_dict,fliersize=0)\n",
    "sns.stripplot('variable','value',\n",
    "              data=tmp.melt(),ax=ax,\n",
    "              size=4,palette=p_c_color_dict,\n",
    "              edgecolor='black',linewidth=.5,\n",
    "             jitter=True)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylim(0.4,0.8)\n",
    "ax.set_ylabel('AUROC',size=16)\n",
    "ax.set_xticklabels([x.get_text()+'\\npanels' for x in ax.get_xticklabels()],rotation=20,size=16)\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'two_marker_panel_predictions_marker_type_combo_performances.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "a = tmp['Clinical-Clinical'].dropna().values\n",
    "b = tmp['Clinical-Protein'].dropna().values\n",
    "print(ttest_ind(a,b))\n",
    "\n",
    "a = tmp['Clinical-Clinical'].dropna().values\n",
    "b = tmp['Protein-Protein'].dropna().values\n",
    "print(ttest_ind(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a = tmp['Clinical-Protein'].dropna().values\n",
    "b = tmp['Protein-Protein'].dropna().values\n",
    "print(ttest_ind(a,b))\n",
    "print(np.mean(a), np.std(a))\n",
    "print(np.mean(b), np.std(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Marker marker type and performance of combos with particular protein characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sets = pperf_df.sort_values('mean',ascending=False).set.unique()\n",
    "anchor_proteins = (fimps_sigs_df.\n",
    "                   query('set in @sets').\n",
    "                   query('Marker==\"Protein\"').\n",
    "                   query('Feature!=\"Intercept\"').\n",
    "                   sort_values('Feature',ascending=False).\n",
    "                   Feature.unique()\n",
    "                  )\n",
    "scores_w_p = {}\n",
    "for p in anchor_proteins:\n",
    "    sets = fimps_sigs_df.query('Feature==@p').set.unique()\n",
    "    scores = []\n",
    "    for s in sets:\n",
    "        scores.append(pperf_df.query('set==@s')['mean'].tolist())\n",
    "    scores_w_p[p] = list(itertools.chain(*scores))\n",
    "    \n",
    "fig,ax=plt.subplots(dpi=dpi,figsize=(15,3))\n",
    "tmp = \\\n",
    "(pd.\n",
    " DataFrame.\n",
    " from_dict(scores_w_p, orient='index').\n",
    " T\n",
    ")\n",
    "\n",
    "protein_order = tmp.mean(0).sort_values(ascending=True).index.values\n",
    "map_ = pd.read_csv('../../data/protein_gene_map_full.csv')[['Protein','Gene_name']]\n",
    "gene_order=[]\n",
    "for po in protein_order:\n",
    "    gene_order.append(map_[map_.Protein==po].Gene_name.values[0])\n",
    "\n",
    "sns.boxplot('variable','value',\n",
    "              data=tmp.melt(),order=protein_order,\n",
    "              ax=ax,color='lightgray',fliersize=0)\n",
    "sns.stripplot('variable','value',\n",
    "              data=tmp.melt(),order=protein_order,\n",
    "              ax=ax,\n",
    "              color='black',size=2,\n",
    "              edgecolor='black',linewidth=.5,\n",
    "             jitter=True)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylim(0.45,0.75)\n",
    "ax.set_ylabel('AUROC',size=16)\n",
    "ax.set_xticklabels(gene_order)\n",
    "ax.set_xticklabels([x.get_text() if len(x.get_text().split(';'))==1 \n",
    "                    else (\n",
    "                        ''+x.get_text().split(';')[0][:len(x.get_text().split(';')[0])-1]+\n",
    "                        '\\nfamily' \n",
    "                        if len(x.get_text().split(';'))>3 \n",
    "                        else ';\\n'.join(x.get_text().split(';')))\n",
    "                    for x in ax.get_xticklabels()],\n",
    "                   rotation=20,size=16)\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'two_marker_panel_predictions_protein_combo_performance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c1 = 'H0YAC1'\n",
    "for c2 in tmp.columns:\n",
    "    print('\\t'+c2)\n",
    "    a = tmp[c1].dropna().values\n",
    "    b = tmp[c2].dropna().values\n",
    "    print('\\t',ttest_ind(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Marker marker type and performance of combos with particular clinical characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fimps_sigs_df['Marker'] = 'N/A'\n",
    "fimps_sigs_df['Marker'][fimps_sigs_df.Feature.isin(X_all_proteins.columns)] = 'Protein'\n",
    "fimps_sigs_df['Marker'][fimps_sigs_df.Feature.isin(X_all_clinical.columns)] = 'Clinical'\n",
    "cs = fimps_sigs_df.query('Marker==\"Clinical\"').Feature.unique()\n",
    "scores_w_c = {}\n",
    "for c in cs:\n",
    "    sets = fimps_sigs_df.query('Feature==@c').set.unique()\n",
    "    scores = []\n",
    "    for s in sets:\n",
    "        scores.append(pperf_df.query('set==@s')['mean'].tolist())\n",
    "    scores_w_c[c] = list(itertools.chain(*scores))\n",
    "    \n",
    "fig,ax=plt.subplots(dpi=dpi,figsize=(2,3))\n",
    "tmp = \\\n",
    "(pd.\n",
    " DataFrame(\n",
    "     dict([ (k,pd.Series(v)) for k,v in scores_w_c.items() ])\n",
    " )\n",
    ")\n",
    "fs = tmp.columns.str.replace('_Y','')\n",
    "fs = fs.str.replace('_',' ')\n",
    "tmp.columns = fs\n",
    "\n",
    "x  = 'variable'\n",
    "y = 'value'\n",
    "\n",
    "sns.boxplot(x,y,data=tmp.melt(),\n",
    "              ax=ax,color='lightgray',fliersize=0)\n",
    "sns.stripplot(x,y,\n",
    "              data=tmp.melt(),ax=ax,\n",
    "              color='black',size=5,\n",
    "              edgecolor='black',linewidth=.5,\n",
    "             jitter=True)\n",
    "arr = tmp.melt()['value'].values\n",
    "arr = np.round(np.arange(0.60,0.74,.02),2)\n",
    "ax.set_yticklabels(arr,size=10)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.set_xticklabels('')\n",
    "#ax.set_ylim(0.45,0.75)\n",
    "#ax.set_xlabel('AUROC',size=16)\n",
    "#ax.set_xticklabels([x.get_text() for x in ax.get_xticklabels()],rotation=20,size=16)\n",
    "#ax.set_xticklabels([x.get_text() if x.get_text()!='Mechanical Support' else 'Mechanical\\nSupport' for x in ax.get_xticklabels()])\n",
    "#ax.set_xticklabels([x.get_text() if x.get_text()!='Beta Blocker' else 'Beta\\nBlocker' for x in ax.get_xticklabels()])\n",
    "#ax.set_xticklabels([x.get_text() if x.get_text()!='Prior Inotrope' else 'Inotrope\\ntherapy' for x in ax.get_xticklabels()])\n",
    "#ax.set_xticklabels([x.get_text() if x.get_text()!='Antiarrhythmic Use' else 'Antiarrhythmic\\nuse' for x in ax.get_xticklabels()])\n",
    "#ax.set_xticklabels([x.get_text() if x.get_text()!='Blood Type O' else 'Blood\\nType O' for x in ax.get_xticklabels()])\n",
    "#ax.set_xticklabels([x.get_text() if x.get_text()!='Ischemic Time' else 'Ischemic\\ntime' for x in ax.get_xticklabels()])\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'two_marker_panel_predictions_clinical_combo_performances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for c1 in tmp.columns.values:\n",
    "    print(c1)\n",
    "    for c2 in tmp.columns.values:\n",
    "        if c1!=c2:\n",
    "            print('\\t'+c2)\n",
    "            a = tmp[c1].dropna().values\n",
    "            b = tmp[c2].dropna().values\n",
    "            print('\\t',ttest_ind(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Combo performances within and between cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "basename = '../../data/integrated_pgd_predictions/'+\\\n",
    "'raw_01_within_notwithcohorts_clinicalclinical_proteinclinical_proteinprotein_and_clinical_and_protein_features_small_combos_pgd_prediction_'\n",
    "feature_set = pickle.load(open(basename+'feature_set_dictionary.pkl','rb'))\n",
    "sets_to_use = [k for \n",
    " k,v in feature_set.items() if len(np.setdiff1d(v,umarkers))==0]\n",
    "all_pperf_df = pd.read_csv(basename+'agg_patient_level_data.csv',index_col=0).query('set in @sets_to_use')\n",
    "print(all_pperf_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_scores(all_pperf_df,set_,n=50,scorer=roc_auc_score):\n",
    "    fs = feature_set[set_]\n",
    "    \n",
    "    dat=all_pperf_df.query('set==@set_')\n",
    "    \n",
    "    lsts = []\n",
    "    for b in range(n):\n",
    "        lsts.append(\n",
    "            (dat.\n",
    "             sample(n=dat.shape[0],replace=True,random_state=b).\n",
    "             groupby('cohort').\n",
    "             apply(\n",
    "                 lambda x : scorer(x.y_true,x.y_proba)\n",
    "             )\n",
    "            )\n",
    "        )\n",
    "    cohort_meaen_series = pd.concat(lsts,1).T.mean()\n",
    "\n",
    "    vals = []\n",
    "    for b in range(n):\n",
    "        x = (dat.\n",
    "             sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "            )\n",
    "        vals.append(scorer(x.y_true,x.y_proba))\n",
    "    \n",
    "    cedar,cumc,paris,all_ = (pd.\n",
    "     concat([pd.concat(lsts,1).\n",
    "             T.\n",
    "             mean(),\n",
    "             pd.Series(np.mean(vals),\n",
    "                       index=['Integrated'])\n",
    "            ]\n",
    "           ).\n",
    "     values)\n",
    "    return [all_,cumc,cedar,paris,set_,fs,\n",
    "                   (cumc+cedar+paris)/3,(all_+cumc+cedar+paris)/4,\n",
    "           np.var([cumc,cedar,paris]),np.var([all_,cumc,cedar,paris]),\n",
    "           np.std([cumc,cedar,paris]),np.std([all_,cumc,cedar,paris])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as sm\n",
    "\n",
    "sets = all_pperf_df['set'].astype(str).unique()\n",
    "params={ 'scorer' : roc_auc_score }\n",
    "\n",
    "scores = Parallel(n_jobs=4,backend='threading')(delayed(get_scores)(all_pperf_df,set_,**params) for set_ in sets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = (pd.DataFrame(np.array(scores),\n",
    "              index=sets,\n",
    "              columns=['all','cumc','cedar','paris','set','markers',\n",
    "                       'avg_cohort_score','avg_score',\n",
    "                      'var_cohort_score','var_score',\n",
    "                      'std_cohort_score','std_score']\n",
    "             ))\n",
    "m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p1 = ['Clinical' if x[0] in X_all_clinical.columns else 'Protein' for x in m.markers]\n",
    "p2 = ['Clinical' if np.any(X_all_clinical.columns.isin(x[1:2])) else 'Protein' for x in m.markers]\n",
    "m['Marker type'] = [a_+'-'+b_ for a_,b_ in zip(p1,p2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m['Marker type'][m['Marker type'].isin(['Protein-Clinical'])] = 'Clinical-Protein'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.sort_values('all',ascending=False).to_csv('../../data/marker_combos_01_within_notwithcohorts_inter_intra_cohort_mean_roc_auc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = pd.read_csv('../../data/marker_combos_01_within_notwithcohorts_inter_intra_cohort_mean_roc_auc.csv',index_col=0)\n",
    "m.markers = [x.strip('][').split(', ') for x in m.markers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_sets = m.sort_values(['all']).tail(3).set.values\n",
    "(fimps_df.query('set in @top_sets').\n",
    " pivot_table(index='set',columns='Feature',values='mean').\n",
    " loc[top_sets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top10_sets = m.sort_values(['all']).tail(10).set.values\n",
    "pperf_df.query('set in @top10_sets').sort_values('mean',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=dpi)\n",
    "tmp = (m[[len(x)==2 for x in m.markers]].\n",
    " set_index('markers').\n",
    " sort_values('avg_score').\n",
    " loc[:,['all','avg_score','Marker type']])\n",
    "sns.scatterplot('all','avg_score',hue='Marker type',data=tmp,ax=ax,\n",
    "                linewidth=.5,s=50,palette=p_c_color_dict,\n",
    "                edgecolor='black')\n",
    "ax.legend(frameon=False)\n",
    "#ax.set_xlim(0.45,0.75)\n",
    "#ax.set_ylim(0.45,0.75)\n",
    "\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'r--', alpha=0.75, zorder=0)\n",
    "\n",
    "ax.set_ylabel('Cohort average AUROC',size=18)\n",
    "ax.set_xlabel('Integrated cohort AUROC',size=18)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'two_marker_panel_predictions_avg_cohort_vs_integrated_performance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Variation of panel performance across cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.sort_values('all').tail(50).sort_values('std_score').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m['1/coefficient_of_variation'] = 1/((m['std_score'] / m['avg_score']).values)\n",
    "m['1/var-mean'] = 1/((m['var_score'] / m['avg_score']).values)\n",
    "m['1/cohort_coefficient_of_variation'] = \\\n",
    "1/((m['std_cohort_score'] / m['avg_cohort_score']).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.sort_values('1/coefficient_of_variation').tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.sort_values('all').tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=dpi)\n",
    "sns.scatterplot('avg_cohort_score','all',\n",
    "                hue='Marker type',data=m,ax=ax,\n",
    "                linewidth=.5,s=50,palette=p_c_color_dict,\n",
    "                edgecolor='black')\n",
    "ax.legend().remove()\n",
    "ax.set_ylabel('AUROC',size=18)\n",
    "ax.set_xlabel('Cohort Mean',size=18)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=dpi)\n",
    "sns.scatterplot('var_score','all',\n",
    "                hue='Marker type',data=m,ax=ax,\n",
    "                linewidth=.5,s=50,palette=p_c_color_dict,\n",
    "                edgecolor='black')\n",
    "ax.legend().remove()\n",
    "ax.set_ylabel('Performance',size=18)\n",
    "ax.set_xlabel('Variation',size=18)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'Variation_vs_Performance_for_two_marker_panels.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=dpi)\n",
    "sns.scatterplot('1/var-mean','all',\n",
    "                hue='Marker type',data=m,ax=ax,\n",
    "                linewidth=.5,s=50,palette=p_c_color_dict,\n",
    "                edgecolor='black')\n",
    "ax.legend().remove()\n",
    "ax.set_ylabel('AUROC',size=18)\n",
    "ax.set_xlabel('Variation/Mean',size=18)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=dpi)\n",
    "sns.scatterplot('1/cohort_coefficient_of_variation','all',\n",
    "                hue='Marker type',data=m,ax=ax,\n",
    "                linewidth=.5,s=50,palette=p_c_color_dict,\n",
    "                edgecolor='black')\n",
    "ax.legend().remove()\n",
    "ax.set_ylabel('AUROC',size=18)\n",
    "ax.set_xlabel(r'$Cohort Coefficient\\ of\\ Variation^{-1}$',size=18)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=dpi)\n",
    "sns.scatterplot('1/coefficient_of_variation','all',\n",
    "                hue='Marker type',data=m,ax=ax,\n",
    "                linewidth=.5,s=50,palette=p_c_color_dict,\n",
    "                edgecolor='black')\n",
    "ax.legend().remove()\n",
    "ax.set_ylabel('AUROC',size=18)\n",
    "ax.set_xlabel(r'$Coefficient\\ of\\ Variation^{-1}$',size=18)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'Inv_CV_vs_AUROC_for_two_marker_panels.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### correlation between aurocs w and wo cohort covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = pd.read_csv('../../data/marker_combos_01_within_inter_intra_cohort_mean_roc_auc.csv',index_col=0)\n",
    "m.markers = [x.strip('][').split(', ') for x in m.markers]\n",
    "m_wcohortcovs = pd.read_csv('../../data/marker_combos_01_within_wcohortcovs_inter_intra_cohort_mean_roc_auc.csv',index_col=0)\n",
    "m_wcohortcovs.markers = [x.strip('][').split(', ') for x in m_wcohortcovs.markers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=dpi)\n",
    "sns.scatterplot(m['all'],m_wcohortcovs['all'],edgecolor='black',color='lightgray',lw=.3)\n",
    "ax.set_ylabel('With covariate adjustment',size=16)\n",
    "ax.set_xlabel('Without covariate adjustment',size=16)\n",
    "\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'r--', alpha=0.75, zorder=0)\n",
    "\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "fig.savefig(dropbox_figures+'effect_of_covariate_adjustment.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "output table with two marker panels better than individual markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = pd.read_csv('../../data/marker_combos_01_within_notwithcohorts_inter_intra_cohort_mean_roc_auc.csv',index_col=0)\n",
    "m_individual = pd.read_csv(\n",
    "    dropbox_data+'all_individual_marker_01_within_notwithcohorts_prediction_results.csv',\n",
    "    index_col=0\n",
    ")\n",
    "umarkers = m_individual.original_feature.unique()\n",
    "markers = [x.strip('\\'[]\\'').split('\\', \\'') for x in m.markers]\n",
    "rmarkers = []\n",
    "for x in markers:\n",
    "    lst=[]\n",
    "    for i in x:\n",
    "        lst.append(m_individual[m_individual.original_feature.isin([i])].index.values[0])\n",
    "    rmarkers.append(' and '.join(lst))\n",
    "m['names'] = rmarkers\n",
    "m_pperf_df = m.set_index('set').join(pperf_df.set_index('set'))\n",
    "tmp = (m_pperf_df.loc[:,['names','2.5%','mean','97.5%']].\n",
    " sort_values('mean',ascending=False)\n",
    ")\n",
    "tmp = tmp[tmp['2.5%']>0.6655].reset_index(drop=True)\n",
    "tmp.to_csv(dropbox_data+'table_of_two_marker_panels_significantly_better_than_individual_markers.csv')\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Differential expression & GSEA \n",
    "\n",
    "using src/python/bootstrap_conditional_protein_logit.py to create protein/gene statistics\n",
    "\n",
    "using 20190104_GSEA.ipynb for creating files and running GSEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gseapy as gp\n",
    "gp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "uniprot = pd.read_csv('../../data/uniprot-all_20171124.tab.gz',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "characterized_prots = uniprot.query('Organism==\"Homo sapiens (Human)\"').Entry.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idmap = uniprot[['Entry','Gene names  (primary )']].rename(columns={'Entry' : 'Protein',\"Gene names  (primary )\" : 'Gene_name'})\n",
    "idmap_sub = idmap[idmap.Protein.isin(characterized_prots)]\n",
    "idmap_sub.to_csv('../../data/gene_list.txt',sep='\\n',header=None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stat = 'mean'\n",
    "cohort='integrated'\n",
    "dir_ = \"../../data/bootstrap_conditional_protein_logit/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Generate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cohort='integrated'\n",
    "print(cohort)\n",
    "logit = pd.read_csv(dir_+cohort+\n",
    "            \"/logit_bootstrap_pgd_~_protein_+_cohort_-_paris_lwr_mean_median_upr.csv\")\n",
    "print(logit.shape)\n",
    "\n",
    "#Joining genes\n",
    "tmp = logit.set_index('variable').join(idmap_sub.set_index('Protein'))\n",
    "leftover_inds = tmp.Gene_name.isnull()\n",
    "leftover_prots = tmp.index[leftover_inds].values\n",
    "leftover_prots_split = [k.split('-')[0] for k in leftover_prots]\n",
    "\n",
    "tmp_df = pd.DataFrame({'Protein' : leftover_prots,\n",
    "                       'Split' : leftover_prots_split,\n",
    "                       'cohort_identified_in' : cohort})\n",
    "\n",
    "tmp_df_join = tmp_df.set_index('Split').join(idmap_sub.set_index('Protein'))\n",
    "\n",
    "join_genes = tmp_df_join.Gene_name.values\n",
    "join_prots = tmp_df_join.Protein.values\n",
    "\n",
    "tmp.at[join_prots,'Gene_name'] = join_genes\n",
    "\n",
    "#single_gene_map = \\\n",
    "#(tmp.\n",
    "# Gene_name.\n",
    "# str.\n",
    "# split('; ').\n",
    "# apply(pd.Series).\n",
    "# rename_axis('Protein').\n",
    "# reset_index().\n",
    "# melt(id_vars=['Protein'],value_name='Gene_name').\n",
    "# dropna().\n",
    "# drop('variable',axis=1).\n",
    "# set_index('Protein')\n",
    "#)\n",
    "\n",
    "#tmp_single_genes = \\\n",
    "#(tmp.\n",
    "# dropna().\n",
    "# drop('Gene_name',axis=1).\n",
    "# join(single_gene_map).\n",
    "# drop_duplicates().\n",
    "# sort_values('mean')\n",
    "#)\n",
    "\n",
    "null_prots = tmp_df_join[tmp_df_join.Gene_name.isnull()].index.values\n",
    "df = (tmp[~tmp.index.isin(null_prots)].\n",
    "      reset_index(drop=True).\n",
    "      set_index('Gene_name')\n",
    "     )\n",
    "df_sig = df[(df.lwr>1) | (df.upr<1)]\n",
    "#\n",
    "\n",
    "logit_rnk = (df[[stat]].\n",
    "         sort_values(stat,ascending=False).\n",
    "         reset_index().\n",
    "         rename(columns={stat : 'Statistic','Gene_name' : 'Gene'}))\n",
    "\n",
    "df = (logit_rnk.\n",
    "  groupby('Gene').\n",
    "  agg('mean').\n",
    "  reset_index().\n",
    "  sort_values('Statistic',ascending=False))\n",
    "print(df.shape)\n",
    "(df.\n",
    " to_csv('../../data/'+cohort+\n",
    "        '_bootstrap_conditional_protein_logit_'+stat+\n",
    "        '_gene_name_statistic.rnk',\n",
    "        sep='\\t',header=None,index=None))\n",
    "\n",
    "df_no_IGs = df[~(df.\n",
    " Gene.\n",
    " str.\n",
    "startswith('IG'))]\n",
    "(df_no_IGs.\n",
    " to_csv('../../data/'+cohort+\n",
    "        '_bootstrap_conditional_protein_logit_'+stat+\n",
    "        '_gene_name_statistic_no_IGs.rnk',\n",
    "        sep='\\t',header=None,index=None))\n",
    "\n",
    "logit_rnk_sig = (df_sig[[stat]].\n",
    "         sort_values(stat,ascending=False).\n",
    "         reset_index().\n",
    "         rename(columns={stat : 'Statistic','Gene_name' : 'Gene'}))\n",
    "\n",
    "df_sig = (logit_rnk_sig.\n",
    "  groupby('Gene').\n",
    "  agg('mean').\n",
    "  reset_index().\n",
    "  sort_values('Statistic',ascending=False))\n",
    "print(df_sig.shape)\n",
    "(df_sig.\n",
    " to_csv('../../data/'+cohort+\n",
    "        '_bootstrap_conditional_protein_logit_'+stat+\n",
    "        '_gene_name_significant_statistic.rnk',\n",
    "        sep='\\t',header=None,index=None))\n",
    "df_sig.Gene = df_sig.Gene.apply(lambda x : x.split(';')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "tmp['Significant'] = (tmp.Gene.isin(df_sig.Gene)).values\n",
    "(tmp.\n",
    " to_csv('../../data/Gene_GSEA_Statistic.csv',sep=',',index=False))\n",
    "(df.\n",
    " Gene.\n",
    " to_csv('../../data/gene_list.txt',sep='\\t',index=False))\n",
    "(df_no_IGs.\n",
    " Gene.\n",
    " to_csv('../../data/gene_list_no_IGs.txt',sep='\\t',index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs = ['GO_Biological_Process_2017b','GO_Molecular_Function_2017b',\n",
    "      'GO_Cellular_Component_2017b','Reactome_2016','WikiPathways_2019_Human',\n",
    "      'KEGG_2019_Human']\n",
    "pre_ress = {}\n",
    "cohort='integrated'\n",
    "rnk = pd.read_table('../../data/'+cohort+\n",
    "                    '_bootstrap_conditional_protein_logit_'+stat+\n",
    "                    '_gene_name_statistic.rnk', header=None)\n",
    "rnk.iloc[:,0] = rnk.iloc[:,0].apply(lambda x : x.split(';')[0])\n",
    "display(rnk.head())\n",
    "for g in gs:\n",
    "    print('\\t'+g)\n",
    "    pre_res = gp.prerank(rnk=rnk, gene_sets=g,\n",
    "                     processes=4,\n",
    "                     permutation_num=10000, \n",
    "                     outdir='../../data/'+cohort+\n",
    "                         '_bootstrap_conditional_protein_logit_'+stat+\n",
    "                         '_prerank_report_'+g,format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs = ['GO_Biological_Process_2017b','GO_Molecular_Function_2017b',\n",
    "      'GO_Cellular_Component_2017b','Reactome_2016','WikiPathways_2019_Human',\n",
    "      'KEGG_2019_Human']\n",
    "pre_ress = {}\n",
    "cohort='integrated'\n",
    "rnk = pd.read_table('../../data/'+cohort+\n",
    "                    '_bootstrap_conditional_protein_logit_'+stat+\n",
    "                    '_gene_name_statistic_no_IGs.rnk', header=None)\n",
    "rnk.iloc[:,0] = rnk.iloc[:,0].apply(lambda x : x.split(';')[0])\n",
    "display(rnk.head())\n",
    "for g in gs:\n",
    "    print('\\t'+g)\n",
    "    pre_res = gp.prerank(rnk=rnk, gene_sets=g,\n",
    "                     processes=4,\n",
    "                     permutation_num=10000, \n",
    "                     outdir='../../data/'+cohort+\n",
    "                         '_bootstrap_conditional_protein_logit_'+stat+\n",
    "                         '_prerank_report_'+g+'_no_IGs',format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Enriched and Depleted pathways\n",
    "\n",
    "https://amp.pharm.mssm.edu/Enrichr/enrich?dataset=7068ee737a4b433316e95d85e9326697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stat = 'mean'\n",
    "gs = ['GO_Biological_Process_2017b','GO_Molecular_Function_2017b',\n",
    "      'GO_Cellular_Component_2017b','Reactome_2016','WikiPathways_2019_Human',\n",
    "      'KEGG_2019_Human']\n",
    "cohort='integrated'\n",
    "datas=[]\n",
    "for path in gs:\n",
    "    data = (pd.read_csv('../../data/'+cohort+\n",
    "                        '_bootstrap_conditional_protein_logit_'+stat+\n",
    "                       '_prerank_report_'+path+\n",
    "                       '/gseapy.prerank.gene_sets.report.csv').\n",
    "            sort_values(['fdr','nes'],\n",
    "                        ascending=[True,False]))\n",
    "    data['Category'] = path\n",
    "    datas.append(data)\n",
    "pd.concat(datas).to_csv('../../data/'+cohort+\n",
    "                        '_bootstrap_conditional_protein_logit_'+stat+\n",
    "                       '_prerank_report_all_categories.csv')\n",
    "pd.concat(datas).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_map = { 'nes' : 'Normalized Enrichment Score', 'pval' : 'P-value', 'fdr' : 'False Discovery Rate',\"Category\" : 'Category'}\n",
    "gs = ['GO_Biological_Process_2017b','GO_Molecular_Function_2017b',\n",
    "      'GO_Cellular_Component_2017b','Reactome_2016','WikiPathways_2019_Human',\n",
    "      'KEGG_2019_Human']\n",
    "datas = []\n",
    "for path in gs:\n",
    "    cohort=\"integrated\"\n",
    "    data_ = (pd.read_csv('../../data/'+cohort+\n",
    "                          '_bootstrap_conditional_protein_logit_'+stat+\n",
    "                          '_prerank_report_all_categories.csv',index_col=0).\n",
    "            query('Category==@path').\n",
    "             sort_values('fdr',ascending=False).\n",
    "             set_index('Term'))\n",
    "    data_ = data_.query('fdr < 0.2 & nes > 0 & fdr>pval').rename(columns=col_map)\n",
    "    datas.append(data_)\n",
    "enriched = pd.concat(datas).copy()\n",
    "tmp = enriched[[k for k in col_map.values()]].sort_values('False Discovery Rate',ascending=True).round(4)\n",
    "tmp.to_csv(dropbox_data+'enriched_PGD_pathways_functions.csv')\n",
    "enriched.to_csv(dropbox_data+'enriched_PGD_pathways_functions_wgenes.csv')\n",
    "display(tmp)\n",
    "print(tmp.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enriched_genes = np.unique(np.concatenate([k for k in pd.concat(datas).genes.str.split(';')]))\n",
    "cohort = 'integrated'\n",
    "stat= 'mean'\n",
    "rnk = pd.read_csv('../../data/'+cohort+\n",
    "                            '_bootstrap_conditional_protein_logit_'+stat+\n",
    "                            '_gene_name_statistic.rnk', sep='\\t',header=None)\n",
    "rnk['In_Enriched_Pathway'] = rnk.loc[:,0].apply(lambda x : x.split(';')[0]).isin(enriched_genes)\n",
    "rnk = rnk.rename(columns={0: 'Gene',1 : 'Statistic'})\n",
    "#rnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_map = { 'nes' : 'Normalized Enrichment Score', 'pval' : 'P-value', 'fdr' : 'False Discovery Rate',\"Category\" : 'Category'}\n",
    "datas = []\n",
    "gs = ['GO_Biological_Process_2017b','GO_Molecular_Function_2017b',\n",
    "      'GO_Cellular_Component_2017b','Reactome_2016','WikiPathways_2019_Human',\n",
    "      'KEGG_2019_Human']\n",
    "for path in gs:\n",
    "    cohort=\"integrated\"\n",
    "    data_ = (pd.read_csv('../../data/'+cohort+\n",
    "                          '_bootstrap_conditional_protein_logit_'+stat+\n",
    "                          '_prerank_report_all_categories.csv',index_col=0).\n",
    "            query('Category==@path').\n",
    "             sort_values('fdr',ascending=False).\n",
    "             set_index('Term'))\n",
    "    data_ = data_.query('fdr < 0.2 & nes < 0 & fdr>pval').rename(columns=col_map)\n",
    "    datas.append(data_)\n",
    "depleted = pd.concat(datas).copy()\n",
    "tmp = depleted[[k for k in col_map.values()]].sort_values('False Discovery Rate',ascending=True).round(4)\n",
    "tmp.to_csv(dropbox_data+'depleted_PGD_pathways_functions.csv')\n",
    "depleted.to_csv(dropbox_data+'depleted_PGD_pathways_functions_wgenes.csv')\n",
    "display(tmp)\n",
    "print(tmp.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "depleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "depleted.genes.apply(lambda x : 'ADIPOQ' in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Enriched and Depleted pathways - No IGs\n",
    "\n",
    "https://amp.pharm.mssm.edu/Enrichr/enrich?dataset=7068ee737a4b433316e95d85e9326697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stat = 'mean'\n",
    "gs = ['GO_Biological_Process_2017b','GO_Molecular_Function_2017b',\n",
    "      'GO_Cellular_Component_2017b','Reactome_2016','WikiPathways_2019_Human',\n",
    "      'KEGG_2019_Human']\n",
    "cohort='integrated'\n",
    "datas=[]\n",
    "for path in gs:\n",
    "    data = (pd.read_csv('../../data/'+cohort+\n",
    "                        '_bootstrap_conditional_protein_logit_'+stat+\n",
    "                       '_prerank_report_'+path+'_no_IGs'+\n",
    "                       '/gseapy.prerank.gene_sets.report.csv').\n",
    "            sort_values(['fdr','nes'],\n",
    "                        ascending=[True,False]))\n",
    "    data['Category'] = path\n",
    "    datas.append(data)\n",
    "pd.concat(datas).to_csv('../../data/'+cohort+\n",
    "                        '_bootstrap_conditional_protein_logit_'+stat+\n",
    "                       '_prerank_report_all_categories_no_IGs.csv')\n",
    "pd.concat(datas).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_map = { 'nes' : 'Normalized Enrichment Score', 'pval' : 'P-value', 'fdr' : 'False Discovery Rate',\"Category\" : 'Category'}\n",
    "gs = ['GO_Biological_Process_2017b','GO_Molecular_Function_2017b',\n",
    "      'GO_Cellular_Component_2017b','Reactome_2016','WikiPathways_2019_Human',\n",
    "      'KEGG_2019_Human']\n",
    "datas = []\n",
    "for path in gs:\n",
    "    cohort=\"integrated\"\n",
    "    data_ = (pd.read_csv('../../data/'+cohort+\n",
    "                          '_bootstrap_conditional_protein_logit_'+stat+\n",
    "                          '_prerank_report_all_categories_no_IGs.csv',index_col=0).\n",
    "            query('Category==@path').\n",
    "             sort_values('fdr',ascending=False).\n",
    "             set_index('Term'))\n",
    "    data_ = data_.query('fdr < 0.2 & nes > 0 & fdr>pval').rename(columns=col_map)\n",
    "    datas.append(data_)\n",
    "enriched = pd.concat(datas).copy()\n",
    "tmp = enriched[[k for k in col_map.values()]].sort_values('False Discovery Rate',ascending=True).round(4)\n",
    "tmp.to_csv(dropbox_data+'enriched_PGD_pathways_functions_no_IGs.csv')\n",
    "enriched.to_csv(dropbox_data+'enriched_PGD_pathways_functions_wgenes_no_IGs.csv')\n",
    "display(tmp)\n",
    "print(tmp.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enriched_genes = np.unique(np.concatenate([k for k in pd.concat(datas).genes.str.split(';')]))\n",
    "cohort = 'integrated'\n",
    "stat= 'mean'\n",
    "rnk = pd.read_csv('../../data/'+cohort+\n",
    "                            '_bootstrap_conditional_protein_logit_'+stat+\n",
    "                            '_gene_name_statistic_no_IGs.rnk', sep='\\t',header=None)\n",
    "rnk['In_Enriched_Pathway'] = rnk.loc[:,0].apply(lambda x : x.split(';')[0]).isin(enriched_genes)\n",
    "rnk = rnk.rename(columns={0: 'Gene',1 : 'Statistic'})\n",
    "#rnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_map = { 'nes' : 'Normalized Enrichment Score', 'pval' : 'P-value', 'fdr' : 'False Discovery Rate',\"Category\" : 'Category'}\n",
    "datas = []\n",
    "gs = ['GO_Biological_Process_2017b','GO_Molecular_Function_2017b',\n",
    "      'GO_Cellular_Component_2017b','Reactome_2016','WikiPathways_2019_Human',\n",
    "      'KEGG_2019_Human']\n",
    "for path in gs:\n",
    "    cohort=\"integrated\"\n",
    "    data_ = (pd.read_csv('../../data/'+cohort+\n",
    "                          '_bootstrap_conditional_protein_logit_'+stat+\n",
    "                          '_prerank_report_all_categories_no_IGs.csv',index_col=0).\n",
    "            query('Category==@path').\n",
    "             sort_values('fdr',ascending=False).\n",
    "             set_index('Term'))\n",
    "    data_ = data_.query('fdr < 0.2 & nes < 0 & fdr>pval').rename(columns=col_map)\n",
    "    datas.append(data_)\n",
    "depleted = pd.concat(datas).copy()\n",
    "tmp = depleted[[k for k in col_map.values()]].sort_values('False Discovery Rate',ascending=True).round(4)\n",
    "tmp.to_csv(dropbox_data+'depleted_PGD_pathways_functions_no_IGs.csv')\n",
    "depleted.to_csv(dropbox_data+'depleted_PGD_pathways_functions_wgenes_no_IGs.csv')\n",
    "display(tmp)\n",
    "print(tmp.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "depleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "depleted.genes.apply(lambda x : 'ADIPOQ' in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Protein associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_depleted_genes = np.unique(np.concatenate([k for k in pd.concat(datas).genes.str.split(';')]))\n",
    "rnk['In_Top_Depleted_Pathway'] = rnk.loc[:,'Gene'].apply(lambda x : x.split(';')[0]).isin(top_depleted_genes)\n",
    "rnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rnk.query('In_Enriched_Pathway==False & In_Top_Depleted_Pathway==True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logit = pd.read_csv(dir_+\n",
    "                    \"/bootstrap_conditional_protein_logit/\"+\n",
    "                    cohort+\n",
    "                    \"/logit_bootstrap_pgd_~_protein_+_cohort_-_paris_lwr_mean_median_upr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = logit.set_index('variable').join(idmap_sub.set_index('Protein'))\n",
    "leftover_inds = tmp.Gene_name.isnull()\n",
    "leftover_prots = tmp.index[leftover_inds].values\n",
    "leftover_prots_split = [k.split('-')[0] for k in leftover_prots]\n",
    "\n",
    "tmp_df = pd.DataFrame({'Protein' : leftover_prots,\n",
    "                       'Split' : leftover_prots_split,\n",
    "                       'cohort_identified_in' : cohort})\n",
    "\n",
    "tmp_df_join = tmp_df.set_index('Split').join(idmap_sub.set_index('Protein'))\n",
    "\n",
    "join_genes = tmp_df_join.Gene_name.values\n",
    "join_prots = tmp_df_join.Protein.values\n",
    "\n",
    "tmp.at[join_prots,'Gene_name'] = join_genes\n",
    "\n",
    "null_prots = tmp_df_join[tmp_df_join.Gene_name.isnull()].index.values\n",
    "df = tmp[~tmp.index.isin(null_prots)].reset_index(drop=True).set_index('Gene_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "genes_in_gene_set = []\n",
    "genes = df[~df.index.str.startswith('IG')].reset_index().Gene_name.apply(lambda x : x.split(';')[0]).values\n",
    "term_genes = np.union1d(depleted.genes,enriched.genes)\n",
    "terms = np.union1d(enriched.index,depleted.index)\n",
    "gene_sets = [x.split(';') for x in term_genes]\n",
    "for i,set_ in enumerate(gene_sets):\n",
    "    t = list(np.intersect1d(genes,set_))\n",
    "    t.sort()\n",
    "    genes_in_gene_set.append(t)\n",
    "sig_genes = np.concatenate(genes_in_gene_set)\n",
    "sig_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stat = 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(dpi=dpi,figsize=(5,5))\n",
    "data = (df[~df.index.str.startswith('IG')].\n",
    "        query('lwr>1 | upr<1').\n",
    "        sort_values(stat,ascending=False))\n",
    "display(data.head())\n",
    "data.index = [x.split(';')[0][:len(x.split(';')[0])-1]+' family' if len(x.split(';'))>2 else x for x in data.index]\n",
    "data.index = [x+'*' if (x in sig_genes) else x for x in data.index]\n",
    "ax.errorbar(y=data.index,\n",
    "            x=data[stat],\n",
    "            xerr=(data[stat] - data['lwr'],\n",
    "                 data['upr'] - data[stat]),\n",
    "           fmt='o',markersize=3,linewidth=1)\n",
    "ax.plot([1,1],[0,len(data.index.unique())-1],'r--',linewidth=0.5)\n",
    "ax.set_xlabel('Odds',fontsize=16)\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'significant_proteins.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Centered Bar plot of GSEA Enriched/Depleted pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enriched = pd.read_csv(dropbox_data+'enriched_PGD_pathways_functions_wgenes.csv')\n",
    "depleted = pd.read_csv(dropbox_data+'depleted_PGD_pathways_functions_wgenes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enriched.Term = enriched.Term.str.split('[(_]').apply(pd.Series).iloc[:,0].copy()\n",
    "depleted.Term = depleted.Term.str.split('[(_]').apply(pd.Series).iloc[:,0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([enriched,depleted]).sort_values('Normalized Enrichment Score',ascending=False)\n",
    "data.Term = data.Term.str.replace('WP545','').str.replace(' WP15','')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import ticker\n",
    "\n",
    "fig,ax=plt.subplots(dpi=dpi,figsize=(10,5))\n",
    "xlab = 'Normalized Enrichment Score'\n",
    "sns.barplot(xlab,'Term',data=data,ax=ax,color='darkgray',linewidth=.2)\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlabel(xlab,size=16)\n",
    "ax.set_xscale('symlog')\n",
    "\n",
    "formatter = ticker.ScalarFormatter(useOffset=True,)\n",
    "formatter.set_scientific(False)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "ax.xaxis.set_major_locator(ticker.FixedLocator([-40,-10,0,1,2,3]))\n",
    "ax.grid(b=True, which='major', color='gray', linewidth=0.1)\n",
    "ax.tick_params(labelsize=18)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'GSEA_Enriched_Depleted_BarPlot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### assigning proteins to their GSEA category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "uniprot = pd.read_csv('../../data/uniprot-all_20171124.tab.gz',sep='\\t')\n",
    "raw_samples = (pd.read_csv('../../data/integrated_sample_data_mean_std_scaled.csv',\n",
    "                          index_col=0))\n",
    "df = raw_samples.join(uniprot.loc[:,['Entry','Gene ontology (biological process)']].set_index('Entry')).dropna()\n",
    "df.loc[:,'Gene ontology (biological process)'] = df.loc[:,'Gene ontology (biological process)'].apply(lambda x : x.split(';'))\n",
    "df.index.name = 'Protein'\n",
    "df=df.reset_index()\n",
    "lens = [len(item) for item in df['Gene ontology (biological process)']]\n",
    "df_out = pd.DataFrame( {\"Protein\" : np.repeat(df['Protein'].values,lens), \n",
    "               \"GO_Biological_Process\" : np.hstack(df['Gene ontology (biological process)'])\n",
    "              })\n",
    "df_out\n",
    "df_join=(df.\n",
    "         set_index('Protein').\n",
    "         join(df_out.\n",
    "              set_index('Protein')\n",
    "             ).\n",
    "         set_index('GO_Biological_Process').\n",
    "         drop('Gene ontology (biological process)',axis=1)\n",
    "        )\n",
    "X = df_join.groupby(df_join.index).agg(np.mean).T\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "riched = (pd.\n",
    "          read_csv('../../data/integrated_bootstrap_conditional_protein_logit'+\n",
    "                   '_mean_prerank_report_all_categories.csv',index_col=0)\n",
    "         )\n",
    "display(riched.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def tall_func(riched):\n",
    "    df = riched.copy().drop('genes',axis=1)\n",
    "    df.ledge_genes = df.ledge_genes.apply(lambda x : x.split(';'))\n",
    "    return (df.\n",
    "            ledge_genes.\n",
    "            apply(pd.Series).\n",
    "            merge(df, \n",
    "                  right_index = True, \n",
    "                  left_index = True).\n",
    "            drop(['ledge_genes'],axis=1).\n",
    "            melt(id_vars=np.setdiff1d(riched.columns,['genes','ledge_genes']),\n",
    "                 value_name='ledge_gene').\n",
    "            drop('variable',axis=1).\n",
    "            dropna().\n",
    "            reset_index(drop=True).\n",
    "            sort_values(['Category','Term','ledge_gene'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "riched_tall = tall_func(riched)\n",
    "display(riched_tall.head())\n",
    "riched_tall.to_csv('../../data/integrated_bootstrap_conditional_protein_logit'+\n",
    "                   '_mean_prerank_report_all_categories_tall.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "riched_tall.ledge_gene.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### GSEA category protein predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../../data/integrated_pgd_predictions/gsea_categories/'\n",
    "type_='ledge_protein_features_pgd_prediction_'\n",
    "proteins_immunoglobulins = pickle.load(open('../../data/proteins_immunoglobulins.pkl','rb'))\n",
    "scorers = { 'roc_auc' : roc_auc_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = [x for x in os.listdir(data_dir) if ( ('pkl' not in x) & \n",
    "                                             (type_ in x) & \n",
    "                                             ('patient' in x) & \n",
    "                                             ('importance' not in x) & \n",
    "                                             ('bootstrap' in x) &\n",
    "                                             ('proteins_prediction_metric' in x) &\n",
    "                                             ('slash' not in x)\n",
    "                                            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(files))\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n=50\n",
    "lsts=[]\n",
    "feature_mccv_scores_df = {}\n",
    "feature_mccv_score_means_dfs = []\n",
    "for score,scorer in scorers.items():\n",
    "    feature_scores_bootstraps = []\n",
    "    for file in files:\n",
    "        feature = (file.\n",
    "                   replace(type_,'').\n",
    "                   replace('_proteins_prediction_metric_bootstrap_train_test_val_patient_level_data.csv',\n",
    "                           '')\n",
    "                  )\n",
    "        dat = pd.read_csv(data_dir+file,index_col=0)\n",
    "        vals = []\n",
    "        for b in range(n):\n",
    "            x = (dat.\n",
    "                 sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "                )\n",
    "            vals.append([feature,b,x.model.unique()[0],scorer(x.y_true,x.y_proba)])\n",
    "        feature_scores_bootstrap = pd.DataFrame(vals,columns=['Pathway','Bootstrap',\n",
    "                                                              'Model',score])\n",
    "        feature_scores_bootstraps.append(feature_scores_bootstrap)\n",
    "    \n",
    "    feature_mccv_scores_df[score] = \\\n",
    "    (pd.concat(feature_scores_bootstraps)\n",
    "    )\n",
    "\n",
    "    feature_mccv_score_means_df = (pd.concat(feature_scores_bootstraps).\n",
    "                                   groupby(['Pathway','Model'])[score].\n",
    "                                   mean().\n",
    "                                   reset_index().\n",
    "                                   rename(columns={score : 'mean_validation_'+score}))\n",
    "    (pd.concat(feature_scores_bootstraps).\n",
    "     groupby(['Pathway','Model'])[score].\n",
    "     describe(percentiles=[0.025,0.975]).\n",
    "     loc[:,['2.5%','mean','97.5%']].\n",
    "     sort_values('mean',ascending=False)\n",
    "    ).to_csv(data_dir+type_+score+'_CIs.csv')\n",
    "\n",
    "    display(feature_mccv_score_means_df.sort_values('mean_validation_'+score).tail())\n",
    "\n",
    "    feature_mccv_score_means_dfs.append(feature_mccv_score_means_df)\n",
    "feature_mccv_score_means_df = (reduce(lambda  left,right: pd.merge(left,right,\n",
    "                                                                  on=['Pathway','Model'],\n",
    "                                            how='outer'), feature_mccv_score_means_dfs))\n",
    "print(feature_mccv_score_means_df.shape)\n",
    "feature_mccv_score_means_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = [x for x in os.listdir(data_dir) if ( ('pkl' not in x) & \n",
    "                                             (type_ in x) & \n",
    "                                             ('patient' not in x) & \n",
    "                                             ('importance' in x) & \n",
    "                                             ('bootstrap' in x) &\n",
    "                                             ('proteins_prediction_metric' in x) &\n",
    "                                             ('slash' not in x)\n",
    "                                            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lsts=[]\n",
    "for file in files:\n",
    "    feature = (file.\n",
    "               replace(type_,'').\n",
    "               replace('_proteins_prediction_metric_bootstrap_train_test_val'+\n",
    "                       '_feature_importances.csv',''))\n",
    "    feature_logit_df = (pd.\n",
    "                    read_csv(data_dir+file,index_col=0).\n",
    "                    rename(columns={'bootstrap' : 'Bootstrap','model' : 'Model'}).\n",
    "                    dropna())\n",
    "    feature_logit_df['Pathway'] = feature\n",
    "    lsts.append(feature_logit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_importance_odds_df = pd.concat(lsts)\n",
    "feature_mccv_importance_odds_df['odds'] = np.exp(feature_mccv_importance_odds_df['Importance'])\n",
    "feature_mccv_odds_df = (feature_mccv_importance_odds_df.\n",
    "                        groupby(['Gene_name','Model','Pathway'])['odds'].\n",
    "                        describe(percentiles=[0.025,0.975]).\n",
    "                        loc[:,['2.5%','mean','97.5%']].\n",
    "                        rename(columns={'2.5%' : 'odds_lwr',\n",
    "                                        'mean' : 'odds_mean',\n",
    "                                        '97.5%' : 'odds_upr'}\n",
    "                              ).\n",
    "                        reset_index().\n",
    "                        reset_index(drop=True)\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(feature_mccv_odds_df.query('odds_lwr>1 | odds_upr<1').shape)\n",
    "feature_mccv_odds_df.query('odds_lwr>1 | odds_upr<1').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(feature_mccv_importance_odds_df.\n",
    " query('Gene_name==\"TPM4\"').\n",
    " pivot_table(index='Pathway',columns='Bootstrap',values='Importance')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_odds_df.pivot_table(index='Gene_name',columns='Pathway',values='odds_mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### permuted performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = [x for x in os.listdir(data_dir) if ( ('pkl' not in x) & \n",
    "                                             (type_ in x) & \n",
    "                                             ('patient' in x) & \n",
    "                                             ('importance' not in x) & \n",
    "                                             ('bootstrap' not in x) &\n",
    "                                             ('proteins_prediction_metric' in x) &\n",
    "                                             ('slash' not in x)\n",
    "                                            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(files))\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n=50\n",
    "lsts=[]\n",
    "feature_mccv_permuted_scores_df = {}\n",
    "feature_mccv_permuted_score_means_dfs = []\n",
    "for score,scorer in scorers.items():\n",
    "    feature_scores_bootstraps = []\n",
    "    for file in files:\n",
    "        feature = (file.\n",
    "                   replace(type_,'').\n",
    "                   replace('_proteins_prediction_metric_permute_train_test_val_patient_level_data.csv',\n",
    "                           '')\n",
    "                  )\n",
    "        dat = pd.read_csv(data_dir+file,index_col=0)\n",
    "        vals = []\n",
    "        for b in range(n):\n",
    "            x = (dat.\n",
    "                 sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "                )\n",
    "            vals.append([feature,b,x.model.unique()[0],scorer(x.y_true,x.y_proba)])\n",
    "        feature_scores_bootstrap = pd.DataFrame(vals,columns=['Pathway','Bootstrap',\n",
    "                                                              'Model',score])\n",
    "        feature_scores_bootstraps.append(feature_scores_bootstrap)\n",
    "    \n",
    "    feature_mccv_permuted_scores_df[score] = \\\n",
    "    (pd.concat(feature_scores_bootstraps)\n",
    "    )\n",
    "\n",
    "    feature_mccv_permuted_score_means_df = (pd.concat(feature_scores_bootstraps).\n",
    "                                   groupby(['Pathway','Model'])[score].\n",
    "                                   mean().\n",
    "                                   reset_index().\n",
    "                                   rename(columns={score : 'mean_validation_'+score}))\n",
    "    (pd.concat(feature_scores_bootstraps).\n",
    "     groupby(['Pathway','Model'])[score].\n",
    "     describe(percentiles=[0.025,0.975]).\n",
    "     loc[:,['2.5%','mean','97.5%']].\n",
    "     sort_values('mean',ascending=False)\n",
    "    ).to_csv(data_dir+type_+score+'_CIs.csv')\n",
    "\n",
    "    display(feature_mccv_permuted_score_means_df.sort_values('mean_validation_'+score).tail())\n",
    "\n",
    "    feature_mccv_permuted_score_means_dfs.append(feature_mccv_permuted_score_means_df)\n",
    "feature_mccv_permuted_score_means_df = (reduce(lambda  left,right: pd.merge(left,right,\n",
    "                                                                  on=['Pathway','Model'],\n",
    "                                            how='outer'), feature_mccv_permuted_score_means_dfs))\n",
    "print(feature_mccv_permuted_score_means_df.shape)\n",
    "feature_mccv_permuted_score_means_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### permuted importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = [x for x in os.listdir(data_dir) if ( ('pkl' not in x) & \n",
    "                                             (type_ in x) & \n",
    "                                             ('patient' not in x) & \n",
    "                                             ('importance' in x) & \n",
    "                                             ('bootstrap' not in x) &\n",
    "                                             ('proteins_prediction_metric' in x) &\n",
    "                                             ('slash' not in x)\n",
    "                                            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lsts=[]\n",
    "for file in files:\n",
    "    feature = (file.\n",
    "               replace(type_,'').\n",
    "               replace('_proteins_prediction_metric_permute_train_test_val'+\n",
    "                       '_feature_importances.csv',''))\n",
    "    feature_logit_df = (pd.\n",
    "                    read_csv(data_dir+file,index_col=0).\n",
    "                    rename(columns={'bootstrap' : 'Bootstrap','model' : 'Model'}).\n",
    "                    dropna())\n",
    "    feature_logit_df['Pathway'] = feature\n",
    "    lsts.append(feature_logit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_permuted_importance_odds_df = pd.concat(lsts)\n",
    "feature_mccv_permuted_importance_odds_df['odds'] = np.exp(feature_mccv_permuted_importance_odds_df['Importance'])\n",
    "feature_mccv_permuted_odds_df = (feature_mccv_permuted_importance_odds_df.\n",
    "                        groupby(['Gene_name','Model','Pathway'])['odds'].\n",
    "                        describe(percentiles=[0.025,0.975]).\n",
    "                        loc[:,['2.5%','mean','97.5%']].\n",
    "                        rename(columns={'2.5%' : 'permuted_odds_lwr',\n",
    "                                        'mean' : 'permuted_odds_mean',\n",
    "                                        '97.5%' : 'permuted_odds_upr'}\n",
    "                              ).\n",
    "                        reset_index().\n",
    "                        reset_index(drop=True)\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(feature_mccv_permuted_odds_df.query('permuted_odds_lwr>1 | permuted_odds_upr<1').shape)\n",
    "feature_mccv_permuted_odds_df.query('permuted_odds_lwr>1 | permuted_odds_upr<1').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### significant performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "score = 'roc_auc'\n",
    "pathways = feature_mccv_permuted_scores_df[score].Pathway.unique()\n",
    "ms = feature_mccv_permuted_scores_df[score].Model.unique()\n",
    "\n",
    "\n",
    "pvals = []\n",
    "for p in pathways:\n",
    "    for m in ms:\n",
    "        bdist = feature_mccv_scores_df[score].query('Model==@m & Pathway==@p')[score].values\n",
    "        pdist = feature_mccv_permuted_scores_df[score].query('Model==@m & Pathway==@p')[score].values\n",
    "        t,pval = ks_2samp(pdist,bdist)\n",
    "        pvals.append([p,m,t,pval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_performance_significance = pd.DataFrame(pvals,\n",
    "                                                     columns=\n",
    "                                                     ['Pathway',\n",
    "                                                      'Model',\n",
    "                                                      'Performance_Statistic',\n",
    "                                                      'Performance_P_value']\n",
    "                                                    )\n",
    "\n",
    "feature_mccv_performance_significance['Performance_bonferroni'] = \\\n",
    "multipletests(feature_mccv_performance_significance.Performance_P_value.values,\n",
    "              method='bonferroni')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_performance_significance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### significant importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "score = 'roc_auc'\n",
    "pathways = feature_mccv_importance_odds_df.Pathway.unique()\n",
    "print(len(pathways))\n",
    "genes = feature_mccv_permuted_importance_odds_df.Gene_name.unique()\n",
    "\n",
    "pvals = []\n",
    "for m in ms:\n",
    "    for p in pathways:\n",
    "        print(p)\n",
    "        genes = (feature_mccv_permuted_importance_odds_df.\n",
    "                 query('Pathway==@p').\n",
    "                 Gene_name.unique()\n",
    "                )\n",
    "        print(len(genes))\n",
    "        for g in genes:\n",
    "            bdist = feature_mccv_importance_odds_df.query('Model==@m & Gene_name==@g & Pathway==@p')['Importance'].values\n",
    "            pdist = feature_mccv_permuted_importance_odds_df.query('Model==@m & Gene_name==@g & Pathway==@p')['Importance'].values\n",
    "            if len(bdist)>0:\n",
    "                t,pval = ks_2samp(pdist,bdist)\n",
    "                pvals.append([p,g,m,t,pval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_importance_significance = pd.DataFrame(pvals,columns=['Pathway','Gene_name','Model','Importance_Statistic','Importance_P_value'])\n",
    "\n",
    "feature_mccv_importance_significance['Importance_bonferroni'] = multipletests(feature_mccv_importance_significance.Importance_P_value.values,method='bonferroni')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_mccv_importance_significance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pathways = (feature_mccv_score_means_df.\n",
    " set_index(['Pathway','Model']).\n",
    " join(feature_mccv_performance_significance.\n",
    "     set_index(['Pathway','Model']))\n",
    ")\n",
    "display(pathways.head())\n",
    "genes = (feature_mccv_odds_df.\n",
    " set_index(['Pathway','Model','Gene_name']).\n",
    " join(feature_mccv_permuted_odds_df.\n",
    "      set_index(['Pathway','Model','Gene_name'])\n",
    "     ).\n",
    " join(feature_mccv_importance_significance.\n",
    "     set_index(['Pathway','Model','Gene_name']))\n",
    ")\n",
    "display(genes.head())\n",
    "joined = genes.join(pathways)\n",
    "print(joined.shape)\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### outputting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "joined.reset_index().to_csv('../../data/gsea_categories_proteins_performance_significance_odds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### joining with gsea statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gsea=(pd.\n",
    "      read_csv('../../data/integrated_bootstrap_conditional_'+\n",
    "               'protein_logit_mean_prerank_report_all_categories.csv',index_col=0)\n",
    "     )\n",
    "print(gsea.shape)\n",
    "display(gsea.head())\n",
    "gsea_predictions = (pd.\n",
    "                   read_csv('../../data/gsea_categories_proteins_'+\n",
    "                            'performance_significance_odds.csv',index_col=0))\n",
    "print(gsea_predictions.shape)\n",
    "display(gsea_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gsea_statistics_predictions = (gsea.\n",
    "set_index(['Term']).\n",
    "join(gsea_predictions.\n",
    "    set_index(['Pathway'])\n",
    "    )\n",
    ")\n",
    "gsea_statistics_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Analysis and plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Intersection of individually predictive proteins and predictive GSEA proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ind_protein_preds = pd.read_csv('../../data/protein_raw_01_within_notwithcohorts_mccv_performance_significance_and_feature_odds_df.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query='mean_validation_roc_auc>0.5 &'+ \\\n",
    "           ' (odds_lwr>1 | odds_upr<1) & '+ \\\n",
    "           '(permuted_odds_lwr<1 & permuted_odds_upr>1) &'+ \\\n",
    "           'importance_bonferroni<0.001 & (importance_bonferroni>=importance_p_value)'\n",
    "ind_predictive_genes = (ind_protein_preds.\n",
    " query(query).\n",
    " Gene_name.\n",
    " unique()\n",
    ")\n",
    "print(len(ind_predictive_genes))\n",
    "ind_predictive_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gsea_statistics_predictions.Gene_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query='mean_validation_roc_auc>0.5 &'+ \\\n",
    "           ' (odds_lwr>1 | odds_upr<1) & '+ \\\n",
    "           '(permuted_odds_lwr<1 & permuted_odds_upr>1) &'+ \\\n",
    "           'Importance_bonferroni<0.001 & (Importance_bonferroni>=Importance_P_value)'\n",
    "(gsea_statistics_predictions.\n",
    "query(query).\n",
    " rename_axis('Pathway').\n",
    " reset_index().\n",
    " loc[:,['Pathway','Gene_name',\n",
    "        'mean_validation_roc_auc','Performance_bonferroni',\n",
    "        'odds_mean','Importance_bonferroni']]\n",
    ").to_csv(dropbox_data+'Significantly_predictive_proteins_within_pathways.csv')\n",
    "gsea_ind_predictive_genes = \\\n",
    "(gsea_statistics_predictions.\n",
    "query(query).\n",
    " Gene_name.\n",
    " unique()\n",
    ")\n",
    "print(len(gsea_ind_predictive_genes))\n",
    "gsea_ind_predictive_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gsea_and_ind_predictive_proteins = np.intersect1d(gsea_ind_predictive_genes,\n",
    "                                                  ind_predictive_genes)\n",
    "print(gsea_and_ind_predictive_proteins)\n",
    "print(len(gsea_and_ind_predictive_proteins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.setdiff1d(gsea_ind_predictive_genes,ind_predictive_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.setdiff1d(ind_predictive_genes,gsea_ind_predictive_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Odds distribution of proteins in different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "edpathways = (gsea.\n",
    " query('fdr<.2 & fdr>pval').\n",
    " Term.\n",
    " unique()\n",
    ")\n",
    "edpathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = (gsea_statistics_predictions.\n",
    " query('Gene_name in @gsea_and_ind_predictive_proteins').\n",
    " rename_axis('Pathway').\n",
    " reset_index().\n",
    " loc[:,['Gene_name','Pathway','odds_mean','Category']].\n",
    " drop_duplicates()\n",
    ")\n",
    "display(data.head())\n",
    "data = data[data.Pathway.isin(edpathways)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['odds_mean'] = np.log(data['odds_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display(data.sort_values('odds_mean',ascending=False).head(20))\n",
    "print(data.sort_values('odds_mean',ascending=False).head(20).Pathway.values)\n",
    "display(data.sort_values('odds_mean',ascending=False).tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(dpi=dpi,figsize=(25,14))\n",
    "sns.stripplot(x='odds_mean',y='Gene_name',hue='Pathway',\n",
    "              data=data,ax=ax,\n",
    "             jitter=True, linewidth=2,size=22,\n",
    "             dodge=True,palette='bright')\n",
    "\n",
    "yticks = [x for x in ax.get_yticklabels()]\n",
    "for i,ytick in enumerate(yticks):\n",
    "    ax.axhline(i,c='gray',alpha=.5,ls='--')\n",
    "    \n",
    "plt.legend(prop={'size': 16},frameon=False)\n",
    "ax.axvline(0,c='red',ls='--')\n",
    "ax.tick_params(labelsize=20)\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlabel(r'Within-Pathway PGD Prediction $\\beta$ Coefficient',size=24)\n",
    "fig.savefig(dropbox_figures+'gsea_pathway_proteins_significant_predictions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Heatmap of significantly predictive Genes by Pathway colored by odds*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = (gsea_statistics_predictions.\n",
    " query('Gene_name in @gsea_ind_predictive_genes').\n",
    " rename_axis('Pathway').\n",
    " reset_index().\n",
    " loc[:,['Gene_name','Pathway','odds_mean','Category']].\n",
    " drop_duplicates().\n",
    "        pivot_table(index='Pathway',columns='Gene_name',values='odds_mean').\n",
    "        applymap(lambda x : np.log(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=dpi,figsize=(15,30))\n",
    "sns.heatmap(data,ax=ax,cmap='seismic',linewidth=.1,linecolor='black',center=0)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.set_xticks(ax.get_xticks())\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45,ha=\"center\")\n",
    "fig.savefig(\n",
    "    dropbox_figures+'Pathway_by_significantly_predicting_gsea_proteins_heatmap.png', \n",
    "    bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Heatmap of significantly predictive Genes by Pathway colored by odds*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = (gsea_statistics_predictions.\n",
    " query('Gene_name in @gsea_and_ind_predictive_proteins').\n",
    " rename_axis('Pathway').\n",
    " reset_index().\n",
    " loc[:,['Gene_name','Pathway','odds_mean','Category']].\n",
    " drop_duplicates().\n",
    "        pivot_table(index='Pathway',columns='Gene_name',values='odds_mean').\n",
    "        applymap(lambda x : np.log(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=dpi,figsize=(15,30))\n",
    "sns.heatmap(data,ax=ax,cmap='seismic',linewidth=.1,linecolor='black',center=0)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.set_xticks(ax.get_xticks())\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45,ha=\"center\")\n",
    "fig.savefig(\n",
    "    dropbox_figures+'Pathway_by_significantly_predicting_proteins_heatmap.png', \n",
    "    bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "paths = gsea.query('fdr<0.2 & fdr>pval').sort_values('nes',ascending=False).Term.unique()\n",
    "display((gsea_statistics_predictions.\n",
    "        query('Gene_name in @gsea_ind_predictive_genes').\n",
    "        rename_axis('Pathway').\n",
    "        reset_index().\n",
    "        query('Pathway in @paths').\n",
    "        loc[:,['Gene_name','Pathway','nes','Category']].\n",
    "        drop_duplicates()))\n",
    "data = (gsea_statistics_predictions.\n",
    "        rename_axis('Pathway').\n",
    "        reset_index().\n",
    "        query('Pathway in @paths').\n",
    "        loc[:,['Gene_name','Pathway','odds_mean','Category']].\n",
    "        drop_duplicates().\n",
    "        pivot_table(index='Pathway',columns='Gene_name',values='odds_mean').\n",
    "        applymap(lambda x : np.log(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "paths = gsea.sort_values('nes',ascending=False).Term.unique()\n",
    "sig_paths = gsea.query('fdr<0.2 & fdr>pval').sort_values('nes',ascending=False).Term.unique()\n",
    "gsea_sig_data_sig_paths = (gsea_statistics_predictions.\n",
    "        query('Gene_name in @gsea_ind_predictive_genes').\n",
    "        rename_axis('Pathway').\n",
    "        reset_index().\n",
    "        query('Pathway in @sig_paths').\n",
    "        loc[:,['Gene_name','Pathway','odds_mean','Category']].\n",
    "        drop_duplicates().\n",
    "        pivot_table(index='Gene_name',columns='Pathway',values='odds_mean').\n",
    "        applymap(lambda x : np.log(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gsea_sig_and_sig_data_sig_paths = (gsea_statistics_predictions.\n",
    "        query('Gene_name in @gsea_and_ind_predictive_proteins').\n",
    "        rename_axis('Pathway').\n",
    "        reset_index().\n",
    "        query('Pathway in @sig_paths').\n",
    "        loc[:,['Gene_name','Pathway','odds_mean','Category']].\n",
    "        drop_duplicates().\n",
    "        pivot_table(index='Gene_name',columns='Pathway',values='odds_mean').\n",
    "        applymap(lambda x : np.log(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gsea_sig_and_sig_data_paths = (gsea_statistics_predictions.\n",
    "        query('Gene_name in @gsea_and_ind_predictive_proteins').\n",
    "        rename_axis('Pathway').\n",
    "        reset_index().\n",
    "        query('Pathway in @paths').\n",
    "        loc[:,['Gene_name','Pathway','odds_mean','Category']].\n",
    "        drop_duplicates().\n",
    "        pivot_table(index='Gene_name',columns='Pathway',values='odds_mean').\n",
    "        applymap(lambda x : np.log(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gsea_sig_data_paths = (gsea_statistics_predictions.\n",
    "        query('Gene_name in @gsea_ind_predictive_genes').\n",
    "        rename_axis('Pathway').\n",
    "        reset_index().\n",
    "        query('Pathway in @paths').\n",
    "        loc[:,['Gene_name','Pathway','odds_mean','Category']].\n",
    "        drop_duplicates().\n",
    "        pivot_table(index='Gene_name',columns='Pathway',values='odds_mean').\n",
    "        applymap(lambda x : np.log(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sig_data_paths = (gsea_statistics_predictions.\n",
    "        query('Gene_name in @ind_predictive_genes').\n",
    "        rename_axis('Pathway').\n",
    "        reset_index().\n",
    "        query('Pathway in @paths').\n",
    "        loc[:,['Gene_name','Pathway','odds_mean','Category']].\n",
    "        drop_duplicates().\n",
    "        pivot_table(index='Gene_name',columns='Pathway',values='odds_mean').\n",
    "        applymap(lambda x : np.log(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sig_data_sig_paths = (gsea_statistics_predictions.\n",
    "        query('Gene_name in @ind_predictive_genes').\n",
    "        rename_axis('Pathway').\n",
    "        reset_index().\n",
    "        query('Pathway in @sig_paths').\n",
    "        loc[:,['Gene_name','Pathway','odds_mean','Category']].\n",
    "        drop_duplicates().\n",
    "        pivot_table(index='Gene_name',columns='Pathway',values='odds_mean').\n",
    "        applymap(lambda x : np.log(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_sig_paths = (gsea_statistics_predictions.\n",
    "        rename_axis('Pathway').\n",
    "        reset_index().\n",
    "        query('Pathway in @sig_paths').\n",
    "        loc[:,['Gene_name','Pathway','odds_mean','Category']].\n",
    "        drop_duplicates().\n",
    "        pivot_table(index='Gene_name',columns='Pathway',values='odds_mean').\n",
    "        applymap(lambda x : np.log(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = pd.Series(gsea_sig_and_sig_data_sig_paths.columns.values).str.split('[(_]').apply(pd.Series).iloc[:,0].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cols.str.replace(' WP545','').str.replace(' WP15','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.clustermap(gsea_sig_and_sig_data_sig_paths.fillna(0).T,\n",
    "                   cmap='RdBu_r',linewidth=.1,linecolor='black',center=0,\n",
    "                   row_cluster=False,\n",
    "                   figsize=(10,10),\n",
    "                  cbar_kws={\n",
    "                      \"ticks\": np.arange(-1,3,.5)})\n",
    "g.fig.dpi=dpi\n",
    "g.ax_heatmap.set_xlabel('')\n",
    "g.ax_heatmap.set_ylabel('')\n",
    "g.ax_heatmap.set_yticks(g.ax_heatmap.get_yticks())\n",
    "g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xticklabels(),fontsize=20,rotation=0)\n",
    "g.ax_heatmap.set_yticklabels(cols,\n",
    "                             rotation=0,ha='left',fontsize=20)\n",
    "plt.savefig(\n",
    "    dropbox_figures+'Significant_pathway_by_significantly_predicting_proteins_heatmap.png', \n",
    "    bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Fisher test of enrichment of significantly predictive proteins in enriched/depleted GSEA pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ind_protein_preds = pd.read_csv('../../data/protein_raw_01_within_notwithcohorts_mccv_performance_significance_and_feature_odds_df.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ind_all_genes = (ind_protein_preds.\n",
    " Gene_name.\n",
    " unique()\n",
    ")\n",
    "print(len(ind_all_genes))\n",
    "query='mean_validation_roc_auc>0.5 &'+ \\\n",
    "           ' (odds_lwr>1 | odds_upr<1) & '+ \\\n",
    "           '(permuted_odds_lwr<1 & permuted_odds_upr>1) &'+ \\\n",
    "           'importance_bonferroni<0.001 & (importance_bonferroni>=importance_p_value)'\n",
    "ind_predictive_genes = (ind_protein_preds.\n",
    " query(query).\n",
    " Gene_name.\n",
    " dropna().\n",
    " unique()\n",
    ")\n",
    "print(len(ind_predictive_genes))\n",
    "ind_predictive_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gsea_ind_all_genes = \\\n",
    "(gsea_statistics_predictions.\n",
    " Gene_name.\n",
    " dropna().\n",
    " unique()\n",
    ")\n",
    "print(len(gsea_ind_all_genes))\n",
    "query='mean_validation_roc_auc>0.5 &'+ \\\n",
    "           ' (odds_lwr>1 | odds_upr<1) & '+ \\\n",
    "           '(permuted_odds_lwr<1 & permuted_odds_upr>1) &'+ \\\n",
    "           'Importance_bonferroni<0.001 & (Importance_bonferroni>=Importance_P_value)'\n",
    "gsea_ind_predictive_genes = \\\n",
    "(gsea_statistics_predictions.\n",
    "query(query).\n",
    " Gene_name.\n",
    " unique()\n",
    ")\n",
    "print(len(gsea_ind_predictive_genes))\n",
    "gsea_ind_predictive_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gsea_and_ind_predictive_proteins = np.intersect1d(gsea_ind_predictive_genes,ind_predictive_genes)\n",
    "print(gsea_and_ind_predictive_proteins)\n",
    "print(len(gsea_and_ind_predictive_proteins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gsea_ind_not_predictive_genes = np.setdiff1d(gsea_ind_all_genes,gsea_ind_predictive_genes)\n",
    "ind_not_predictive_genes = np.setdiff1d(ind_all_genes,ind_predictive_genes)\n",
    "print(len(gsea_ind_not_predictive_genes))\n",
    "print(len(ind_not_predictive_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = len(np.intersect1d(ind_predictive_genes,gsea_ind_predictive_genes))\n",
    "print(a)\n",
    "b = len(np.setdiff1d(ind_predictive_genes,gsea_ind_not_predictive_genes))\n",
    "print(b)\n",
    "c = len(np.setdiff1d(ind_not_predictive_genes,gsea_ind_predictive_genes))\n",
    "print(c)\n",
    "d = len(np.union1d(ind_not_predictive_genes,gsea_ind_not_predictive_genes))\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "oddsratio, pvalue = stats.fisher_exact([[a,b],[c,d]])\n",
    "print(oddsratio)\n",
    "print(pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Two marker panel bootstrap validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "std_name='01_within_notwithcohorts'\n",
    "basename = '../../data/integrated_pgd_predictions/'+\\\n",
    "'raw_'+std_name+'_clinicalclinical_proteinclinical_proteinprotein_and_clinical_and_protein_features_small_combos_pgd_prediction_'\n",
    "\n",
    "perf_df = pd.read_csv(basename+'agg_performance.csv',index_col=0).query('set in @sets_to_use')\n",
    "fimps_df = (pd.\n",
    "            read_csv(basename+'agg_feature_importances.csv',\n",
    "                     index_col=0).\n",
    "            query('Feature!=\"Intercept\"').\n",
    "            query('Feature not in @features_not_to_see').\n",
    "            query('set in @sets_to_use')\n",
    "           )\n",
    "\n",
    "query='mean_validation_roc_auc>0.5 &'+ \\\n",
    "           ' (odds_lwr>1 | odds_upr<1) & '+ \\\n",
    "           '(permuted_odds_lwr<1 & permuted_odds_upr>1) &'+ \\\n",
    "           'importance_bonferroni<0.001 & (importance_bonferroni>=importance_p_value)'\n",
    "predictive_proteins =  \\\n",
    "(pd.\n",
    " read_csv('../../data/protein_raw_'+std_name+'_mccv_performance_significance_and_feature_odds_df.csv',\n",
    "          index_col=0).\n",
    " query(query).\n",
    " feature.\n",
    " unique()\n",
    ")\n",
    "predictive_clinicals =  \\\n",
    "(pd.\n",
    " read_csv('../../data/clinical_'+std_name+'_mccv_performance_significance_and_feature_odds_df.csv',\n",
    "          index_col=0).\n",
    " query(query).\n",
    " feature.\n",
    " unique()\n",
    ")\n",
    "\n",
    "umarkers = np.union1d(predictive_proteins,predictive_clinicals)\n",
    "feature_set = pickle.load(open(basename+'feature_set_dictionary.pkl','rb'))\n",
    "sets_to_use = [k for \n",
    " k,v in feature_set.items() if len(np.intersect1d(umarkers,v))==len(v)]\n",
    "X_all_clinical = pd.read_csv(dir_+cohort+'_X_clinical_and_cohort_minus_paris_covariates.csv',index_col=0)\n",
    "features_not_to_see = [x for x in X_all_clinical.columns if 'Cohort_' in x]\n",
    "\n",
    "def get_validation_scores(set_):\n",
    "    \n",
    "    try:\n",
    "        dat = fimps_df.query('set==@set_')\n",
    "        lst = []\n",
    "        fs = dat.Feature.tolist()\n",
    "        lst = [fs]\n",
    "        vals = perf_df.query('set==@set_').values[0]\n",
    "        lst.extend(vals)\n",
    "        return lst\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "m = []\n",
    "params = {}\n",
    "arrs = Parallel(backend='threading')(delayed(get_validation_scores)(set_,**params) for \n",
    "                                     set_ in sets_to_use)\n",
    "tmp = pd.DataFrame(arrs,columns=['Features','set','2.5%','mean','97.5%'])\n",
    "\n",
    "m.extend([tmp])\n",
    "tmp.set = tmp.set.astype(int)\n",
    "display(tmp.sort_values('mean',ascending=False).head())\n",
    "(pd.concat(m).\n",
    " sort_values('mean',ascending=False).\n",
    " to_csv('../../data/marker_combo_'+std_name+'_bootstrap_validation_performance.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "   ### Performance of two marker equations of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "std_name='01_within_notwithcohorts'\n",
    "basename = '../../data/integrated_pgd_predictions/'+\\\n",
    "'raw_'+std_name+'_clinicalclinical_proteinclinical_proteinprotein_and_clinical_and_protein_features_small_combos_pgd_prediction_'\n",
    "\n",
    "\n",
    "query='mean_validation_roc_auc>0.5 &'+ \\\n",
    "           ' (odds_lwr>1 | odds_upr<1) & '+ \\\n",
    "           '(permuted_odds_lwr<1 & permuted_odds_upr>1) &'+ \\\n",
    "           'importance_bonferroni<0.001 & (importance_bonferroni>=importance_p_value)'\n",
    "predictive_proteins =  \\\n",
    "(pd.\n",
    " read_csv('../../data/protein_raw_'+std_name+'_mccv_performance_significance_and_feature_odds_df.csv',\n",
    "          index_col=0).\n",
    " query(query).\n",
    " feature.\n",
    " unique()\n",
    ")\n",
    "predictive_clinicals =  \\\n",
    "(pd.\n",
    " read_csv('../../data/clinical_'+std_name+'_mccv_performance_significance_and_feature_odds_df.csv',\n",
    "          index_col=0).\n",
    " query(query).\n",
    " feature.\n",
    " unique()\n",
    ")\n",
    "\n",
    "umarkers = np.union1d(predictive_proteins,predictive_clinicals)\n",
    "\n",
    "X_all_proteins = pd.read_csv(dir_+cohort+'_X_raw_all_proteins.csv',index_col=0)\n",
    "X_all_clinical = pd.read_csv(dir_+cohort+'_X_clinical_and_cohort_minus_paris_covariates.csv',index_col=0)\n",
    "X_all = X_all_proteins.join(X_all_clinical)\n",
    "Y = pd.read_csv(dir_+cohort+'_pgd_y.csv',index_col=0,header=None)\n",
    "y_true = Y.values.reshape(1,-1)[0]\n",
    "\n",
    "cumc = pd.read_csv('../../data/df_samples_cumc_allsets.csv',index_col=0).columns.tolist()\n",
    "cedar = pd.read_csv('../../data/df_samples_cedar_allsets.csv',index_col=0).columns.tolist()\n",
    "paris = pd.read_csv('../../data/df_samples_paris_allsets.csv',index_col=0).columns.tolist()\n",
    "\n",
    "y_true = Y.values.reshape(1,-1)[0]\n",
    "y_true_cumc = Y.loc[cumc].values.reshape(1,-1)[0]\n",
    "y_true_cedar = Y.loc[cedar].values.reshape(1,-1)[0]\n",
    "y_true_paris = Y.loc[paris].values.reshape(1,-1)[0]\n",
    "\n",
    "feature_set = pickle.load(open(basename+'feature_set_dictionary.pkl','rb'))\n",
    "sets_to_use = [k for \n",
    " k,v in feature_set.items() if len(np.intersect1d(umarkers,v))==len(v)]\n",
    "features_not_to_see = [x for x in X_all_clinical.columns if 'Cohort_' in x]\n",
    "\n",
    "fimps_df = (pd.\n",
    "            read_csv(basename+'agg_feature_importances.csv',\n",
    "                     index_col=0).\n",
    "            query('Feature!=\"Intercept\"').\n",
    "            query('Feature not in @features_not_to_see').\n",
    "            query('set in @sets_to_use')\n",
    "           )\n",
    "\n",
    "def predict_probability(data, weights):\n",
    "    \"\"\"probability predicted by the logistic regression\"\"\"\n",
    "    score = np.dot(data, weights)\n",
    "    predictions = 1 / (1 + np.exp(-score))\n",
    "    return predictions\n",
    "\n",
    "def get_equation_scores(set_,func,name='roc_auc'):\n",
    "    \n",
    "    dat = fimps_df.query('set==@set_')\n",
    "    fs = dat.Feature.tolist()\n",
    "    equation = dat['mean'].values\n",
    "    X = X_all[fs]\n",
    "    X_cumc = X.loc[cumc]\n",
    "    X_cedar = X.loc[cedar]\n",
    "    X_paris = X.loc[paris]\n",
    "    ps = predict_probability(X,equation)\n",
    "    ps_cumc = predict_probability(X_cumc,equation)\n",
    "    ps_cedar = predict_probability(X_cedar,equation)\n",
    "    ps_paris = predict_probability(X_paris,equation)\n",
    "    return [fs,set_,name,\n",
    "            np.round(func(y_true,ps),4),\n",
    "            np.round(func(y_true_cumc,ps_cumc),4),\n",
    "            np.round(func(y_true_cedar,ps_cedar),4),\n",
    "            np.round(func(y_true_paris,ps_paris),4)]\n",
    "    \n",
    "m = []\n",
    "params={ 'func' : roc_auc_score }\n",
    "arrs = Parallel(backend='threading')(delayed(get_equation_scores)(set_,**params) for \n",
    "                                     set_ in sets_to_use)\n",
    "tmp = (pd.DataFrame(arrs,columns=['Features','set','score',\n",
    "                                 'integrated','cumc','cedar','paris']))\n",
    "m.extend([tmp])\n",
    "display(tmp.sort_values('integrated',ascending=False).head())\n",
    "(pd.concat(m).\n",
    " sort_values('integrated',ascending=False).\n",
    " to_csv('../../data/marker_combo_'+std_name+'_equation_performance_on_our_data.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Inotrope and KLKB1 Panel Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### panel prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "basename = '../../data/integrated_pgd_predictions/'+\\\n",
    "'raw_01_within_notwithcohorts_clinicalclinical_proteinclinical_proteinprotein_and_clinical_and_protein_features_small_combos_pgd_prediction_'\n",
    "feature_set = pickle.load(open(basename+'feature_set_dictionary.pkl','rb'))\n",
    "all_pperf_df = pd.read_csv(basename+'agg_patient_level_data.csv',index_col=0).query('set in @sets_to_use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "k_sets = [k for k,v in feature_set.items() if 'H0YAC1' in v]\n",
    "i_sets = [k for k,v in feature_set.items() if 'Prior_Inotrope_Y' in v]\n",
    "ki_set = np.intersect1d(k_sets,i_sets)[0]\n",
    "ki_pperf = all_pperf_df.query('set==@ki_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_pperf_CI_scores(dat,n=50,scorer=roc_auc_score,seed=seed):\n",
    "    \n",
    "    lsts = []\n",
    "    for b in range(n):\n",
    "        lsts.append(\n",
    "            (dat.\n",
    "             sample(n=dat.shape[0],replace=True,random_state=b).\n",
    "             groupby('cohort').\n",
    "             apply(\n",
    "                 lambda x : scorer(x.y_true,x.y_proba)\n",
    "             )\n",
    "            )\n",
    "        )\n",
    "    cohort_df = (pd.concat(lsts,1).\n",
    "                           T.\n",
    "                           describe(percentiles=[0.025,0.975]).\n",
    "                           loc[['2.5%','mean','97.5%']].\n",
    "                T)\n",
    "\n",
    "    vals = []\n",
    "    for b in range(n):\n",
    "        x = (dat.\n",
    "             sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "            )\n",
    "        vals.append(scorer(x.y_true,x.y_proba))\n",
    "    \n",
    "    integrated_df = (pd.\n",
    "     DataFrame(vals,\n",
    "               columns=['Integrated']).\n",
    "     describe(percentiles=[0.025,0.975]).\n",
    "     loc[['2.5%','mean','97.5%']].T)\n",
    "    return pd.concat([cohort_df,integrated_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compare_cohort_scores(dat1,dat2,f1,f2,n=50,scorer=roc_auc_score,stat_scorer=ks_2samp,seed=seed):\n",
    "    \n",
    "    lsts = []\n",
    "    for b in range(n):\n",
    "        lsts.append(\n",
    "            (dat1.\n",
    "             sample(n=dat1.shape[0],replace=True,random_state=b).\n",
    "             groupby('cohort').\n",
    "             apply(\n",
    "                 lambda x : scorer(x.y_true,x.y_proba)\n",
    "             )\n",
    "            )\n",
    "        )\n",
    "    dat1_df = pd.concat(lsts,1).T\n",
    "\n",
    "    lsts = []\n",
    "    for b in range(n):\n",
    "        lsts.append(\n",
    "            (dat2.\n",
    "             sample(n=dat2.shape[0],replace=True,random_state=b).\n",
    "             groupby('cohort').\n",
    "             apply(\n",
    "                 lambda x : scorer(x.y_true,x.y_proba)\n",
    "             )\n",
    "            )\n",
    "        )\n",
    "    dat2_df = pd.concat(lsts,1).T\n",
    "\n",
    "    lst = []\n",
    "    for c1 in dat1_df:\n",
    "        for c2 in dat2_df:\n",
    "            if c1==c2:\n",
    "                stat,p = stat_scorer(dat1_df.loc[:,c1],dat2_df.loc[:,c2])\n",
    "                lst.append([c1,f1,f2,stat,p])\n",
    "    return pd.DataFrame(lst,columns=['Cohort','Panel1','Panel2',\n",
    "                                     'KS_Statistic','KS_pvalue'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compare_integrated_scores(dat1,dat2,f1,f2,n=50,scorer=roc_auc_score,stat_scorer=ks_2samp,seed=seed):\n",
    "    \n",
    "    lsts = []\n",
    "    for b in range(n):\n",
    "        x = (dat1.\n",
    "         sample(n=dat1.shape[0],replace=True,random_state=b)\n",
    "        )\n",
    "        lsts.append(roc_auc_score(x.y_true,x.y_proba))\n",
    "    dat1_df = pd.DataFrame(lsts,columns=['Integrated'])\n",
    "\n",
    "    lsts = []\n",
    "    for b in range(n):\n",
    "        x = (dat2.\n",
    "         sample(n=dat2.shape[0],replace=True,random_state=b)\n",
    "        )\n",
    "        lsts.append(roc_auc_score(x.y_true,x.y_proba))\n",
    "    dat2_df = pd.DataFrame(lsts,columns=['Integrated'])\n",
    "\n",
    "    lst = []\n",
    "    for c1 in dat1_df:\n",
    "        for c2 in dat2_df:\n",
    "            if c1==c2:\n",
    "                stat,p = stat_scorer(dat1_df.loc[:,c1],dat2_df.loc[:,c2])\n",
    "                lst.append([c1,f1,f2,stat,p])\n",
    "    return pd.DataFrame(lst,columns=['Cohort','Panel1','Panel2',\n",
    "                                     'KS_Statistic','KS_pvalue'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_pperf_scores(dat,n=50,scorer=roc_auc_score,seed=seed):\n",
    "    \n",
    "    lsts = []\n",
    "    for b in range(n):\n",
    "        lsts.append(\n",
    "            (dat.\n",
    "             sample(n=dat.shape[0],replace=True,random_state=b).\n",
    "             groupby('cohort').\n",
    "             apply(\n",
    "                 lambda x : scorer(x.y_true,x.y_proba)\n",
    "             )\n",
    "            )\n",
    "        )\n",
    "    cohort_meaen_series = pd.concat(lsts,1).T.mean()\n",
    "\n",
    "    vals = []\n",
    "    for b in range(n):\n",
    "        x = (dat.\n",
    "             sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "            )\n",
    "        vals.append(scorer(x.y_true,x.y_proba))\n",
    "    \n",
    "    cedar,cumc,paris,all_ = (pd.\n",
    "     concat([pd.concat(lsts,1).\n",
    "             T.\n",
    "             mean(),\n",
    "             pd.Series(np.mean(vals),\n",
    "                       index=['Integrated'])\n",
    "            ]\n",
    "           ).\n",
    "     values)\n",
    "    return [all_,cumc,cedar,paris,\n",
    "            (cumc+cedar+paris)/3,(all_+cumc+cedar+paris)/4,\n",
    "           np.var([cumc,cedar,paris]),np.var([all_,cumc,cedar,paris])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "k_pperf = \\\n",
    "(pd.\n",
    " read_csv('../../data/integrated_pgd_predictions/'+\n",
    "          'protein_raw_01_within_notwithcohorts_features_pgd_prediction_'+\n",
    "          'H0YAC1_prediction_metric_bootstrap_train_test_val_patient_level_data.csv',\n",
    "         index_col=0)\n",
    ")\n",
    "i_pperf = \\\n",
    "(pd.\n",
    " read_csv('../../data/integrated_pgd_predictions/'+\n",
    "          'clinical_01_within_notwithcohorts_features_pgd_prediction_'+\n",
    "          'Prior_Inotrope_Y_prediction_metric_bootstrap_train_test_val_patient_level_data.csv',\n",
    "         index_col=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(k_pperf[['bootstrap','y_proba','cohort']].\n",
    " pivot_table(index='bootstrap',columns='cohort',values='y_proba')).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_boot_cohort_N = \\\n",
    "(pd.DataFrame(\n",
    "    (k_pperf[['bootstrap','cohort']].\n",
    "     groupby('bootstrap')['cohort'].\n",
    "     value_counts()\n",
    "    )).\n",
    " rename(columns = {'cohort' : 'N'}).\n",
    " reset_index().\n",
    " pivot_table(index='bootstrap',columns='cohort',values='N')\n",
    ")\n",
    "val_boot_cohort_N.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### #3, avg within bootstrap then avg across bootstrap validation probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=200)\n",
    "scorer = roc_auc_score\n",
    "scores=[]\n",
    "m=[]\n",
    "for i,grp in ki_pperf.groupby('bootstrap'):\n",
    "    vals=grp.y_proba.values\n",
    "    norm_vals = (vals - min(vals)) / (max(vals) - min(vals))\n",
    "    m.append(vals)\n",
    "    scores.append(scorer(grp.y_true.values,vals))\n",
    "    sns.kdeplot(vals,color='blue',alpha=.1,ax=ax)\n",
    "sns.kdeplot([np.median(j) for j in m],color='red',ax=ax)\n",
    "plt.axvline(np.mean([np.median(j) for j in m]),c='purple',lw=3)\n",
    "print(np.mean(scores))\n",
    "print(np.median(m))\n",
    "print(np.var(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### #3, normalize probabilities and avg within bootstrap then avg across bootstrap validation probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=200)\n",
    "scorer = roc_auc_score\n",
    "scores=[]\n",
    "m=[]\n",
    "v=[]\n",
    "for i,grp in ki_pperf.groupby('bootstrap'):\n",
    "    vals=grp.y_proba.values\n",
    "    norm_vals = (vals - min(vals)) / (max(vals) - min(vals))\n",
    "    m.append(norm_vals)\n",
    "    scores.append(scorer(grp.y_true.values,norm_vals))\n",
    "    sns.kdeplot(norm_vals,color='blue',alpha=.1,ax=ax)\n",
    "sns.kdeplot([np.median(j) for j in m],color='red',ax=ax)\n",
    "plt.axvline(np.mean([np.median(j) for j in m]),c='purple',lw=3)\n",
    "print(np.mean(scores))\n",
    "print(np.median(m))\n",
    "print(np.var(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### #1, bootstrap all 13*200 validation probabilities 50 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=200)\n",
    "dat = ki_pperf.copy()\n",
    "scorer = roc_auc_score\n",
    "n=50\n",
    "m = []\n",
    "scores=[]\n",
    "vars_=[]\n",
    "for b in range(n):\n",
    "    x = (dat.\n",
    "         sample(n=dat.shape[0],replace=True)\n",
    "        )\n",
    "    vals = x.y_proba.values\n",
    "    norm_vals = (vals - min(vals)) / (max(vals) - min(vals))\n",
    "    scores.append(scorer(x.y_true,vals))\n",
    "    sns.kdeplot(vals,color='blue',alpha=.1,ax=ax)\n",
    "    m.append(vals)\n",
    "sns.kdeplot([np.median(j) for j in m],color='red',ax=ax)\n",
    "print(np.mean(scores))\n",
    "print(np.median(m))\n",
    "print(np.var(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### #1, normalize the bootstrap validation probabilities 50 times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=200)\n",
    "dat = ki_pperf.copy()\n",
    "n=50\n",
    "m = []\n",
    "scores=[]\n",
    "vars_=[]\n",
    "for b in range(n):\n",
    "    x = (dat.\n",
    "         sample(n=dat.shape[0],replace=True)\n",
    "        )\n",
    "    vals = x.y_proba.values\n",
    "    norm_vals = (vals - min(vals)) / (max(vals) - min(vals))\n",
    "    scores.append(scorer(x.y_true,norm_vals))\n",
    "    sns.kdeplot(norm_vals,color='blue',alpha=.1,ax=ax)\n",
    "    m.append(norm_vals)\n",
    "sns.kdeplot([np.median(j) for j in m],color='red',ax=ax)\n",
    "print(np.mean(scores))\n",
    "print(np.median(m))\n",
    "print(np.var(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Curves and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('roc_auc')\n",
    "func = roc_auc_score\n",
    "print('k')\n",
    "display(pd.DataFrame(get_pperf_scores(k_pperf,scorer=func),index=['Integrated','Columbia','Cedar',\n",
    "                                                       'Paris','avg_cohort_score',\n",
    "                                                       'avg_score','var_cohort_score',\n",
    "                                                       'var_score']).T)\n",
    "display(get_pperf_CI_scores(k_pperf,scorer=func))\n",
    "print('i')\n",
    "display(pd.DataFrame(get_pperf_scores(i_pperf,scorer=func),index=['Integrated','Columbia','Cedar',\n",
    "                                                       'Paris','avg_cohort_score',\n",
    "                                                       'avg_score','var_cohort_score',\n",
    "                                                       'var_score']).T)\n",
    "display(get_pperf_CI_scores(i_pperf,scorer=func))\n",
    "print('ki')\n",
    "display(pd.DataFrame(get_pperf_scores(ki_pperf,scorer=func),index=['Integrated','Columbia','Cedar',\n",
    "                                                       'Paris','avg_cohort_score',\n",
    "                                                       'avg_score','var_cohort_score',\n",
    "                                                       'var_score']).T)\n",
    "display(get_pperf_CI_scores(ki_pperf,scorer=func))\n",
    "\n",
    "display(compare_integrated_scores(k_pperf,i_pperf,f1='KLKB1',f2='Inotrope',scorer=func))\n",
    "display(compare_integrated_scores(i_pperf,ki_pperf,f1='Inotrope',f2='KLKB1+Inotrope',scorer=func))\n",
    "display(compare_integrated_scores(k_pperf,ki_pperf,f1='KLKB1',f2='KLKB1+Inotrope',scorer=func))\n",
    "\n",
    "print('auprc')\n",
    "func = average_precision_score\n",
    "print('k')\n",
    "display(pd.DataFrame(get_pperf_scores(k_pperf,scorer=func),index=['Integrated','Columbia','Cedar',\n",
    "                                                       'Paris','avg_cohort_score',\n",
    "                                                       'avg_score','var_cohort_score',\n",
    "                                                       'var_score']).T)\n",
    "display(get_pperf_CI_scores(k_pperf,scorer=func))\n",
    "print('i')\n",
    "display(pd.DataFrame(get_pperf_scores(i_pperf,scorer=func),index=['Integrated','Columbia','Cedar',\n",
    "                                                       'Paris','avg_cohort_score',\n",
    "                                                       'avg_score','var_cohort_score',\n",
    "                                                       'var_score']).T)\n",
    "display(get_pperf_CI_scores(i_pperf,scorer=func))\n",
    "print('ki')\n",
    "display(pd.DataFrame(get_pperf_scores(ki_pperf,scorer=func),index=['Integrated','Columbia','Cedar',\n",
    "                                                       'Paris','avg_cohort_score',\n",
    "                                                       'avg_score','var_cohort_score',\n",
    "                                                       'var_score']).T)\n",
    "display(get_pperf_CI_scores(ki_pperf,scorer=func))\n",
    "\n",
    "display(compare_integrated_scores(k_pperf,i_pperf,f1='KLKB1',f2='Inotrope',scorer=func))\n",
    "display(compare_integrated_scores(i_pperf,ki_pperf,f1='Inotrope',f2='KLKB1+Inotrope',scorer=func))\n",
    "display(compare_integrated_scores(k_pperf,ki_pperf,f1='KLKB1',f2='KLKB1+Inotrope',scorer=func))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_pperf_roc_curve_stats(dat,n=50):\n",
    "    \n",
    "    tups = []\n",
    "    for b in range(n):\n",
    "        x = (dat.\n",
    "             sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "            )\n",
    "        f,t,th = roc_curve(x.y_true,x.y_proba)\n",
    "\n",
    "        tups.append(\n",
    "            pd.DataFrame({ 'fpr' : f,\n",
    "                          'tpr' : t,\n",
    "                          't' : th\n",
    "                         }\n",
    "                        )\n",
    "        )\n",
    "\n",
    "    tmp = pd.concat(tups).groupby('t').mean()\n",
    "    fpr = tmp['fpr'].values\n",
    "    tpr = tmp['tpr'].values\n",
    "    return fpr,tpr\n",
    "    \n",
    "def get_pperf_precision_recall_curve_stats(dat,n=50):\n",
    "    \n",
    "    tups = []\n",
    "    for b in range(n):\n",
    "        x = (dat.\n",
    "             sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "            )\n",
    "        r,p,th = precision_recall_curve(x.y_true,x.y_proba)\n",
    "        r = list(r)\n",
    "        p = list(p)\n",
    "        r.pop()\n",
    "        p.pop()\n",
    "        tups.append(\n",
    "            pd.DataFrame({ 'precision' : p,\n",
    "                          'recall' : r,\n",
    "                          't' : th\n",
    "                         }\n",
    "                        )\n",
    "        )\n",
    "\n",
    "    tmp = pd.concat(tups).groupby('t').mean()\n",
    "    p = tmp['precision'].tolist()\n",
    "    r = tmp['recall'].tolist()\n",
    "    p[0] = 1\n",
    "    r[0] = 0\n",
    "    return p,r\n",
    "\n",
    "def plt_atts_roc(ax,fig):\n",
    "    ax.set_xlim(-0.01,1.01)\n",
    "    ax.set_ylim(-0.01,1.01)\n",
    "\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "    ]\n",
    "\n",
    "    # now plot both limits against eachother\n",
    "    ax.plot(lims, lims, 'r--', alpha=0.75, zorder=0)\n",
    "\n",
    "    ax.set_ylabel('Sensitivity',size=18)\n",
    "    ax.set_xlabel('1 - Specificity',size=18)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plt_atts_pr(ax,fig):\n",
    "    ax.set_xlim(-0.01,1.01)\n",
    "    ax.set_ylim(-0.01,1.01)\n",
    "\n",
    "    lims = [\n",
    "        [np.min(ax.get_xlim()), np.max(ax.get_ylim())],  \n",
    "        [np.max(ax.get_xlim()), np.min(ax.get_ylim())]\n",
    "    ]\n",
    "\n",
    "    # now plot both limits against eachother\n",
    "    ax.plot(lims[0], lims[1], 'r--', alpha=0.75, zorder=0)\n",
    "\n",
    "    ax.set_ylabel('Precision',size=18)\n",
    "    ax.set_xlabel('Recall',size=18)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type_='PGD_Prediction_Panel'\n",
    "func=get_pperf_roc_curve_stats\n",
    "fig,ax = plt.subplots(dpi=dpi)\n",
    "\n",
    "fpr,tpr = func(ki_pperf.copy())\n",
    "\n",
    "c='purple'\n",
    "ax.plot(fpr,tpr,c=c)\n",
    "ax.plot(fpr,tpr,'.',c=c,marker='o',mec=c,ms=1,lw=0.00001)\n",
    "fig = plt_atts_roc(ax,fig)\n",
    "\n",
    "fpr,tpr = func(k_pperf.copy())\n",
    "\n",
    "c='red'\n",
    "ax.plot(fpr,tpr,c=c)\n",
    "ax.plot(fpr,tpr,'.',c=c,marker='^',mec=c,ms=1,lw=0.00001)\n",
    "fig = plt_atts_roc(ax,fig)\n",
    "\n",
    "fpr,tpr = func(i_pperf.copy())\n",
    "\n",
    "c='steelblue'\n",
    "ax.plot(fpr,tpr,c=c)\n",
    "ax.plot(fpr,tpr,'.',c=c,marker='s',mec=c,ms=1,lw=0.00001)\n",
    "fig = plt_atts_roc(ax,fig)\n",
    "fig.savefig(dropbox_figures+'All_Cohorts_Best_Clinical_Protein_'+type_+'.png')\n",
    "\n",
    "cohorts=['Columbia','Cedar','Paris']\n",
    "for cohort in cohorts:\n",
    "    fig,ax = plt.subplots(dpi=dpi)\n",
    "\n",
    "    fpr,tpr = func(ki_pperf.query('cohort==@cohort').copy())\n",
    "\n",
    "    c='purple'\n",
    "    ax.plot(fpr,tpr,c=c)\n",
    "    ax.plot(fpr,tpr,'.',c=c,marker='o',mec=c,ms=1,lw=0.001)\n",
    "    fog = plt_atts_roc(ax,fig)\n",
    "\n",
    "    fpr,tpr = func(k_pperf.query('cohort==@cohort').copy())\n",
    "\n",
    "    c='red'\n",
    "    ax.plot(fpr,tpr,c=c)\n",
    "    ax.plot(fpr,tpr,'.',c=c,marker='^',mec=c,ms=1,lw=0.001)\n",
    "    fig = plt_atts_roc(ax,fig)\n",
    "\n",
    "    fpr,tpr = func(i_pperf.query('cohort==@cohort').copy())\n",
    "\n",
    "    c='steelblue'\n",
    "    ax.plot(fpr,tpr,c=c)\n",
    "    ax.plot(fpr,tpr,'.',c=c,marker='s',mec=c,ms=1,lw=0.001)\n",
    "    fig = plt_atts_roc(ax,fig)\n",
    "    fig.savefig(dropbox_figures+cohort+'_Best_Clinical_Protein_'+type_+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type_='PGD_Precision_Recall_Panel'\n",
    "func=get_pperf_precision_recall_curve_stats\n",
    "fig,ax = plt.subplots(dpi=dpi)\n",
    "\n",
    "fpr,tpr = func(ki_pperf.copy())\n",
    "\n",
    "c='purple'\n",
    "ax.plot(fpr,tpr,c=c)\n",
    "ax.plot(fpr,tpr,'.',c=c,marker='o',mec=c,ms=1,lw=0.00001)\n",
    "fig = plt_atts_pr(ax,fig)\n",
    "\n",
    "fpr,tpr = func(k_pperf.copy())\n",
    "\n",
    "c='red'\n",
    "ax.plot(fpr,tpr,c=c)\n",
    "ax.plot(fpr,tpr,'.',c=c,marker='^',mec=c,ms=1,lw=0.00001)\n",
    "fig = plt_atts_pr(ax,fig)\n",
    "\n",
    "fpr,tpr = func(i_pperf.copy())\n",
    "\n",
    "c='steelblue'\n",
    "ax.plot(fpr,tpr,c=c)\n",
    "ax.plot(fpr,tpr,'.',c=c,marker='s',mec=c,ms=1,lw=0.00001)\n",
    "fig = plt_atts_pr(ax,fig)\n",
    "fig.savefig(dropbox_figures+'All_Cohorts_Best_Clinical_Protein_'+type_+'.png')\n",
    "\n",
    "cohorts=['Columbia','Cedar','Paris']\n",
    "for cohort in cohorts:\n",
    "    fig,ax = plt.subplots(dpi=dpi)\n",
    "\n",
    "    fpr,tpr = func(ki_pperf.query('cohort==@cohort').copy())\n",
    "\n",
    "    c='purple'\n",
    "    ax.plot(fpr,tpr,c=c)\n",
    "    ax.plot(fpr,tpr,'.',c=c,marker='o',mec=c,ms=1,lw=0.001)\n",
    "    fog = plt_atts_pr(ax,fig)\n",
    "\n",
    "    fpr,tpr = func(k_pperf.query('cohort==@cohort').copy())\n",
    "\n",
    "    c='red'\n",
    "    ax.plot(fpr,tpr,c=c)\n",
    "    ax.plot(fpr,tpr,'.',c=c,marker='^',mec=c,ms=1,lw=0.001)\n",
    "    fig = plt_atts_pr(ax,fig)\n",
    "\n",
    "    fpr,tpr = func(i_pperf.query('cohort==@cohort').copy())\n",
    "\n",
    "    c='steelblue'\n",
    "    ax.plot(fpr,tpr,c=c)\n",
    "    ax.plot(fpr,tpr,'.',c=c,marker='s',mec=c,ms=1,lw=0.001)\n",
    "    fig = plt_atts_pr(ax,fig)\n",
    "    fig.savefig(dropbox_figures+cohort+'_Best_Clinical_Protein_'+type_+'.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Composite measures vs top panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cvppcwp_pperf = \\\n",
    "(pd.\n",
    " read_csv('../../data/integrated_pgd_predictions/'+\n",
    "          'clinical_01_within_notwithcohorts_features_pgd_prediction_'+\n",
    "          'CVP_PCWP_prediction_metric_bootstrap_train_test_val_patient_level_data.csv',\n",
    "         index_col=0)\n",
    ")\n",
    "meld_pperf = \\\n",
    "(pd.\n",
    " read_csv('../../data/integrated_pgd_predictions/'+\n",
    "          'clinical_01_within_notwithcohorts_features_pgd_prediction_'+\n",
    "          'MELD_prediction_metric_bootstrap_train_test_val_patient_level_data.csv',\n",
    "         index_col=0)\n",
    ")\n",
    "radial_pperf = \\\n",
    "(pd.\n",
    " read_csv('../../data/integrated_pgd_predictions/'+\n",
    "          'clinical_01_within_notwithcohorts_features_pgd_prediction_'+\n",
    "          'Radial_Score_prediction_metric_bootstrap_train_test_val_patient_level_data.csv',\n",
    "         index_col=0)\n",
    ")\n",
    "\n",
    "print('roc_auc')\n",
    "func = roc_auc_score\n",
    "print('cvppcwp')\n",
    "display(pd.DataFrame(get_pperf_scores(cvppcwp_pperf,scorer=func),index=['Integrated','Columbia','Cedar',\n",
    "                                                       'Paris','avg_cohort_score',\n",
    "                                                       'avg_score','var_cohort_score',\n",
    "                                                       'var_score']).T)\n",
    "display(get_pperf_CI_scores(cvppcwp_pperf,scorer=func))\n",
    "print('meld')\n",
    "display(pd.DataFrame(get_pperf_scores(meld_pperf,scorer=func),index=['Integrated','Columbia','Cedar',\n",
    "                                                       'Paris','avg_cohort_score',\n",
    "                                                       'avg_score','var_cohort_score',\n",
    "                                                       'var_score']).T)\n",
    "display(get_pperf_CI_scores(meld_pperf,scorer=func))\n",
    "print('radial')\n",
    "display(pd.DataFrame(get_pperf_scores(radial_pperf,scorer=func),index=['Integrated','Columbia','Cedar',\n",
    "                                                       'Paris','avg_cohort_score',\n",
    "                                                       'avg_score','var_cohort_score',\n",
    "                                                       'var_score']).T)\n",
    "display(get_pperf_CI_scores(radial_pperf,scorer=func))\n",
    "print('ki')\n",
    "display(pd.DataFrame(get_pperf_scores(ki_pperf,scorer=func),index=['Integrated','Columbia','Cedar',\n",
    "                                                       'Paris','avg_cohort_score',\n",
    "                                                       'avg_score','var_cohort_score',\n",
    "                                                       'var_score']).T)\n",
    "display(get_pperf_CI_scores(ki_pperf,scorer=func))\n",
    "\n",
    "display(compare_integrated_scores(cvppcwp_pperf,radial_pperf,f1='CVP/PCWP',f2='Radial Score',scorer=func))\n",
    "display(compare_integrated_scores(cvppcwp_pperf,meld_pperf,f1='CVP/PCWP',f2='MELD',scorer=func))\n",
    "display(compare_integrated_scores(meld_pperf,radial_pperf,f1='MELD',f2='Radial Score',scorer=func))\n",
    "display(compare_integrated_scores(radial_pperf,ki_pperf,f1='Radial Score',f2='KLKB1+Inotrope',scorer=func))\n",
    "display(compare_integrated_scores(cvppcwp_pperf,ki_pperf,f1='CVP/PCWP',f2='KLKB1+Inotrope',scorer=func))\n",
    "display(compare_integrated_scores(meld_pperf,ki_pperf,f1='MELD',f2='KLKB1+Inotrope',scorer=func))\n",
    "\n",
    "print('auprc')\n",
    "func=average_precision_score\n",
    "print('cvppcwp')\n",
    "display(pd.DataFrame(get_pperf_scores(cvppcwp_pperf,scorer=func),index=['Integrated','Columbia','Cedar',\n",
    "                                                       'Paris','avg_cohort_score',\n",
    "                                                       'avg_score','var_cohort_score',\n",
    "                                                       'var_score']).T)\n",
    "display(get_pperf_CI_scores(cvppcwp_pperf,scorer=func))\n",
    "print('meld')\n",
    "display(pd.DataFrame(get_pperf_scores(meld_pperf,scorer=func),index=['Integrated','Columbia','Cedar',\n",
    "                                                       'Paris','avg_cohort_score',\n",
    "                                                       'avg_score','var_cohort_score',\n",
    "                                                       'var_score']).T)\n",
    "display(get_pperf_CI_scores(meld_pperf,scorer=func))\n",
    "print('radial')\n",
    "display(pd.DataFrame(get_pperf_scores(radial_pperf,scorer=func),index=['Integrated','Columbia','Cedar',\n",
    "                                                       'Paris','avg_cohort_score',\n",
    "                                                       'avg_score','var_cohort_score',\n",
    "                                                       'var_score']).T)\n",
    "display(get_pperf_CI_scores(radial_pperf,scorer=func))\n",
    "print('ki')\n",
    "display(pd.DataFrame(get_pperf_scores(ki_pperf,scorer=func),index=['Integrated','Columbia','Cedar',\n",
    "                                                       'Paris','avg_cohort_score',\n",
    "                                                       'avg_score','var_cohort_score',\n",
    "                                                       'var_score']).T)\n",
    "display(get_pperf_CI_scores(ki_pperf,scorer=func))\n",
    "\n",
    "display(compare_integrated_scores(cvppcwp_pperf,radial_pperf,f1='CVP/PCWP',f2='Radial Score',scorer=func))\n",
    "display(compare_integrated_scores(cvppcwp_pperf,meld_pperf,f1='CVP/PCWP',f2='MELD',scorer=func))\n",
    "display(compare_integrated_scores(meld_pperf,radial_pperf,f1='MELD',f2='Radial Score',scorer=func))\n",
    "display(compare_integrated_scores(radial_pperf,ki_pperf,f1='Radial Score',f2='KLKB1+Inotrope',scorer=func))\n",
    "display(compare_integrated_scores(cvppcwp_pperf,ki_pperf,f1='CVP/PCWP',f2='KLKB1+Inotrope',scorer=func))\n",
    "display(compare_integrated_scores(meld_pperf,ki_pperf,f1='MELD',f2='KLKB1+Inotrope',scorer=func))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type_='PGD_Prediction_Composite_Panel'\n",
    "func=get_pperf_roc_curve_stats\n",
    "fig,ax = plt.subplots(dpi=dpi)\n",
    "\n",
    "fpr,tpr = func(cvppcwp_pperf.copy())\n",
    "\n",
    "c='brown'\n",
    "ax.plot(fpr,tpr,c=c)\n",
    "ax.plot(fpr,tpr,'.',c=c,marker='X',mec=c,ms=1,lw=0.00001)\n",
    "fig = plt_atts_roc(ax,fig)\n",
    "\n",
    "fpr,tpr = func(radial_pperf.copy())\n",
    "\n",
    "c='blue'\n",
    "ax.plot(fpr,tpr,c=c)\n",
    "ax.plot(fpr,tpr,'.',c=c,marker='D',mec=c,ms=1,lw=0.00001)\n",
    "fig = plt_atts_roc(ax,fig)\n",
    "\n",
    "fpr,tpr = func(meld_pperf.copy())\n",
    "\n",
    "c='orange'\n",
    "ax.plot(fpr,tpr,c=c)\n",
    "ax.plot(fpr,tpr,'.',c=c,marker='p',mec=c,ms=1,lw=0.00001)\n",
    "fig = plt_atts_roc(ax,fig)\n",
    "\n",
    "fpr,tpr = func(ki_pperf.copy())\n",
    "\n",
    "c='purple'\n",
    "ax.plot(fpr,tpr,c=c)\n",
    "ax.plot(fpr,tpr,'.',c=c,marker='o',mec=c,ms=1,lw=0.00001)\n",
    "fig = plt_atts_roc(ax,fig)\n",
    "fig.savefig(dropbox_figures+'All_Cohorts_Best_Clinical_Protein_'+type_+'.png')\n",
    "\n",
    "cohorts=['Columbia','Cedar','Paris']\n",
    "for cohort in cohorts:\n",
    "    fig,ax = plt.subplots(dpi=dpi)\n",
    "\n",
    "    fpr,tpr = func(cvppcwp_pperf.query('cohort==@cohort').copy())\n",
    "\n",
    "    c='brown'\n",
    "    ax.plot(fpr,tpr,c=c)\n",
    "    ax.plot(fpr,tpr,'.',c=c,marker='X',mec=c,ms=1,lw=0.001)\n",
    "    fog = plt_atts_roc(ax,fig)\n",
    "\n",
    "    fpr,tpr = func(radial_pperf.query('cohort==@cohort').copy())\n",
    "\n",
    "    c='blue'\n",
    "    ax.plot(fpr,tpr,c=c)\n",
    "    ax.plot(fpr,tpr,'.',c=c,marker='D',mec=c,ms=1,lw=0.001)\n",
    "    fig = plt_atts_roc(ax,fig)\n",
    "\n",
    "    fpr,tpr = func(meld_pperf.query('cohort==@cohort').copy())\n",
    "\n",
    "    c='orange'\n",
    "    ax.plot(fpr,tpr,c=c)\n",
    "    ax.plot(fpr,tpr,'.',c=c,marker='p',mec=c,ms=1,lw=0.001)\n",
    "    fig = plt_atts_roc(ax,fig)\n",
    "\n",
    "    fpr,tpr = func(ki_pperf.query('cohort==@cohort').copy())\n",
    "    \n",
    "    c='purple'\n",
    "    ax.plot(fpr,tpr,c=c)\n",
    "    ax.plot(fpr,tpr,'.',c=c,marker='o',mec=c,ms=1,lw=0.001)\n",
    "    fig = plt_atts_roc(ax,fig)\n",
    "\n",
    "    fig.savefig(dropbox_figures+cohort+'_Best_Clinical_Protein_'+type_+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type_='PGD_Precision_Recall_Composite_Panel'\n",
    "func=get_pperf_precision_recall_curve_stats\n",
    "fig,ax = plt.subplots(dpi=dpi)\n",
    "\n",
    "fpr,tpr = func(cvppcwp_pperf.copy())\n",
    "\n",
    "c='brown'\n",
    "ax.plot(fpr,tpr,c=c)\n",
    "ax.plot(fpr,tpr,'.',c=c,marker='X',mec=c,ms=1,lw=0.00001)\n",
    "fig = plt_atts_pr(ax,fig)\n",
    "\n",
    "fpr,tpr = func(radial_pperf.copy())\n",
    "\n",
    "c='blue'\n",
    "ax.plot(fpr,tpr,c=c)\n",
    "ax.plot(fpr,tpr,'.',c=c,marker='D',mec=c,ms=1,lw=0.00001)\n",
    "fig = plt_atts_pr(ax,fig)\n",
    "\n",
    "fpr,tpr = func(meld_pperf.copy())\n",
    "\n",
    "c='orange'\n",
    "ax.plot(fpr,tpr,c=c)\n",
    "ax.plot(fpr,tpr,'.',c=c,marker='p',mec=c,ms=1,lw=0.00001)\n",
    "fig = plt_atts_pr(ax,fig)\n",
    "\n",
    "fpr,tpr = func(ki_pperf.copy())\n",
    "\n",
    "c='purple'\n",
    "ax.plot(fpr,tpr,c=c)\n",
    "ax.plot(fpr,tpr,'.',c=c,marker='o',mec=c,ms=1,lw=0.00001)\n",
    "fig = plt_atts_pr(ax,fig)\n",
    "fig.savefig(dropbox_figures+'All_Cohorts_Best_Clinical_Protein_'+type_+'.png')\n",
    "\n",
    "cohorts=['Columbia','Cedar','Paris']\n",
    "for cohort in cohorts:\n",
    "    fig,ax = plt.subplots(dpi=dpi)\n",
    "\n",
    "    fpr,tpr = func(cvppcwp_pperf.query('cohort==@cohort').copy())\n",
    "\n",
    "    c='brown'\n",
    "    ax.plot(fpr,tpr,c=c)\n",
    "    ax.plot(fpr,tpr,'.',c=c,marker='X',mec=c,ms=1,lw=0.001)\n",
    "    fog = plt_atts_pr(ax,fig)\n",
    "\n",
    "    fpr,tpr = func(radial_pperf.query('cohort==@cohort').copy())\n",
    "\n",
    "    c='blue'\n",
    "    ax.plot(fpr,tpr,c=c)\n",
    "    ax.plot(fpr,tpr,'.',c=c,marker='D',mec=c,ms=1,lw=0.001)\n",
    "    fig = plt_atts_pr(ax,fig)\n",
    "\n",
    "    fpr,tpr = func(meld_pperf.query('cohort==@cohort').copy())\n",
    "\n",
    "    c='orange'\n",
    "    ax.plot(fpr,tpr,c=c)\n",
    "    ax.plot(fpr,tpr,'.',c=c,marker='p',mec=c,ms=1,lw=0.001)\n",
    "    fig = plt_atts_pr(ax,fig)\n",
    "\n",
    "    fpr,tpr = func(ki_pperf.query('cohort==@cohort').copy())\n",
    "    \n",
    "    c='purple'\n",
    "    ax.plot(fpr,tpr,c=c)\n",
    "    ax.plot(fpr,tpr,'.',c=c,marker='o',mec=c,ms=1,lw=0.001)\n",
    "    fig = plt_atts_pr(ax,fig)\n",
    "\n",
    "    fig.savefig(dropbox_figures+cohort+'_Best_Clinical_Protein_'+type_+'.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inotrope therapy prediction in each cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /Users/nickgiangreco/Research/Projects/exosome_pgf/src/python/prediction_functions.py\n",
    "\n",
    "\n",
    "metric = 'roc_auc'\n",
    "cv_split = 10\n",
    "n_jobs = 20\n",
    "nboot=200\n",
    "test_size = 0.15\n",
    "treat='PGD'\n",
    "i=0\n",
    "classification_metrics = ['roc_auc']\n",
    "\n",
    "dir_=\"../../data/\"\n",
    "cohort = 'integrated'\n",
    "\n",
    "def get_performance(lst):\n",
    "    perf = (pd.\n",
    "            concat(lst,keys=range(len(lst))).\n",
    "            reset_index(level=1,drop=True).\n",
    "            rename_axis('bootstrap').\n",
    "            reset_index()\n",
    "           )\n",
    "    return perf\n",
    "\n",
    "def model_feature_importances(boot_mods):\n",
    "    dfs = []\n",
    "    X = params['X'].copy()\n",
    "    X.loc[:,'Intercept'] = 0\n",
    "    for i in range(len(boot_mods)):\n",
    "        for j in boot_mods[i].keys():\n",
    "            mod = boot_mods[i][j]\n",
    "            coef = []\n",
    "            try:\n",
    "                coef.extend([i for i in mod.feature_importances_])\n",
    "            except:\n",
    "                coef.extend([i for i in mod.coef_[0]])\n",
    "            coef.extend(mod.intercept_)\n",
    "            fs = []\n",
    "            fs.extend(X.columns.values)\n",
    "            df = pd.DataFrame({\n",
    "                'Feature' : fs,\n",
    "                'Gene_name' : (X.T.\n",
    "                               join(idmap_sub.\n",
    "                                    set_index('Protein'),how='left').\n",
    "                               Gene_name.values),\n",
    "                'Importance' : coef,\n",
    "                'Model' : j,\n",
    "                'Bootstrap' : i\n",
    "            })\n",
    "            dfs.append(df)\n",
    "    return pd.concat(dfs,sort=True)\n",
    "\n",
    "def patient_predictions(lst):\n",
    "        dat = \\\n",
    "        (pd.\n",
    "         concat(\n",
    "             lst\n",
    "         ).\n",
    "         reset_index().\n",
    "         rename(columns={0 : 'Sample'}).\n",
    "         set_index('Sample').\n",
    "         join(all_cov_df,how='left').\n",
    "         reset_index().\n",
    "         melt(id_vars=['Sample','bootstrap','model','y_true','y_pred','y_proba'],\n",
    "              var_name='cohort',value_name='mem')\n",
    "        )\n",
    "        dat.cohort = dat.cohort.str.split('_').apply(lambda x : x[1])\n",
    "        dat = dat[dat.mem==1].drop('mem',1).reset_index(drop=True)\n",
    "        return dat\n",
    "\n",
    "X_all_proteins = pd.read_csv(dir_+cohort+'_X_raw_all_proteins.csv',index_col=0)\n",
    "X_all_clinical = pd.read_csv(dir_+cohort+'_X_clinical_and_cohort_covariates.csv',index_col=0)\n",
    "Y = pd.read_csv(dir_+cohort+'_pgd_y.csv',index_col=0,header=None)\n",
    "\n",
    "cov_df = X_all_clinical.loc[:,['Cohort_Columbia','Cohort_Cedar']].copy().astype(int)\n",
    "all_cov_df = cov_df.copy()\n",
    "all_cov_df.loc[:,'Cohort_Paris'] = (\n",
    "    (all_cov_df['Cohort_Columbia'] + \n",
    "     all_cov_df['Cohort_Cedar'])==0).astype(int)\n",
    "\n",
    "idmap_sub = pd.read_csv('../../data/protein_gene_map_full.csv')[['Protein','Gene_name']].dropna()\n",
    "\n",
    "features = ['Prior_Inotrope_Y']\n",
    "\n",
    "X_all = X_all_proteins.join(X_all_clinical)\n",
    "X = X_all[features]\n",
    "feature_set[str(i)] = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "params = {'X' : X,'Y' : Y, 'cv_split' : cv_split, \n",
    "\t\t  'metrics' : classification_metrics, 'n_jobs' : 1, \n",
    "\t\t  'test_size' : test_size,\n",
    "\t\t  'retrained_models' : True, 'patient_level_predictions' : True,\n",
    "         'models' : l1_logit_model.copy()}\n",
    "lst = bootstrap_of_fcn(func=train_test_val_top_fold_01_within,\n",
    "               params=params,n_jobs=n_jobs,nboot=nboot)\n",
    "perf_all = get_performance([lst[i][0] for i in range(len(lst))])\n",
    "perf_all['set'] = str(i)\n",
    "fimps_all = model_feature_importances([lst[i][1] for i in range(len(lst))])\n",
    "fimps_all['set'] = str(i)\n",
    "ppreds_all = patient_predictions([lst[i][2] for i in range(len(lst))])\n",
    "ppreds_all['set'] = str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppreds_all.groupby(['cohort','y_true'])['y_proba'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pperf_dat_processing(ppreds_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex_F prediction - investigating AUROC<0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /Users/nickgiangreco/Research/Projects/exosome_pgf/src/python/prediction_functions.py\n",
    "\n",
    "\n",
    "metric = 'roc_auc'\n",
    "cv_split = 10\n",
    "n_jobs = 20\n",
    "nboot=200\n",
    "test_size = 0.15\n",
    "treat='PGD'\n",
    "i=0\n",
    "classification_metrics = ['roc_auc']\n",
    "\n",
    "dir_=\"../../data/\"\n",
    "cohort = 'integrated'\n",
    "\n",
    "def get_performance(lst):\n",
    "    perf = (pd.\n",
    "            concat(lst,keys=range(len(lst))).\n",
    "            reset_index(level=1,drop=True).\n",
    "            rename_axis('bootstrap').\n",
    "            reset_index()\n",
    "           )\n",
    "    return perf\n",
    "\n",
    "def model_feature_importances(boot_mods):\n",
    "    dfs = []\n",
    "    X = params['X'].copy()\n",
    "    X.loc[:,'Intercept'] = 0\n",
    "    for i in range(len(boot_mods)):\n",
    "        for j in boot_mods[i].keys():\n",
    "            mod = boot_mods[i][j]\n",
    "            coef = []\n",
    "            try:\n",
    "                coef.extend([i for i in mod.feature_importances_])\n",
    "            except:\n",
    "                coef.extend([i for i in mod.coef_[0]])\n",
    "            coef.extend(mod.intercept_)\n",
    "            fs = []\n",
    "            fs.extend(X.columns.values)\n",
    "            df = pd.DataFrame({\n",
    "                'Feature' : fs,\n",
    "                'Gene_name' : (X.T.\n",
    "                               join(idmap_sub.\n",
    "                                    set_index('Protein'),how='left').\n",
    "                               Gene_name.values),\n",
    "                'Importance' : coef,\n",
    "                'Model' : j,\n",
    "                'Bootstrap' : i\n",
    "            })\n",
    "            dfs.append(df)\n",
    "    return pd.concat(dfs,sort=True)\n",
    "\n",
    "def patient_predictions(lst):\n",
    "        dat = \\\n",
    "        (pd.\n",
    "         concat(\n",
    "             lst\n",
    "         ).\n",
    "         reset_index().\n",
    "         rename(columns={0 : 'Sample'}).\n",
    "         set_index('Sample').\n",
    "         join(all_cov_df,how='left').\n",
    "         reset_index().\n",
    "         melt(id_vars=['Sample','bootstrap','model','y_true','y_pred','y_proba'],\n",
    "              var_name='cohort',value_name='mem')\n",
    "        )\n",
    "        dat.cohort = dat.cohort.str.split('_').apply(lambda x : x[1])\n",
    "        dat = dat[dat.mem==1].drop('mem',1).reset_index(drop=True)\n",
    "        return dat\n",
    "\n",
    "X_all_proteins = pd.read_csv(dir_+cohort+'_X_raw_all_proteins.csv',index_col=0)\n",
    "X_all_clinical = pd.read_csv(dir_+cohort+'_X_clinical_and_cohort_covariates.csv',index_col=0)\n",
    "Y = pd.read_csv(dir_+cohort+'_pgd_y.csv',index_col=0,header=None)\n",
    "\n",
    "cov_df = X_all_clinical.loc[:,['Cohort_Columbia','Cohort_Cedar']].copy().astype(int)\n",
    "all_cov_df = cov_df.copy()\n",
    "all_cov_df.loc[:,'Cohort_Paris'] = (\n",
    "    (all_cov_df['Cohort_Columbia'] + \n",
    "     all_cov_df['Cohort_Cedar'])==0).astype(int)\n",
    "\n",
    "idmap_sub = pd.read_csv('../../data/protein_gene_map_full.csv')[['Protein','Gene_name']].dropna()\n",
    "\n",
    "features = ['Sex_F']\n",
    "\n",
    "X_all = X_all_proteins.join(X_all_clinical)\n",
    "X = X_all[features]\n",
    "tmp = X.join(Y)\n",
    "tmp['mem'] = 1\n",
    "tmp.groupby(['Sex_F',1])['mem'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpgd = Y.index.values[Y.values.reshape(1,-1)[0]==0]\n",
    "pgd = Y.index.values[Y.values.reshape(1,-1)[0]==1]\n",
    "male = X.index.values[X.values.reshape(1,-1)[0]==0]\n",
    "female = X.index.values[X.values.reshape(1,-1)[0]==1]\n",
    "val=1\n",
    "Y.at[np.intersect1d(male,nonpgd)[:9],1] = 1\n",
    "#X.at[np.intersect1d(female,nonpgd)[:5],'Sex_F'] = 0\n",
    "#Y.at[np.intersect1d(male,pgd)[:5],1] = 0\n",
    "#X.at[np.intersect1d(female,pgd)[:5],'Sex_F'] = 0\n",
    "tmp = X.join(Y)\n",
    "tmp['mem'] = 1\n",
    "tmp.groupby(['Sex_F',1])['mem'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = X.rename(columns={'Sex_F' : 'Sex_new'})\n",
    "tmp['Sex_new'] = np.random.randint(0,2,X.shape[0])\n",
    "X = tmp\n",
    "#tmp.to_csv('../../X.csv')\n",
    "Y =  pd.Series(np.random.randint(0,2,X.shape[0]),index=Y.index)\n",
    "Y.name=1\n",
    "tmp = X.join(Y)\n",
    "tmp['mem'] = 1\n",
    "tmp.groupby(['Sex_new',1])['mem'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "i=0\n",
    "params = {'X' : X,'Y' : Y, 'cv_split' : cv_split, \n",
    "\t\t  'metrics' : classification_metrics, 'n_jobs' : 1, \n",
    "\t\t  'test_size' : test_size,\n",
    "\t\t  'retrained_models' : True, 'patient_level_predictions' : True,\n",
    "         'models' : {'Logistic Regression' : LogisticRegression(solver='saga')}}\n",
    "lst = bootstrap_of_fcn(func=train_test_val_top_fold_01_within_unveiled,\n",
    "               params=params,n_jobs=n_jobs,nboot=nboot)\n",
    "perf_all = get_performance([lst[i][0] for i in range(len(lst))])\n",
    "perf_all['set'] = str(i)\n",
    "fimps_all = model_feature_importances([lst[i][1] for i in range(len(lst))])\n",
    "fimps_all['set'] = str(i)\n",
    "ppreds_all = patient_predictions([lst[i][2] for i in range(len(lst))])\n",
    "ppreds_all['set'] = str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,mod in enumerate([lst[i][1] for i in range(len(lst))]):\n",
    "    X_train, y_train, X_test, y_test = [lst[i][3] for i in range(len(lst))][i]\n",
    "    auroc = roc_auc_score(y_test.values.reshape(1,-1)[0],\n",
    "                          mod['Logistic Regression'].predict_proba(X_test)[:,1])\n",
    "    if auroc<.5:\n",
    "        print(y_test.values.reshape(1,-1)[0])\n",
    "        print(mod['Logistic Regression'].coef_[0][0])\n",
    "        print(mod['Logistic Regression'].predict_proba(X_test)[:,1])\n",
    "        print(auroc,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XY_data_processing(lst,cov='Sex_F',cov_name='females',noncov_name='males'):\n",
    "    X_train, y_train, X_test, y_test = lst\n",
    "    train_cov_breakdown = X_train.join(y_train).groupby([cov]).sum().reindex([0,1]).fillna(0)\n",
    "    train_pgd_breakdown = X_train.join(y_train).groupby([1]).sum().reindex([0,1]).fillna(0)\n",
    "    train_total = X_train.shape[0]\n",
    "    train_cov = train_pgd_breakdown.sum().values[0]\n",
    "    train_noncov = train_total - train_cov\n",
    "    train_pgd = train_cov_breakdown.sum().values[0]\n",
    "    train_nonpgd = train_total - train_pgd\n",
    "    train_nonpgd_cov = train_pgd_breakdown.loc[0].values[0]\n",
    "    train_nonpgd_noncov = train_nonpgd - train_nonpgd_cov\n",
    "    train_pgd_cov = train_cov_breakdown.loc[1].values[0]\n",
    "    train_pgd_noncov = train_pgd - train_pgd_cov    \n",
    "\n",
    "    val_cov_breakdown = X_test.join(y_test).groupby([cov]).sum().reindex([0,1]).fillna(0)\n",
    "    val_pgd_breakdown = X_test.join(y_test).groupby([1]).sum().reindex([0,1]).fillna(0)\n",
    "    val_total = X_test.shape[0]\n",
    "    val_cov = val_pgd_breakdown.sum().values[0]\n",
    "    val_noncov = val_total - val_cov\n",
    "    val_pgd = val_cov_breakdown.sum().values[0]\n",
    "    val_nonpgd = val_total - val_pgd\n",
    "    val_nonpgd_cov = val_pgd_breakdown.loc[0].values[0]\n",
    "    val_nonpgd_noncov = val_nonpgd - val_nonpgd_cov\n",
    "    val_pgd_cov = val_cov_breakdown.loc[1].values[0]\n",
    "    val_pgd_noncov = val_pgd - val_pgd_cov\n",
    "    \n",
    "    res = pd.DataFrame(\n",
    "        [train_total,train_nonpgd,train_pgd,\n",
    "         train_cov,train_noncov,\n",
    "         train_nonpgd_noncov, train_nonpgd_cov, train_pgd_noncov, train_pgd_cov,\n",
    "         val_total,val_nonpgd,val_pgd,\n",
    "         val_cov,val_noncov,\n",
    "         val_nonpgd_noncov, val_nonpgd_cov,val_pgd_noncov, val_pgd_cov],\n",
    "        index=['N_training','N_training_nonpgd','N_training_pgd',\n",
    "               'N_training_'+cov_name,'N_training_'+noncov_name,\n",
    "               'N_training_nonpgd_'+noncov_name,'N_training_nonpgd_'+cov_name,\n",
    "                 'N_training_pgd_'+noncov_name,'N_training_pgd_'+cov_name,\n",
    "                 'N_validation','N_validation_nonpgd','N_validation_pgd',\n",
    "               'N_validation_'+cov_name,'N_validation_'+noncov_name,\n",
    "               'N_validation_nonpgd_'+noncov_name,'N_validation_nonpgd_'+cov_name,\n",
    "                 'N_validation_pgd_'+noncov_name,'N_validation_pgd_'+cov_name]\n",
    "    ).T\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_data_N = \\\n",
    "(pd.concat([XY_data_processing(lst[i][3],cov='Sex_new') for i in range(len(lst))]).\n",
    " reset_index(drop=True).\n",
    " rename_axis('bootstrap').\n",
    " reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=50\n",
    "dat = ppreds_all\n",
    "vals = []\n",
    "for b in range(n):\n",
    "    x = (dat.\n",
    "         sample(n=dat.shape[0],replace=True)\n",
    "        )\n",
    "    vals.append(['Sex_new',b,x.model.unique()[0],roc_auc_score(x.y_true,x.y_proba)])\n",
    "tmp = pd.DataFrame(vals,columns=['Feature','Bootstrap','Model','roc_auc'])\n",
    "tmp['roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_data_imp_score = \\\n",
    "(XY_data_N.\n",
    " join(fimps_all.\n",
    "      query('Feature==\"Sex_new\"').\n",
    "      set_index('Bootstrap')).\n",
    " join(tmp[['Bootstrap','roc_auc']].set_index('Bootstrap')).\n",
    " rename(columns={'roc_auc' : 'bootstrapped_roc_auc',\n",
    "                 'Importance' : 'Beta_Coefficient'})\n",
    ")\n",
    "XY_data_imp_score['Importance'] = [lst[i][1]['Logistic Regression'].coef_[0][0] for i in range(len(lst))]\n",
    "aurocs = []\n",
    "coefs = []\n",
    "for i,mod in enumerate([lst[i][1] for i in range(len(lst))]):\n",
    "    X_train, y_train, X_test, y_test = [lst[i][3] for i in range(len(lst))][i]\n",
    "    auroc = roc_auc_score(y_test.values.reshape(1,-1)[0],\n",
    "                          mod['Logistic Regression'].predict_proba(X_test)[:,1])\n",
    "    coef = mod['Logistic Regression'].coef_[0][0]\n",
    "    coefs.append(coef)\n",
    "    aurocs.append(auroc)\n",
    "XY_data_imp_score['Importance'] = coefs\n",
    "XY_data_imp_score['roc_auc'] = aurocs\n",
    "print(XY_data_imp_score.shape)\n",
    "XY_data_imp_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(XY_data_imp_score['roc_auc']==0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aurocs=[]\n",
    "for i in range(50):\n",
    "    auroc = (XY_data_imp_score.\n",
    "             roc_auc.\n",
    "             sample(n=XY_data_imp_score.shape[0],replace=True).\n",
    "             mean()\n",
    "            )\n",
    "    aurocs.append(auroc)\n",
    "plt.hist(aurocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_data_imp_score[['roc_auc']].describe(percentiles=[0.025,0.975\n",
    "                                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_data_imp_score[['bootstrapped_roc_auc']].describe(percentiles=[0.025,0.975\n",
    "                                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_data_imp_score['N_training_pgd_females_freq'] = \\\n",
    "XY_data_imp_score['N_training_pgd_females'] / XY_data_imp_score['N_training_pgd']\n",
    "XY_data_imp_score['N_training_nonpgd_females_freq'] = \\\n",
    "XY_data_imp_score['N_training_nonpgd_females'] / XY_data_imp_score['N_training_nonpgd']\n",
    "XY_data_imp_score['N_validation_pgd_females_freq'] = \\\n",
    "XY_data_imp_score['N_validation_pgd_females'] / XY_data_imp_score['N_validation_pgd']\n",
    "XY_data_imp_score['N_validation_nonpgd_females_freq'] = \\\n",
    "XY_data_imp_score['N_validation_nonpgd_females'] / XY_data_imp_score['N_validation_nonpgd']\n",
    "XY_data_imp_score['N_training_pgd_males_freq'] = \\\n",
    "XY_data_imp_score['N_training_pgd_males'] / XY_data_imp_score['N_training_pgd']\n",
    "XY_data_imp_score['N_training_nonpgd_males_freq'] = \\\n",
    "XY_data_imp_score['N_training_nonpgd_males'] / XY_data_imp_score['N_training_nonpgd']\n",
    "XY_data_imp_score['N_validation_pgd_males_freq'] = \\\n",
    "XY_data_imp_score['N_validation_pgd_males'] / XY_data_imp_score['N_validation_pgd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "mod = Ridge(normalize=False)\n",
    "tmp = (XY_data_imp_score.\n",
    "         filter(like='N').\n",
    "       drop(['N_training','N_validation'],1).\n",
    "       filter(regex='females$').\n",
    "         apply(lambda x : (x - min(x)) / (max(x) - min(x)) ))\n",
    "mod.fit(tmp,\n",
    "        XY_data_imp_score[['roc_auc']])\n",
    "pd.DataFrame({\n",
    "    'term' : tmp.columns,\n",
    "    'coef' : mod.coef_[0]\n",
    "}).sort_values('coef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(XY_data_imp_score['N_training_pgd_females_freq'].describe(percentiles=[.025,0.975]))\n",
    "display(XY_data_imp_score['N_training_nonpgd_females_freq'].describe(percentiles=[.025,0.975]))\n",
    "display(XY_data_imp_score['N_validation_pgd_females_freq'].describe(percentiles=[.025,0.975]))\n",
    "display(XY_data_imp_score['N_training_pgd_females_freq'].describe(percentiles=[.025,0.975]))\n",
    "display(XY_data_imp_score['N_validation_nonpgd_females_freq'].describe(percentiles=[.025,0.975]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = XY_data_imp_score['N_training_pgd_females_freq']\n",
    "b = XY_data_imp_score['N_validation_pgd_females_freq']\n",
    "c = XY_data_imp_score['roc_auc']\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,c,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(b,c,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue=c<.5,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue= c==.5,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue=c>.5,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue=c,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = XY_data_imp_score['N_training_pgd_males_freq']\n",
    "b = XY_data_imp_score['N_validation_pgd_males_freq']\n",
    "c = XY_data_imp_score['roc_auc']\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,c,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(b,c,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue=c<.5,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue= c==.5,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue=c>.5,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue=c,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = XY_data_imp_score.N_training_pgd_females_freq\n",
    "b = XY_data_imp_score.N_training_nonpgd_females_freq\n",
    "c = XY_data_imp_score.roc_auc\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(b,c,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue=c<.5,ax=ax,cmap='viridis')\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue= c==.5,ax=ax,cmap='viridis')\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue= c>.5,ax=ax,cmap='viridis')\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue=c,ax=ax,cmap='viridis')\n",
    "ax.legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = XY_data_imp_score.N_training_pgd_males_freq\n",
    "b = XY_data_imp_score.N_training_nonpgd_males_freq\n",
    "c = XY_data_imp_score.roc_auc\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(b,c,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue=c<.5,ax=ax,cmap='viridis')\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue= c==.5,ax=ax,cmap='viridis')\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue= c>.5,ax=ax,cmap='viridis')\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue=c,ax=ax,cmap='viridis')\n",
    "ax.legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = XY_data_imp_score.N_training_pgd_females_freq\n",
    "b = XY_data_imp_score.N_training_nonpgd_males_freq\n",
    "c = XY_data_imp_score.roc_auc\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue=c<.5,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue= c==.5,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue=c>.5,ax=ax)\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot(a,b,hue=c,ax=ax)\n",
    "ax.legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fimps_all.query('Feature==\"Sex_F\"')['Importance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = (ppreds_all.\n",
    " set_index('Sample').\n",
    " join(X_all_clinical).\n",
    "       reset_index().\n",
    " loc[:,['bootstrap','Sample','y_true','y_proba','cohort','Sex_F']])\n",
    "(tmp.\n",
    "groupby(['bootstrap'])['Sex_F'].sum()).hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = (perf_all.\n",
    "       set_index('bootstrap').\n",
    "       drop('set',1).\n",
    "       join(fimps_all.\n",
    "            query('Feature==\"Sex_F\"').\n",
    "            set_index('Bootstrap')).\n",
    "       loc[:,['test_roc_auc','validation_roc_auc','Feature','Importance']]\n",
    "      )\n",
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.scatterplot('Importance','validation_roc_auc',\n",
    "                data=tmp,linewidth=.2,edgecolor='black',ax=ax)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_these = fimps_all.query('Importance==0 & Feature==\"Sex_F\"')['Bootstrap'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=50\n",
    "dat = ppreds_all\n",
    "vals = []\n",
    "for b in range(n):\n",
    "    x = (dat.\n",
    "         query('bootstrap not in @not_these').\n",
    "         sample(n=200-len(not_these),replace=True,random_state=b)\n",
    "        )\n",
    "    vals.append(['Sex_F',b,x.model.unique()[0],roc_auc_score(x.y_true,x.y_proba)])\n",
    "tmp = pd.DataFrame(vals,columns=['Feature','Bootstrap','Model','roc_auc'])\n",
    "tmp['roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=50\n",
    "dat = ppreds_all\n",
    "vals = []\n",
    "for b in range(n):\n",
    "    x = (dat.\n",
    "         sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "        )\n",
    "    vals.append(['Sex_F',b,x.model.unique()[0],roc_auc_score(x.y_true,x.y_proba)])\n",
    "tmp = pd.DataFrame(vals,columns=['Feature','Bootstrap','Model','roc_auc'])\n",
    "tmp['roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inotrope and LVAD relationship to PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /Users/nickgiangreco/Research/Projects/exosome_pgf/src/python/prediction_functions.py\n",
    "\n",
    "\n",
    "metric = 'roc_auc'\n",
    "cv_split = 10\n",
    "n_jobs = 20\n",
    "nboot=200\n",
    "test_size = 0.15\n",
    "treat='PGD'\n",
    "i=0\n",
    "classification_metrics = ['roc_auc']\n",
    "\n",
    "dir_=\"../../data/\"\n",
    "cohort = 'integrated'\n",
    "\n",
    "def get_performance(lst):\n",
    "    perf = (pd.\n",
    "            concat(lst,keys=range(len(lst))).\n",
    "            reset_index(level=1,drop=True).\n",
    "            rename_axis('bootstrap').\n",
    "            reset_index()\n",
    "           )\n",
    "    return perf\n",
    "\n",
    "def model_feature_importances(boot_mods):\n",
    "    dfs = []\n",
    "    X = params['X'].copy()\n",
    "    X.loc[:,'Intercept'] = 0\n",
    "    for i in range(len(boot_mods)):\n",
    "        for j in boot_mods[i].keys():\n",
    "            mod = boot_mods[i][j]\n",
    "            coef = []\n",
    "            try:\n",
    "                coef.extend([i for i in mod.feature_importances_])\n",
    "            except:\n",
    "                coef.extend([i for i in mod.coef_[0]])\n",
    "            coef.extend(mod.intercept_)\n",
    "            fs = []\n",
    "            fs.extend(X.columns.values)\n",
    "            df = pd.DataFrame({\n",
    "                'Feature' : fs,\n",
    "                'Gene_name' : (X.T.\n",
    "                               join(idmap_sub.\n",
    "                                    set_index('Protein'),how='left').\n",
    "                               Gene_name.values),\n",
    "                'Importance' : coef,\n",
    "                'Model' : j,\n",
    "                'Bootstrap' : i\n",
    "            })\n",
    "            dfs.append(df)\n",
    "    return pd.concat(dfs,sort=True)\n",
    "\n",
    "def patient_predictions(lst):\n",
    "        dat = \\\n",
    "        (pd.\n",
    "         concat(\n",
    "             lst\n",
    "         ).\n",
    "         reset_index().\n",
    "         rename(columns={0 : 'Sample'}).\n",
    "         set_index('Sample').\n",
    "         join(all_cov_df,how='left').\n",
    "         reset_index().\n",
    "         melt(id_vars=['Sample','bootstrap','model','y_true','y_pred','y_proba'],\n",
    "              var_name='cohort',value_name='mem')\n",
    "        )\n",
    "        dat.cohort = dat.cohort.str.split('_').apply(lambda x : x[1])\n",
    "        dat = dat[dat.mem==1].drop('mem',1).reset_index(drop=True)\n",
    "        return dat\n",
    "\n",
    "X_all_proteins = pd.read_csv(dir_+cohort+'_X_raw_all_proteins.csv',index_col=0)\n",
    "X_all_clinical = pd.read_csv(dir_+cohort+'_X_clinical_and_cohort_covariates.csv',index_col=0)\n",
    "Y = pd.read_csv(dir_+cohort+'_pgd_y.csv',index_col=0,header=None)\n",
    "\n",
    "cov_df = X_all_clinical.loc[:,['Cohort_Columbia','Cohort_Cedar']].copy().astype(int)\n",
    "all_cov_df = cov_df.copy()\n",
    "all_cov_df.loc[:,'Cohort_Paris'] = (\n",
    "    (all_cov_df['Cohort_Columbia'] + \n",
    "     all_cov_df['Cohort_Cedar'])==0).astype(int)\n",
    "\n",
    "idmap_sub = pd.read_csv('../../data/protein_gene_map_full.csv')[['Protein','Gene_name']].dropna()\n",
    "\n",
    "features = ['Prior_Inotrope_Y']\n",
    "\n",
    "X_all = X_all_proteins.join(X_all_clinical)\n",
    "X = X_all[features]\n",
    "\n",
    "i=0\n",
    "params = {'X' : X,'Y' : Y, 'cv_split' : cv_split, \n",
    "\t\t  'metrics' : classification_metrics, 'n_jobs' : 1, \n",
    "\t\t  'test_size' : test_size,\n",
    "\t\t  'retrained_models' : True, 'patient_level_predictions' : True,\n",
    "         'models' : l1_logit_model.copy()}\n",
    "lst = bootstrap_of_fcn(func=train_test_val_top_fold_01_within,\n",
    "               params=params,n_jobs=n_jobs,nboot=nboot)\n",
    "perf_i = get_performance([lst[i][0] for i in range(len(lst))])\n",
    "perf_i['set'] = str(i)\n",
    "fimps_i = model_feature_importances([lst[i][1] for i in range(len(lst))])\n",
    "fimps_i['set'] = str(i)\n",
    "ppreds_i = patient_predictions([lst[i][2] for i in range(len(lst))])\n",
    "ppreds_i['set'] = str(i)\n",
    "\n",
    "features = ['Mechanical_Support_Y']\n",
    "X = X_all[features]\n",
    "\n",
    "i=1\n",
    "params = {'X' : X,'Y' : Y, 'cv_split' : cv_split, \n",
    "\t\t  'metrics' : classification_metrics, 'n_jobs' : 1, \n",
    "\t\t  'test_size' : test_size,\n",
    "\t\t  'retrained_models' : True, 'patient_level_predictions' : True,\n",
    "         'models' : l1_logit_model.copy()}\n",
    "lst = bootstrap_of_fcn(func=train_test_val_top_fold_01_within,\n",
    "               params=params,n_jobs=n_jobs,nboot=nboot)\n",
    "perf_l = get_performance([lst[i][0] for i in range(len(lst))])\n",
    "perf_l['set'] = str(i)\n",
    "fimps_l = model_feature_importances([lst[i][1] for i in range(len(lst))])\n",
    "fimps_l['set'] = str(i)\n",
    "ppreds_l = patient_predictions([lst[i][2] for i in range(len(lst))])\n",
    "ppreds_l['set'] = str(i)\n",
    "\n",
    "features = ['Prior_Inotrope_Y','Mechanical_Support_Y']\n",
    "X = X_all[features]\n",
    "\n",
    "i=2\n",
    "params = {'X' : X,'Y' : Y, 'cv_split' : cv_split, \n",
    "\t\t  'metrics' : classification_metrics, 'n_jobs' : 1, \n",
    "\t\t  'test_size' : test_size,\n",
    "\t\t  'retrained_models' : True, 'patient_level_predictions' : True,\n",
    "         'models' : l1_logit_model.copy()}\n",
    "lst = bootstrap_of_fcn(func=train_test_val_top_fold_01_within,\n",
    "               params=params,n_jobs=n_jobs,nboot=nboot)\n",
    "perf_il = get_performance([lst[i][0] for i in range(len(lst))])\n",
    "perf_il['set'] = str(i)\n",
    "fimps_il = model_feature_importances([lst[i][1] for i in range(len(lst))])\n",
    "fimps_il['set'] = str(i)\n",
    "ppreds_il = patient_predictions([lst[i][2] for i in range(len(lst))])\n",
    "ppreds_il['set'] = str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fimps_i.\n",
    "      query('Feature!=\"Intercept\"')['Importance'].\n",
    "      describe(percentiles=[0.025,0.975]).\n",
    "     loc[['2.5%','mean','97.5%']])\n",
    "print(fimps_l.\n",
    "      query('Feature!=\"Intercept\"')['Importance'].\n",
    "      describe(percentiles=[0.025,0.975]).\n",
    "     loc[['2.5%','mean','97.5%']])\n",
    "print(fimps_il.\n",
    "      query('Feature!=\"Intercept\"').\n",
    "      groupby('Feature')['Importance'].\n",
    "      describe(percentiles=[0.025,0.975]).\n",
    "     loc[:,['2.5%','mean','97.5%']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=50\n",
    "dat = ppreds_i\n",
    "vals = []\n",
    "for b in range(n):\n",
    "    x = (dat.\n",
    "         sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "        )\n",
    "    vals.append(['Inotrope Therapy',b,x.model.unique()[0],roc_auc_score(x.y_true,x.y_proba)])\n",
    "tmp = pd.DataFrame(vals,columns=['Feature','Bootstrap','Model','roc_auc'])\n",
    "tmp['roc_auc'].describe(percentiles=[0.025,0.975]).loc[['2.5%','mean','97.5%']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=50\n",
    "dat = ppreds_l\n",
    "vals = []\n",
    "for b in range(n):\n",
    "    x = (dat.\n",
    "         sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "        )\n",
    "    vals.append(['LVAD',b,x.model.unique()[0],roc_auc_score(x.y_true,x.y_proba)])\n",
    "tmp = pd.DataFrame(vals,columns=['Feature','Bootstrap','Model','roc_auc'])\n",
    "tmp['roc_auc'].describe(percentiles=[0.025,0.975]).loc[['2.5%','mean','97.5%']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=50\n",
    "dat = ppreds_il\n",
    "vals = []\n",
    "for b in range(n):\n",
    "    x = (dat.\n",
    "         sample(n=dat.shape[0],replace=True,random_state=b)\n",
    "        )\n",
    "    vals.append(['Inotrope therapy and LVAD',b,x.model.unique()[0],roc_auc_score(x.y_true,x.y_proba)])\n",
    "tmp = pd.DataFrame(vals,columns=['Feature','Bootstrap','Model','roc_auc'])\n",
    "tmp['roc_auc'].describe(percentiles=[0.025,0.975]).loc[['2.5%','mean','97.5%']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dat = \\\n",
    "(pd.concat([\n",
    "    fimps_i.query('Feature!=\"Intercept\"')[['Bootstrap','Feature','Importance','set']],\n",
    "    fimps_l.query('Feature!=\"Intercept\"')[['Bootstrap','Feature','Importance','set']],\n",
    "    fimps_il.query('Feature!=\"Intercept\"')[['Bootstrap','Feature','Importance','set']]\n",
    "]).\n",
    " rename(\n",
    "     columns={\n",
    "         'Inotrope therapy' : 'Prior_Inotrope_Y',\n",
    "         'LVAD' : 'Mechanical Support_Y'\n",
    "     }\n",
    " )\n",
    ")\n",
    "set_dict = {\n",
    "    0 : 'Inotrope therapy',\n",
    "    1 : 'LVAD', \n",
    "    2 : 'Inotrope therapy and LVAD'\n",
    "}\n",
    "\n",
    "plot_dat['set'] = (plot_dat['set'].\n",
    "                   astype(int).\n",
    "                   apply(lambda x : set_dict[x])\n",
    "                  )\n",
    "plot_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=200)\n",
    "sns.boxplot('set','Importance',hue='Feature',\n",
    "            data=plot_dat,ax=ax,fliersize=0,\n",
    "           color='lightgray')\n",
    "ax.legend().remove()\n",
    "ax.set_xlabel('')\n",
    "ax.set_xticklabels(['Inotrope therapy','LVAD','Inotrope therapy\\nand\\nLVAD'],size=16)\n",
    "ax.set_ylabel(r'$\\beta$ coefficient',size=20)\n",
    "ax.axvline(0.5,color='gray')\n",
    "ax.axvline(1.5,color='gray')\n",
    "ax.axhline(0,c='r',linestyle='--')\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'inotrope_lvad_prediction_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### KLKB1 validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/KLKB1_80_DEIDENTIFIED_patient_validation.csv')\n",
    "print(data.shape)\n",
    "print(data['PGD'].value_counts())\n",
    "print(data.columns)\n",
    "print(data.barcode_id.values)\n",
    "data.barcode_id = data.barcode_id.astype(int)\n",
    "display(data.head())\n",
    "data['PGD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cats = {}\n",
    "i = 0\n",
    "for cat in data.LVAD.unique():\n",
    "    cats[cat] = i\n",
    "    i = i + 1\n",
    "data['LVAD_map'] = data.LVAD.map(cats)\n",
    "data['PGD_agg'] = (data['PGD']>0).astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### PGD vs no PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "var = 'concentration'\n",
    "a = data.query('PGD in [0]')[var].values\n",
    "b = data.query('PGD in [1,2,3,4,5]')[var].values\n",
    "display(ttest_ind(a,b))\n",
    "mannwhitneyu(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "var = 'concentration'\n",
    "a = data.query('PGD in [0]')[var].values\n",
    "b = data.query('PGD in [1,2,3,4]')[var].values\n",
    "display(ttest_ind(a,b))\n",
    "mannwhitneyu(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "var = 'concentration'\n",
    "a = data.query('PGD in [0]')[var].values\n",
    "b = data.query('PGD in [1,2,3]')[var].values\n",
    "display(ttest_ind(a,b))\n",
    "mannwhitneyu(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "var = 'concentration'\n",
    "a = data.query('PGD in [0]')[var].values\n",
    "b = data.query('PGD in [1,2]')[var].values\n",
    "display(ttest_ind(a,b))\n",
    "mannwhitneyu(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "var = 'concentration'\n",
    "a = data.query('PGD in [0]')[var].values\n",
    "b = data.query('PGD in [2,3,4]')[var].values\n",
    "display(ttest_ind(a,b))\n",
    "mannwhitneyu(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "var = 'concentration'\n",
    "a = data.query('PGD in [0]')[var].values\n",
    "b = data.query('PGD in [2,3]')[var].values\n",
    "print(ttest_ind(a,b))\n",
    "print((np.mean(a), np.std(a)))\n",
    "print((np.mean(b), np.std(b)))\n",
    "mannwhitneyu(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "var = 'concentration'\n",
    "a = data.query('PGD in [0]')[var].values\n",
    "b = data.query('PGD in [3]')[var].values\n",
    "print(ttest_ind(a,b))\n",
    "print((np.mean(a), np.std(a)))\n",
    "print((np.mean(b), np.std(b)))\n",
    "mannwhitneyu(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### PGD type by elisa swarmplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = data.query('PGD in [0,2,3]').copy()\n",
    "tmp['concentration'] = \\\n",
    "(tmp['concentration'] - tmp['concentration'].min() ) / ( tmp['concentration'].max() - tmp['concentration'].min())\n",
    "fig,ax=plt.subplots(dpi=dpi,figsize=(10,4))\n",
    "sns.boxplot('PGD','concentration',data=tmp,ax=ax,color='darkgrey',fliersize=0)\n",
    "sns.stripplot('PGD','concentration',hue='Inotrope',\n",
    "              palette=['lightgray','black'],edgecolor='black',\n",
    "              data=tmp,\n",
    "              jitter=True,linewidth=1\n",
    "             )\n",
    "ax.set_xticklabels(['no PGD','moderate PGD','severe PGD'],)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Normalized\\nKLKB1 ELISA Concentration',size=18)\n",
    "ax.tick_params(axis='both', which='both', length=0,labelsize=14)\n",
    "\n",
    "noi_patch = Line2D([0],[0],marker='o',\n",
    "                   markerfacecolor='lightgray',markeredgecolor='black',\n",
    "                   color='w',markersize=5,label='no Inotrope')\n",
    "i_patch = Line2D([0],[0],marker='o',\n",
    "                 markerfacecolor='black',markeredgecolor='black',\n",
    "                 color='w',markersize=5,label='Inotrope')\n",
    "ax.legend(handles=[noi_patch,i_patch],title='',frameon=False)\n",
    "fig.savefig(dropbox_figures+'pgd_grade_by_elisa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### no-PGD vs. PGD by elisa swarmplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = data.query('PGD in [0,2,3]').copy()\n",
    "tmp['concentration'] = \\\n",
    "(tmp['concentration'] - tmp['concentration'].min() ) / ( tmp['concentration'].max() - tmp['concentration'].min())\n",
    "log = tmp.PGD==2\n",
    "tmp.at[log,'PGD'] = 3\n",
    "fig,ax=plt.subplots(dpi=dpi,figsize=(6,4))\n",
    "sns.boxplot('PGD','concentration',data=tmp,ax=ax,color='darkgrey',fliersize=0)\n",
    "sns.stripplot('PGD','concentration',hue='Inotrope',\n",
    "              palette=['lightgray','black'],edgecolor='black',\n",
    "              data=tmp,\n",
    "              jitter=True,linewidth=1\n",
    "             )\n",
    "ax.set_xticklabels(['no PGD','moderate/severe PGD'],fontsize=20)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Normalized\\nKLKB1 ELISA\\nConcentration',size=18)\n",
    "ax.tick_params(axis='both', which='both', length=0,labelsize=16)\n",
    "\n",
    "noi_patch = Line2D([0],[0],marker='o',\n",
    "                   markerfacecolor='lightgray',markeredgecolor='black',\n",
    "                   color='w',markersize=5,label='no Inotrope')\n",
    "i_patch = Line2D([0],[0],marker='o',\n",
    "                 markerfacecolor='black',markeredgecolor='black',\n",
    "                 color='w',markersize=5,label='Inotrope')\n",
    "ax.legend(handles=[noi_patch,i_patch],title='',frameon=False,fontsize=20,markerscale=2)\n",
    "\n",
    "var = 'concentration'\n",
    "a = data.query('PGD in [0]')[var].values\n",
    "b = data.query('PGD in [2,3]')[var].values\n",
    "test, pv = mannwhitneyu(a,b)\n",
    "\n",
    "ax.set_title('Mann Whitney test p-value={}'.format(np.round(pv,4)),size=20\n",
    "        )\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'nopgd_pgd_by_elisa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### PGD agg by concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = data.copy()\n",
    "tmp.loc[tmp.loc[:,'PGD'].isin([2,3]),'PGD_agg'] = 'PGD'\n",
    "tmp.loc[tmp.loc[:,'PGD'].isin([1,4,5]),'PGD_agg'] = np.nan\n",
    "tmp.loc[tmp.loc[:,'PGD'].isin([0]),'PGD_agg'] = 'no PGD'\n",
    "tmp['concentration'] = \\\n",
    "(tmp['concentration'] - tmp['concentration'].min() ) / ( tmp['concentration'].max() - tmp['concentration'].min())\n",
    "fig,ax=plt.subplots(dpi=dpi)\n",
    "sns.boxplot('PGD_agg','concentration',color='gray',data=tmp,ax=ax,fliersize=0)\n",
    "sns.stripplot('PGD_agg','concentration',\n",
    "              marker='o',color='lightgray',edgecolor='black',\n",
    "              data=tmp[tmp['Inotrope']==0],\n",
    "              ax=ax,jitter=True,linewidth=1\n",
    "             )\n",
    "sns.stripplot('PGD_agg','concentration',\n",
    "              marker='^',color='black',edgecolor='black',\n",
    "              data=tmp[tmp['Inotrope']==1],\n",
    "              ax=ax,jitter=True,linewidth=1\n",
    "             )\n",
    "ax.set_xlabel('')\n",
    "ax.set_xticklabels(['No PGD', 'Moderate\\nand Severe PGD'])\n",
    "ax.set_ylabel('Normalized\\nKLKB1 ELISA Concentration',size=18)\n",
    "\n",
    "noi_patch = Line2D([0],[0],marker='o',\n",
    "                   markerfacecolor='lightgray',markeredgecolor='black',\n",
    "                   color='w',markersize=5,label='no Inotrope')\n",
    "i_patch = Line2D([0],[0],marker='^',\n",
    "                 markerfacecolor='black',markeredgecolor='black',\n",
    "                 color='w',markersize=5,label='Inotrope')\n",
    "ax.legend(handles=[noi_patch,i_patch],title='',frameon=False)\n",
    "\n",
    "\n",
    "ax.tick_params(axis='both', which='both', length=0,labelsize=14)\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'KLKB1_to_PGD_agg_validation.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### PGD 2-3 vs nonPGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fimps_df.query('Feature==\"H0YAC1\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "set_ = \"17\"\n",
    "fimps_df.query('set==@set_').set_index('Feature')['mean'].sort_index(ascending=False).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_params = fimps_df.query('set==@set_').set_index('Feature')['mean'].sort_index(ascending=False).values\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#http://ethen8181.github.io/machine-learning/text_classification/logistic.html\n",
    "def predict_probability(data, weights):\n",
    "    \"\"\"probability predicted by the logistic regression\"\"\"\n",
    "    score = np.dot(data, weights)\n",
    "    predictions = 1 / (1 + np.exp(-score))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/KLKB1_80_DEIDENTIFIED_patient_validation.csv')\n",
    "display(data.PGD.value_counts())\n",
    "data = data.query('PGD in [0,2,3]')\n",
    "data['PGD_agg'] = (data['PGD']>0).map({True : 1, False : 0})\n",
    "Y_elisa = data[['PGD_agg']]\n",
    "display(Y_elisa['PGD_agg'].value_counts())\n",
    "elisa_X = data[['Inotrope','concentration']]\n",
    "elisa_X['concentration'] = (elisa_X['concentration'] - elisa_X['concentration'].min()) / (elisa_X['concentration'].max() - elisa_X['concentration'].min())\n",
    "ps = predict_probability(elisa_X.values,best_params)\n",
    "fpr, tpr, thresholds = roc_curve(Y_elisa.values,ps,pos_label=1)\n",
    "score = np.round(roc_auc_score(Y_elisa.values,ps),2)\n",
    "fig,ax=plt.subplots(dpi=dpi)\n",
    "ax.plot(fpr,tpr,c='red')\n",
    "ax.plot(fpr,tpr,'.',c='red',mec='red',lw=0.001)\n",
    "ax.set_ylabel('Sensitivity',size=18)\n",
    "print('AUROC : {}'.format(score))\n",
    "ax.set_xlabel('1 - Specificity',size=18)\n",
    "\n",
    "ax.tick_params(axis='both', which='both', length=0,labelsize=14)\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'assessment_set_equation_roc_curve_nopgd_vs_pgd23.png')\n",
    "cs = []\n",
    "for t in thresholds:\n",
    "    tn, fp, fn, tp = confusion_matrix(Y_elisa.values,ps>=t).ravel()\n",
    "    cs.append([tp,fp,fn,tn])\n",
    "cs_df = (pd.\n",
    "         DataFrame(cs,\n",
    "                   columns=['TP','FP','FN','TN'],\n",
    "                   index=thresholds\n",
    "                  ).\n",
    "         rename_axis('Threshold').\n",
    "         reset_index().\n",
    "         sort_values('Threshold',ascending=True).\n",
    "         reset_index(drop=True)\n",
    ")\n",
    "cs_df['Sensitivity'] = cs_df['TP'] / (cs_df['TP'] + cs_df['FN'])\n",
    "cs_df['Specificity'] = cs_df['TN'] / (cs_df['FP'] + cs_df['TN'])\n",
    "cs_df['1-Specificity'] = 1 - cs_df['Specificity']\n",
    "cs_df['Accuracy'] = ( cs_df['TP'] + cs_df['TN'] ) / ( cs_df['TP'] + cs_df['TN'] + cs_df['FP'] + cs_df['FN'])\n",
    "cs_df['FPR'] = cs_df['FP'] / (cs_df['FP'] + cs_df['TN'])\n",
    "cs_df['TPR'] = cs_df['TP'] / (cs_df['TP'] + cs_df['FN'])\n",
    "cs_df['PPV'] = cs_df['TP'] / (cs_df['TP'] + cs_df['FP'])\n",
    "cs_df['NPV'] = cs_df['TN'] / (cs_df['TN'] + cs_df['FN'])\n",
    "display(cs_df)\n",
    "cs_df.to_csv(dropbox_data+'assessment_set_equation_pgd0_vs_pgd23_performance_table.csv')\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(Y_elisa.values,ps,pos_label=1)\n",
    "precision[len(precision)-1] = 0\n",
    "score = np.round(average_precision_score(Y_elisa.values,ps),2)\n",
    "fig,ax=plt.subplots(dpi=dpi)\n",
    "ax.plot(recall,precision,c='red')\n",
    "ax.plot(recall,precision,'.',c='red',mec='red',lw=0.001)\n",
    "print('AUPRC : {}'.format(score))\n",
    "ax.set_ylabel('Precision',size=18)\n",
    "ax.set_xlabel('Recall',size=18)\n",
    "ax.set_ylim(0,1)\n",
    "ax.tick_params(axis='both', which='both', length=0,labelsize=14)\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'assessment_set_equation_precision_recall_curve_nopgd_vs_pgd23.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/KLKB1_80_DEIDENTIFIED_patient_validation.csv')\n",
    "display(data.PGD.value_counts())\n",
    "data = data.query('PGD in [0,2,3]')\n",
    "data['PGD_agg'] = (data['PGD']>0).map({True : 1, False : 0})\n",
    "Y_elisa = data[['PGD_agg']]\n",
    "display(Y_elisa['PGD_agg'].value_counts())\n",
    "elisa_X = data[['concentration']]\n",
    "elisa_X['concentration'] = (elisa_X['concentration'] - elisa_X['concentration'].min()) / (elisa_X['concentration'].max() - elisa_X['concentration'].min())\n",
    "ps = predict_probability(elisa_X.values,[0.1959])\n",
    "fpr, tpr, thresholds = roc_curve(Y_elisa.values,ps,pos_label=1)\n",
    "score = np.round(roc_auc_score(Y_elisa.values,ps),2)\n",
    "fig,ax=plt.subplots(dpi=dpi)\n",
    "ax.plot(fpr,tpr,c='red')\n",
    "ax.plot(fpr,tpr,'.',c='red',mec='red',lw=0.001)\n",
    "ax.set_ylabel('Sensitivity',size=18)\n",
    "print('AUROC : {}'.format(score))\n",
    "ax.set_xlabel('1 - Specificity',size=18)\n",
    "\n",
    "ax.tick_params(axis='both', which='both', length=0,labelsize=14)\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'assessment_set_equation_roc_curve_nopgd_vs_pgd23_just_klkb1.png')\n",
    "cs = []\n",
    "for t in thresholds:\n",
    "    tn, fp, fn, tp = confusion_matrix(Y_elisa.values,ps>=t).ravel()\n",
    "    cs.append([tp,fp,fn,tn])\n",
    "cs_df = (pd.\n",
    "         DataFrame(cs,\n",
    "                   columns=['TP','FP','FN','TN'],\n",
    "                   index=thresholds\n",
    "                  ).\n",
    "         rename_axis('Threshold').\n",
    "         reset_index().\n",
    "         sort_values('Threshold',ascending=True).\n",
    "         reset_index(drop=True)\n",
    ")\n",
    "cs_df['Sensitivity'] = cs_df['TP'] / (cs_df['TP'] + cs_df['FN'])\n",
    "cs_df['Specificity'] = cs_df['TN'] / (cs_df['FP'] + cs_df['TN'])\n",
    "cs_df['1-Specificity'] = 1 - cs_df['Specificity']\n",
    "cs_df['Accuracy'] = ( cs_df['TP'] + cs_df['TN'] ) / ( cs_df['TP'] + cs_df['TN'] + cs_df['FP'] + cs_df['FN'])\n",
    "cs_df['FPR'] = cs_df['FP'] / (cs_df['FP'] + cs_df['TN'])\n",
    "cs_df['TPR'] = cs_df['TP'] / (cs_df['TP'] + cs_df['FN'])\n",
    "cs_df['PPV'] = cs_df['TP'] / (cs_df['TP'] + cs_df['FP'])\n",
    "cs_df['NPV'] = cs_df['TN'] / (cs_df['TN'] + cs_df['FN'])\n",
    "display(cs_df)\n",
    "cs_df.to_csv(dropbox_data+'assessment_set_equation_pgd0_vs_pgd23_performance_table_just_klkb1.csv')\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(Y_elisa.values,ps,pos_label=1)\n",
    "precision[len(precision)-1] = 0\n",
    "score = np.round(average_precision_score(Y_elisa.values,ps),2)\n",
    "fig,ax=plt.subplots(dpi=dpi)\n",
    "ax.plot(recall,precision,c='red')\n",
    "ax.plot(recall,precision,'.',c='red',mec='red',lw=0.001)\n",
    "print('AUPRC : {}'.format(score))\n",
    "ax.set_ylabel('Precision',size=18)\n",
    "ax.set_xlabel('Recall',size=18)\n",
    "ax.set_ylim(0,1)\n",
    "ax.tick_params(axis='both', which='both', length=0,labelsize=14)\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'assessment_set_equation_precision_recall_curve_nopgd_vs_pgd23_just_klkb1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = (pd.\n",
    "       DataFrame(\n",
    "           {'Probability' : ps, 'PGD_agg' : data['PGD_agg'].values, 'PGD' : data['PGD']\n",
    "           }\n",
    "       ).\n",
    "       sort_values('Probability')\n",
    "      )\n",
    "tmp['n_cumsum'] = (tmp['PGD_agg'].cumsum())\n",
    "tmp['perc_cumsum'] = (tmp['PGD_agg'].cumsum() / tmp['PGD_agg'].sum())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp.query('PGD==2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp.query('PGD==3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp[tmp['PGD_agg']==0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(dpi=dpi)\n",
    "sns.scatterplot('Probability',\n",
    "               'perc_cumsum',\n",
    "                data=tmp,\n",
    "                s=0,\n",
    "                color='black',\n",
    "               ax=ax)\n",
    "sns.lineplot('Probability',\n",
    "               'perc_cumsum',\n",
    "                data=tmp,\n",
    "                color='lightgray',\n",
    "               ax=ax)\n",
    "ax2 = plt.twinx()\n",
    "sns.scatterplot('Probability',\n",
    "               'n_cumsum',\n",
    "                data=tmp[tmp['PGD_agg']==0],\n",
    "                s=10,\n",
    "                marker='o',\n",
    "                linewidth=.5,\n",
    "                color='lightgray',\n",
    "                edgecolor='black',\n",
    "               ax=ax2)\n",
    "sns.scatterplot('Probability',\n",
    "               'n_cumsum',\n",
    "                data=tmp[tmp['PGD_agg']==1],\n",
    "                hue='PGD',\n",
    "                palette=['darkgray','black'],\n",
    "                s=40,\n",
    "                marker='^',\n",
    "                linewidth=.5,\n",
    "                edgecolor='black',\n",
    "               ax=ax2)\n",
    "ax.set_ylabel('Percent of PGD patients')\n",
    "ax2.set_ylabel('Number of PGD patients')\n",
    "ax.set_xlabel('Probability of PGD')\n",
    "\n",
    "ax2.set_yticks(np.arange(0,8,1))\n",
    "ax2.set_yticklabels(np.arange(0,8,1))\n",
    "\n",
    "ax.legend().remove()\n",
    "ax2.legend().remove()\n",
    "\n",
    "noi_patch = Line2D([0],[0],marker='^',\n",
    "                   markerfacecolor='darkgray',markeredgecolor='black',\n",
    "                   color='w',markersize=5,label='Moderate')\n",
    "i_patch = Line2D([0],[0],marker='^',\n",
    "                 markerfacecolor='black',markeredgecolor='black',\n",
    "                 color='w',markersize=5,label='Severe')\n",
    "ax.legend(handles=[noi_patch,i_patch],title='',frameon=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'validation_data_calibration_curve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Clinical dignostic figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.query('PGD in [0,2,3]').dropna(subset=['C3','C4','Total Complement'])['PGD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type_='grades_03'\n",
    "vars_=['C3','C4','Total Complement','Complement','ESR','hsCRP']\n",
    "pgds = ['PGD_agg']\n",
    "for p in pgds:\n",
    "    if p=='PGD_agg':\n",
    "        plot = data.query('PGD in [0,3]')\n",
    "    else:\n",
    "        plot = data.copy()\n",
    "    for var in vars_:\n",
    "        if var==\"Complement\":\n",
    "            cvars = ['C3','C4','Total Complement']\n",
    "            tmp = (plot.\n",
    "                   loc[:,[p,'C3','C4','Total Complement','Inotrope']].\n",
    "                   dropna().\n",
    "                   melt(id_vars=[p,'Inotrope'],var_name='Complement Type')\n",
    "                  )\n",
    "            fig,ax=plt.subplots(dpi=dpi)\n",
    "            g = sns.stripplot('Complement Type','value',\n",
    "                              hue=p,palette=['lightgray','black'],\n",
    "                              data=tmp,ax=ax,\n",
    "                              marker='o',color='darkgray',linewidth=.2,edgecolor='black',\n",
    "                              dodge=True,jitter=True)\n",
    "            ax.set_xticklabels(ax.get_xticklabels(),size=14)\n",
    "            ax.legend(loc='best',handles=[\n",
    "                    Line2D([0],[0],color='lightgray',marker='o',linewidth=0,label='no PGD'),\n",
    "                    Line2D([0],[0],color='black',marker='o',linewidth=0,label='PGD')\n",
    "                ])\n",
    "            fig.tight_layout()\n",
    "            if p=='PGD_agg':\n",
    "                    ax.set_xlabel('')\n",
    "            fig.savefig(dropbox_figures+\n",
    "                        p+'_x_Complements_'+type_+'.png')\n",
    "        else:\n",
    "            for i,grp1 in plot[[p,var]].dropna().groupby(p):\n",
    "                for j,grp2 in plot[[p,var]].dropna().groupby(p):\n",
    "                    if i<j:\n",
    "                        a = grp1[var].values\n",
    "                        b = grp2[var].values\n",
    "                        tmp = pd.DataFrame([grp1[var].describe(),\n",
    "                                            grp2[var].describe()],\n",
    "                                           index=['PGD'+str(i),'PGD'+str(j)]\n",
    "                                          )\n",
    "                        tmp.index.name=p\n",
    "                        tmp.columns.name=var\n",
    "                        test = mannwhitneyu(b,a)\n",
    "                        m,sd=np.mean(b),np.std(b)\n",
    "                        print(var)\n",
    "                        print(m)\n",
    "                        print(sd)\n",
    "                        m,sd=np.mean(a),np.std(a)\n",
    "                        print(m)\n",
    "                        print(sd)\n",
    "                fig,ax=plt.subplots(dpi=dpi)\n",
    "                g = sns.boxplot(p,var,data=plot,ax=ax,color='lightgrey',fliersize=0)\n",
    "                g = sns.stripplot(p,var,hue='Inotrope',palette=['darkgray','black'],\n",
    "                                  data=plot,size=10,\n",
    "                                  ax=ax,marker='o',linewidth=.5,edgecolor='black',\n",
    "                              dodge=True,jitter=True)\n",
    "                if var!='ESR':\n",
    "                    ax.set_ylabel(var+'\\nconcentration',size=18)\n",
    "                else:\n",
    "                    ax.set_ylabel(var,size=18)\n",
    "                ax.set_xticklabels(ax.get_xticklabels(),size=14)\n",
    "                ax.set_xlabel(p.replace('_agg',''),size=18)\n",
    "                ax.legend(loc='upper center',handles=[\n",
    "                    Line2D([0],[0],color='darkgray',marker='o',linewidth=0,label='no Inotrope'),\n",
    "                    Line2D([0],[0],color='black',marker='o',linewidth=0,label='Inotrope')\n",
    "                ],frameon=False)\n",
    "                if p=='PGD_agg':\n",
    "                    ax.set_xticklabels(['no PGD','PGD'],size=14)\n",
    "                    ax.set_xlabel('')\n",
    "                    ax.set_title('U statistic = {}; p-value = {}'.\n",
    "                                 format(np.round(test[0],2),np.round(test[1],2)),size=18)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(dropbox_figures+p+'_x_'+var+'_'+type_+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Supplemental Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Clinical descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### PGD by all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"../../data/integrated_sample_groups_imputed_data_raw.csv\",index_col=0).set_index('Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "x='PGD'\n",
    "vars_ = np.setdiff1d(data.columns.values,'PGD')\n",
    "for v in vars_:\n",
    "    y = v\n",
    "    try:\n",
    "        g = sns.catplot(y,x,hue=x,data=data)\n",
    "        g.fig.dpi = 150\n",
    "        g.set_axis_labels(y_var='')\n",
    "        g.set_yticklabels('')\n",
    "    except:\n",
    "        g = sns.catplot(x,hue=y,kind='count',data=data)\n",
    "        g.fig.dpi = 150\n",
    "        g.set_axis_labels(y_var='Count')\n",
    "    g.savefig(dropbox_figures+x+'_by_'+y+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Univariate association statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "uni = pd.read_csv('../../data/bootstrap_clinical_logit/integrated_logit_bootstrap_pgd_~_clinical_features.csv').reset_index(drop=True)\n",
    "uni_agg = pd.read_csv('../../data/bootstrap_clinical_logit/integrated_logit_bootstrap_pgd_~_clinical_features_lwr_mean_median_upr.csv').reset_index(drop=True)\n",
    "uni['odds'] = np.log(uni['odds'])\n",
    "uni_agg['mean'] = np.log(uni_agg['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "var_ord = uni_agg.sort_values('mean',ascending=False).variable.unique()\n",
    "uni_agg = uni_agg.sort_values('mean',ascending=False)\n",
    "dfs = []\n",
    "for var in var_ord:\n",
    "    dfs.append(uni.query('variable==@var'))\n",
    "data = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fs = data.variable.str.replace('_Y','')\n",
    "fs = fs.str.replace('_',' ')\n",
    "data.variable = fs\n",
    "\n",
    "fs = uni_agg.variable.str.replace('_Y','')\n",
    "fs = fs.str.replace('_',' ')\n",
    "uni_agg.variable = fs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(dpi=400,figsize=(10,12))\n",
    "\n",
    "sns.stripplot('odds','variable',data=data,ax=ax,alpha=0.2)\n",
    "\n",
    "sns.stripplot('mean','variable',data=uni_agg,ax=ax,jitter=False,color=\"red\",linewidth=.5)\n",
    "\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlabel('Population risk coefficient')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(dropbox_figures+'clinical_characteristics_population_risk_stripplot.pdf',width=20,height=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "uniprot = pd.read_csv('../../data/uniprot-all_20171124.tab.gz',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "characterized_prots = uniprot.query('Organism==\"Homo sapiens (Human)\"').Entry.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idmap = uniprot[['Entry','Gene names  (primary )']].rename(columns={'Entry' : 'Protein',\"Gene names  (primary )\" : 'Gene_name'})\n",
    "idmap_sub = idmap[idmap.Protein.isin(characterized_prots)]\n",
    "idmap_sub.to_csv('../../data/gene_list.txt',sep='\\n',header=None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cohort = 'integrated'\n",
    "logit = pd.read_csv(\"../../data/bootstrap_conditional_protein_logit/\"+cohort+\"/logit_bootstrap_pgd_~_protein_+_cohort_+_set_lwr_mean_median_upr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = logit.set_index('variable').join(idmap_sub.set_index('Protein'))\n",
    "leftover_inds = tmp.Gene_name.isnull()\n",
    "leftover_prots = tmp.index[leftover_inds].values\n",
    "leftover_prots_split = [k.split('-')[0] for k in leftover_prots]\n",
    "\n",
    "tmp_df = pd.DataFrame({'Protein' : leftover_prots,\n",
    "                       'Split' : leftover_prots_split,\n",
    "                       'cohort_identified_in' : cohort})\n",
    "\n",
    "tmp_df_join = tmp_df.set_index('Split').join(idmap_sub.set_index('Protein'))\n",
    "\n",
    "join_genes = tmp_df_join.Gene_name.values\n",
    "join_prots = tmp_df_join.Protein.values\n",
    "\n",
    "tmp.at[join_prots,'Gene_name'] = join_genes\n",
    "\n",
    "display(len(tmp.dropna()[~tmp.dropna().Gene_name.str.startswith('IG')].query('lwr>1 | upr<1').index.values))\n",
    "display(tmp.head())\n",
    "tmp.dropna().reset_index(drop=True).to_csv('../../data/bootstrap_protein_univariate_features.csv')\n",
    "pickle.dump(tmp.dropna()[~tmp.dropna().Gene_name.str.startswith('IG')].query('lwr>1 | upr<1').index.values,open('../../data/significant_bootstrap_protein_univariate_features.pkl','wb'))\n",
    "\n",
    "null_prots = tmp_df_join[tmp_df_join.Gene_name.isnull()].index.values\n",
    "df = tmp[~tmp.index.isin(null_prots)].reset_index(drop=True).set_index('Gene_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stat='mean'\n",
    "data = (df[~df.index.str.startswith('IG')].\n",
    "        query('lwr>1 | upr<1').\n",
    "        sort_values(stat,ascending=False))\n",
    "data.index = [x.split(';')[0]+' family' if len(x.split(';'))>2 else x for x in data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data,uni_sig.set_index('variable')],sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['lwr'] = np.log(data['lwr'])\n",
    "data['mean'] = np.log(data['mean'])\n",
    "data['upr'] = np.log(data['upr']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(dpi=dpi,figsize=(5,5))\n",
    "display(data.shape)\n",
    "ax.errorbar(y=data.index,\n",
    "            x=data[stat],\n",
    "            xerr=(data[stat] - data['lwr'],\n",
    "                 data['upr'] - data[stat]),\n",
    "           fmt='o',markersize=3,linewidth=1)\n",
    "ax.plot([0,0],[0,len(data.index.unique())-1],'r--',linewidth=0.5)\n",
    "ax.set_xlabel('Population risk coefficient',fontsize=16)\n",
    "fig.tight_layout()\n",
    "fig.savefig(dropbox_figures+'significant_proteins_and_clinical_characteristics.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### PCA colored by experimental batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('../../data/integrated_X_all_but_immunoglobulin_proteins.csv',index_col=0)\n",
    "display(X.head())\n",
    "tmt_covs = pd.read_csv('../../data/integrated_tmt_tag_covariates.csv',index_col=0)\n",
    "display(tmt_covs.head())\n",
    "set_covs = pd.read_csv('../../data/integrated_set_covariates.csv',index_col=0)\n",
    "display(set_covs.head())\n",
    "cohort_covs = pd.read_csv('../../data/integrated_cohort_covariates.csv',index_col=0)\n",
    "display(cohort_covs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mod = PCA(n_components=2)\n",
    "\n",
    "mod_data = pd.DataFrame(mod.fit_transform(X),columns=['PC1','PC2'],index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = (mod_data.\n",
    "        join(tmt_covs).\n",
    "        melt(id_vars=['PC1','PC2'],\n",
    "             var_name='Covariate').\n",
    "        query('value==1')\n",
    "       )\n",
    "display(data.head())\n",
    "\n",
    "fig,ax = plt.subplots(dpi=200)\n",
    "\n",
    "sns.scatterplot('PC1','PC2',hue='Covariate',data=data,ax=ax)\n",
    "\n",
    "ax.legend(loc='upper right',frameon=False,fontsize='small')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(dropbox_figures+'Protein_PCA_by_tmt_tag.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = (mod_data.\n",
    "        join(set_covs).\n",
    "        melt(id_vars=['PC1','PC2'],\n",
    "             var_name='Covariate').\n",
    "        query('value==1')\n",
    "       )\n",
    "display(data.head())\n",
    "\n",
    "fig,ax = plt.subplots(dpi=200)\n",
    "\n",
    "sns.scatterplot('PC1','PC2',hue='Covariate',data=data,ax=ax)\n",
    "\n",
    "ax.legend(loc='upper right',frameon=False,fontsize='small')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(dropbox_figures+'Protein_PCA_by_set.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = (mod_data.\n",
    "        join(cohort_covs).\n",
    "        melt(id_vars=['PC1','PC2'],\n",
    "             var_name='Covariate').\n",
    "        query('value==1')\n",
    "       )\n",
    "display(data.head())\n",
    "\n",
    "fig,ax = plt.subplots(dpi=200)\n",
    "\n",
    "sns.scatterplot('PC1','PC2',hue='Covariate',data=data,ax=ax)\n",
    "\n",
    "ax.legend(loc='upper right',frameon=False,fontsize='small')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(dropbox_figures+'Protein_PCA_by_cohort.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### KLKB1 tetramer prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def performance_df_from_lst(lst):\n",
    "    tmp = [lst[i][0] for i in range(len(lst))]\n",
    "    data = (pd.concat(tmp,keys=range(len(tmp))).\n",
    "            reset_index(level=1,drop=True).\n",
    "            rename_axis('bootstrap').\n",
    "            reset_index())\n",
    "    return data\n",
    "\n",
    "def feature_importances_df_from_lst(lst):\n",
    "    boot_mods = [lst[i][1] for i in range(nboot)]\n",
    "    dfs = []\n",
    "    X = params['X'].copy()\n",
    "    X.loc[:,'Intercept'] = 0\n",
    "    for i in range(len(boot_mods)):\n",
    "        for j in boot_mods[i].keys():\n",
    "            mod = boot_mods[i][j]\n",
    "            coef = []\n",
    "            try:\n",
    "                coef.extend([i for i in mod.feature_importances_])\n",
    "            except:\n",
    "                coef.extend([i for i in mod.coef_[0]])\n",
    "            coef.extend(mod.intercept_)\n",
    "            fs = []\n",
    "            fs.extend(X.columns.values)\n",
    "            df = pd.DataFrame({\n",
    "                'Feature' : fs,\n",
    "                'Gene_name' : (X.T.\n",
    "                               join(idmap_sub.\n",
    "                                    set_index('Protein'),how='left').\n",
    "                               Gene_name.values),\n",
    "                'Importance' : coef,\n",
    "                'Model' : j,\n",
    "                'Bootstrap' : i\n",
    "            })\n",
    "            dfs.append(df)\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run /Users/nickgiangreco/Research/Projects/exosome_pgf/src/python/prediction_functions.py\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "dir_ = '../../data/'\n",
    "cohort = 'integrated'\n",
    "\n",
    "classification_metrics = ['roc_auc','precision','recall','f1']\n",
    "nboot=1000\n",
    "n_jobs = 4\n",
    "test_size = .15\n",
    "cv_split = 10\n",
    "\n",
    "X_all_proteins = pd.read_csv(dir_+cohort+'_X_raw_all_proteins.csv',index_col=0)\n",
    "X_all_clinical = pd.read_csv(dir_+cohort+'_X_clinical_and_cohort_minus_paris_covariates.csv',index_col=0)\n",
    "Y = pd.read_csv(dir_+cohort+'_pgd_y.csv',index_col=0,header=None)\n",
    "\n",
    "idmap_sub = pd.read_csv('../../data/protein_gene_map_full.csv')[['Protein','Gene_name']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {'Y' : Y, 'cv_split' : cv_split, \n",
    "          'metrics' : classification_metrics, 'n_jobs' : 1, \n",
    "          'test_size' : test_size,\n",
    "          'retrained_models' : True, 'patient_level_predictions' : True}\n",
    "\n",
    "X_all = X_all_proteins.join(X_all_clinical)\n",
    "features = ['H0YAC1']\n",
    "X = X_all[features]\n",
    "\n",
    "params.update({'X' : X,'models' : l1_logit_model.copy()})\n",
    "\n",
    "lst = bootstrap_of_fcn(func=train_test_val_top_fold,\n",
    "                       params=params,n_jobs=n_jobs,nboot=nboot)\n",
    "\n",
    "i = 10000\n",
    "fimps = feature_importances_df_from_lst(lst)\n",
    "fimps['set'] = str(i)\n",
    "klkb1_fimp_df = (fimps.\n",
    "            groupby(['set','Feature'])['Importance'].\n",
    "            describe(percentiles=[0.025,0.975]).\n",
    "            loc[:,['2.5%','mean','97.5%']].\n",
    "            sort_values('2.5%',ascending=False).\n",
    "            reset_index()\n",
    "          )\n",
    "perf = performance_df_from_lst(lst)\n",
    "perf['set'] = str(i)\n",
    "klkb1_perf_df = (perf.\n",
    "           groupby(['set'])['validation_roc_auc'].\n",
    "           describe(percentiles=[0.025,0.975]).\n",
    "           loc[:,['2.5%','mean','97.5%']].\n",
    "           sort_values('2.5%',ascending=False).\n",
    "           reset_index()\n",
    "          )\n",
    "display(klkb1_perf_df)\n",
    "display(klkb1_fimp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = 10000\n",
    "fimps = feature_importances_df_from_lst(lst)\n",
    "fimps['set'] = str(i)\n",
    "klkb1_fimp_df = (fimps.\n",
    "            groupby(['set','Feature'])['Importance'].\n",
    "            describe(percentiles=[0.025,0.975]).\n",
    "            loc[:,['2.5%','mean','97.5%']].\n",
    "            sort_values('2.5%',ascending=False).\n",
    "            reset_index()\n",
    "          )\n",
    "perf = performance_df_from_lst(lst)\n",
    "perf['set'] = str(i)\n",
    "klkb1_perf_df = (perf.\n",
    "           groupby(['set'])['validation_roc_auc'].\n",
    "           describe(percentiles=[0.025,0.975]).\n",
    "           loc[:,['2.5%','mean','97.5%']].\n",
    "           sort_values('2.5%',ascending=False).\n",
    "           reset_index()\n",
    "          )\n",
    "display(klkb1_perf_df)\n",
    "display(klkb1_fimp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {'Y' : Y, 'cv_split' : cv_split, \n",
    "          'metrics' : classification_metrics, 'n_jobs' : 1, \n",
    "          'test_size' : test_size,\n",
    "          'retrained_models' : True, 'patient_level_predictions' : True}\n",
    "\n",
    "X_all = X_all_proteins.join(X_all_clinical)\n",
    "features = ['P01042']\n",
    "X = X_all[features]\n",
    "\n",
    "params.update({'X' : X,'models' : l1_logit_model.copy()})\n",
    "\n",
    "lst = bootstrap_of_fcn(func=train_test_val_top_fold,\n",
    "                       params=params,n_jobs=n_jobs,nboot=nboot)\n",
    "\n",
    "i = 10000\n",
    "fimps = feature_importances_df_from_lst(lst)\n",
    "fimps['set'] = str(i)\n",
    "kng1_fimp_df = (fimps.\n",
    "            groupby(['set','Feature'])['Importance'].\n",
    "            describe(percentiles=[0.025,0.975]).\n",
    "            loc[:,['2.5%','mean','97.5%']].\n",
    "            sort_values('2.5%',ascending=False).\n",
    "            reset_index()\n",
    "          )\n",
    "perf = performance_df_from_lst(lst)\n",
    "perf['set'] = str(i)\n",
    "kng1_perf_df = (perf.\n",
    "           groupby(['set'])['validation_roc_auc'].\n",
    "           describe(percentiles=[0.025,0.975]).\n",
    "           loc[:,['2.5%','mean','97.5%']].\n",
    "           sort_values('2.5%',ascending=False).\n",
    "           reset_index()\n",
    "          )\n",
    "display(kng1_perf_df)\n",
    "display(kng1_fimp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {'Y' : Y, 'cv_split' : cv_split, \n",
    "          'metrics' : classification_metrics, 'n_jobs' : 1, \n",
    "          'test_size' : test_size,\n",
    "          'retrained_models' : True, 'patient_level_predictions' : True}\n",
    "\n",
    "X_all = X_all_proteins.join(X_all_clinical)\n",
    "features = ['P00748']\n",
    "X = X_all[features]\n",
    "\n",
    "params.update({'X' : X,'models' : l1_logit_model.copy()})\n",
    "\n",
    "lst = bootstrap_of_fcn(func=train_test_val_top_fold,\n",
    "                       params=params,n_jobs=n_jobs,nboot=nboot)\n",
    "\n",
    "i = 10000\n",
    "fimps = feature_importances_df_from_lst(lst)\n",
    "fimps['set'] = str(i)\n",
    "f12_fimp_df = (fimps.\n",
    "            groupby(['set','Feature'])['Importance'].\n",
    "            describe(percentiles=[0.025,0.975]).\n",
    "            loc[:,['2.5%','mean','97.5%']].\n",
    "            sort_values('2.5%',ascending=False).\n",
    "            reset_index()\n",
    "          )\n",
    "perf = performance_df_from_lst(lst)\n",
    "perf['set'] = str(i)\n",
    "f12_perf_df = (perf.\n",
    "           groupby(['set'])['validation_roc_auc'].\n",
    "           describe(percentiles=[0.025,0.975]).\n",
    "           loc[:,['2.5%','mean','97.5%']].\n",
    "           sort_values('2.5%',ascending=False).\n",
    "           reset_index()\n",
    "          )\n",
    "display(f12_perf_df)\n",
    "display(f12_fimp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {'Y' : Y, 'cv_split' : cv_split, \n",
    "          'metrics' : classification_metrics, 'n_jobs' : 1, \n",
    "          'test_size' : test_size,\n",
    "          'retrained_models' : True, 'patient_level_predictions' : True}\n",
    "\n",
    "X_all = X_all_proteins.join(X_all_clinical)\n",
    "features = ['H0YAC1','P01042']\n",
    "X = X_all[features]\n",
    "\n",
    "params.update({'X' : X,'models' : l1_logit_model.copy()})\n",
    "\n",
    "lst = bootstrap_of_fcn(func=train_test_val_top_fold,\n",
    "                       params=params,n_jobs=n_jobs,nboot=nboot)\n",
    "\n",
    "i = 10000\n",
    "fimps = feature_importances_df_from_lst(lst)\n",
    "fimps['set'] = str(i)\n",
    "klkb1_kng1_fimp_df = (fimps.\n",
    "            groupby(['set','Feature'])['Importance'].\n",
    "            describe(percentiles=[0.025,0.975]).\n",
    "            loc[:,['2.5%','mean','97.5%']].\n",
    "            sort_values('2.5%',ascending=False).\n",
    "            reset_index()\n",
    "          )\n",
    "perf = performance_df_from_lst(lst)\n",
    "perf['set'] = str(i)\n",
    "klkb1_kng1_perf_df = (perf.\n",
    "           groupby(['set'])['validation_roc_auc'].\n",
    "           describe(percentiles=[0.025,0.975]).\n",
    "           loc[:,['2.5%','mean','97.5%']].\n",
    "           sort_values('2.5%',ascending=False).\n",
    "           reset_index()\n",
    "          )\n",
    "display(klkb1_kng1_perf_df)\n",
    "display(klkb1_kng1_fimp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_all['H0YAC1'][Y.values.reshape(1,-1)[0]==1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "\n",
    "X_all = X_all_proteins.join(X_all_clinical)\n",
    "\n",
    "display(sc.stats.ttest_ind(X_all['H0YAC1'][Y.values.reshape(1,-1)[0]==1].values,\n",
    "                           X_all['H0YAC1'][Y.values.reshape(1,-1)[0]==0].values))\n",
    "\n",
    "display(sc.stats.ttest_ind(X_all['P00748'][Y.values.reshape(1,-1)[0]==1].values,\n",
    "                           X_all['P00748'][Y.values.reshape(1,-1)[0]==0].values))\n",
    "\n",
    "display(sc.stats.ttest_ind(X_all['P01042'][Y.values.reshape(1,-1)[0]==1].values,\n",
    "                           X_all['P01042'][Y.values.reshape(1,-1)[0]==0].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {'Y' : Y, 'cv_split' : cv_split, \n",
    "          'metrics' : classification_metrics, 'n_jobs' : 1, \n",
    "          'test_size' : test_size,\n",
    "          'retrained_models' : True, 'patient_level_predictions' : True}\n",
    "\n",
    "X_all = X_all_proteins.join(X_all_clinical)\n",
    "features = ['H0YAC1','P00748']\n",
    "X = X_all[features]\n",
    "\n",
    "params.update({'X' : X,'models' : l1_logit_model.copy()})\n",
    "\n",
    "lst = bootstrap_of_fcn(func=train_test_val_top_fold,\n",
    "                       params=params,n_jobs=n_jobs,nboot=nboot)\n",
    "\n",
    "i = 10000\n",
    "fimps = feature_importances_df_from_lst(lst)\n",
    "fimps['set'] = str(i)\n",
    "klkb1_f12_fimp_df = (fimps.\n",
    "            groupby(['set','Feature'])['Importance'].\n",
    "            describe(percentiles=[0.025,0.975]).\n",
    "            loc[:,['2.5%','mean','97.5%']].\n",
    "            sort_values('2.5%',ascending=False).\n",
    "            reset_index()\n",
    "          )\n",
    "perf = performance_df_from_lst(lst)\n",
    "perf['set'] = str(i)\n",
    "klkb1_f12_perf_df = (perf.\n",
    "           groupby(['set'])['validation_roc_auc'].\n",
    "           describe(percentiles=[0.025,0.975]).\n",
    "           loc[:,['2.5%','mean','97.5%']].\n",
    "           sort_values('2.5%',ascending=False).\n",
    "           reset_index()\n",
    "          )\n",
    "display(klkb1_f12_perf_df)\n",
    "display(klkb1_f12_fimp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {'Y' : Y, 'cv_split' : cv_split, \n",
    "          'metrics' : classification_metrics, 'n_jobs' : 1, \n",
    "          'test_size' : test_size,\n",
    "          'retrained_models' : True, 'patient_level_predictions' : True}\n",
    "\n",
    "X_all = X_all_proteins.join(X_all_clinical)\n",
    "features = ['P01042','P00748']\n",
    "X = X_all[features]\n",
    "\n",
    "params.update({'X' : X,'models' : l1_logit_model.copy()})\n",
    "\n",
    "lst = bootstrap_of_fcn(func=train_test_val_top_fold,\n",
    "                       params=params,n_jobs=n_jobs,nboot=nboot)\n",
    "\n",
    "i = 10000\n",
    "fimps = feature_importances_df_from_lst(lst)\n",
    "fimps['set'] = str(i)\n",
    "f12_kng1_fimp_df = (fimps.\n",
    "            groupby(['set','Feature'])['Importance'].\n",
    "            describe(percentiles=[0.025,0.975]).\n",
    "            loc[:,['2.5%','mean','97.5%']].\n",
    "            sort_values('2.5%',ascending=False).\n",
    "            reset_index()\n",
    "          )\n",
    "perf = performance_df_from_lst(lst)\n",
    "perf['set'] = str(i)\n",
    "f12_kng1_perf_df = (perf.\n",
    "           groupby(['set'])['validation_roc_auc'].\n",
    "           describe(percentiles=[0.025,0.975]).\n",
    "           loc[:,['2.5%','mean','97.5%']].\n",
    "           sort_values('2.5%',ascending=False).\n",
    "           reset_index()\n",
    "          )\n",
    "display(f12_kng1_perf_df)\n",
    "display(f12_kng1_fimp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {'Y' : Y, 'cv_split' : cv_split, \n",
    "          'metrics' : classification_metrics, 'n_jobs' : 1, \n",
    "          'test_size' : test_size,\n",
    "          'retrained_models' : True, 'patient_level_predictions' : True}\n",
    "\n",
    "X_all = X_all_proteins.join(X_all_clinical)\n",
    "features = ['H0YAC1','P01042','P00748']\n",
    "X = X_all[features]\n",
    "\n",
    "params.update({'X' : X,'models' : l1_logit_model.copy()})\n",
    "\n",
    "lst = bootstrap_of_fcn(func=train_test_val_top_fold,\n",
    "                       params=params,n_jobs=n_jobs,nboot=nboot)\n",
    "\n",
    "i = 10000\n",
    "fimps = feature_importances_df_from_lst(lst)\n",
    "fimps['set'] = str(i)\n",
    "tet_fimp_df = (fimps.\n",
    "            groupby(['set','Feature'])['Importance'].\n",
    "            describe(percentiles=[0.025,0.975]).\n",
    "            loc[:,['2.5%','mean','97.5%']].\n",
    "            sort_values('2.5%',ascending=False).\n",
    "            reset_index()\n",
    "          )\n",
    "perf = performance_df_from_lst(lst)\n",
    "perf['set'] = str(i)\n",
    "tet_perf_df = (perf.\n",
    "           groupby(['set'])['validation_roc_auc'].\n",
    "           describe(percentiles=[0.025,0.975]).\n",
    "           loc[:,['2.5%','mean','97.5%']].\n",
    "           sort_values('2.5%',ascending=False).\n",
    "           reset_index()\n",
    "          )\n",
    "display(tet_perf_df)\n",
    "display(tet_fimp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### KLKB1 inhibitor prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def performance_df_from_lst(lst):\n",
    "    tmp = [lst[i][0] for i in range(len(lst))]\n",
    "    data = (pd.concat(tmp,keys=range(len(tmp))).\n",
    "            reset_index(level=1,drop=True).\n",
    "            rename_axis('bootstrap').\n",
    "            reset_index())\n",
    "    return data\n",
    "\n",
    "def feature_importances_df_from_lst(lst):\n",
    "    boot_mods = [lst[i][1] for i in range(nboot)]\n",
    "    dfs = []\n",
    "    X = params['X'].copy()\n",
    "    X.loc[:,'Intercept'] = 0\n",
    "    for i in range(len(boot_mods)):\n",
    "        for j in boot_mods[i].keys():\n",
    "            mod = boot_mods[i][j]\n",
    "            coef = []\n",
    "            try:\n",
    "                coef.extend([i for i in mod.feature_importances_])\n",
    "            except:\n",
    "                coef.extend([i for i in mod.coef_[0]])\n",
    "            coef.extend(mod.intercept_)\n",
    "            fs = []\n",
    "            fs.extend(X.columns.values)\n",
    "            df = pd.DataFrame({\n",
    "                'Feature' : fs,\n",
    "                'Gene_name' : (X.T.\n",
    "                               join(idmap_sub.\n",
    "                                    set_index('Protein'),how='left').\n",
    "                               Gene_name.values),\n",
    "                'Importance' : coef,\n",
    "                'Model' : j,\n",
    "                'Bootstrap' : i\n",
    "            })\n",
    "            dfs.append(df)\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run /Users/nickgiangreco/Research/Projects/exosome_pgf/src/python/prediction_functions.py\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "dir_ = '../../data/'\n",
    "cohort = 'integrated'\n",
    "\n",
    "classification_metrics = ['roc_auc','precision','recall','f1']\n",
    "nboot=1000\n",
    "n_jobs = 4\n",
    "test_size = .15\n",
    "cv_split = 10\n",
    "\n",
    "X_all_proteins = pd.read_csv(dir_+cohort+'_X_raw_all_proteins.csv',index_col=0)\n",
    "X_all_clinical = pd.read_csv(dir_+cohort+'_X_clinical_and_cohort_minus_paris_covariates.csv',index_col=0)\n",
    "Y = pd.read_csv(dir_+cohort+'_pgd_y.csv',index_col=0,header=None)\n",
    "\n",
    "idmap_sub = pd.read_csv('../../data/protein_gene_map_full.csv')[['Protein','Gene_name']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_all.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {'Y' : Y, 'cv_split' : cv_split, \n",
    "          'metrics' : classification_metrics, 'n_jobs' : 1, \n",
    "          'test_size' : test_size,\n",
    "          'retrained_models' : True, 'patient_level_predictions' : True}\n",
    "\n",
    "X_all = X_all_proteins.join(X_all_clinical)\n",
    "features = ['P05154']\n",
    "X = X_all[features]\n",
    "\n",
    "params.update({'X' : X,'models' : l1_logit_model.copy()})\n",
    "\n",
    "lst = bootstrap_of_fcn(func=train_test_val_top_fold,\n",
    "                       params=params,n_jobs=n_jobs,nboot=nboot)\n",
    "\n",
    "i = 10000\n",
    "fimps = feature_importances_df_from_lst(lst)\n",
    "fimps['set'] = str(i)\n",
    "inh_fimp_df = (fimps.\n",
    "            groupby(['set','Feature'])['Importance'].\n",
    "            describe(percentiles=[0.025,0.975]).\n",
    "            loc[:,['2.5%','mean','97.5%']].\n",
    "            sort_values('2.5%',ascending=False).\n",
    "            reset_index()\n",
    "          )\n",
    "perf = performance_df_from_lst(lst)\n",
    "perf['set'] = str(i)\n",
    "inh_perf_df = (perf.\n",
    "           groupby(['set'])['validation_roc_auc'].\n",
    "           describe(percentiles=[0.025,0.975]).\n",
    "           loc[:,['2.5%','mean','97.5%']].\n",
    "           sort_values('2.5%',ascending=False).\n",
    "           reset_index()\n",
    "          )\n",
    "display(inh_perf_df)\n",
    "display(inh_fimp_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
